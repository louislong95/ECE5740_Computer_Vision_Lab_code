{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab9 part2 classification color dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1WKpegr48Zb",
        "colab_type": "text"
      },
      "source": [
        "part2 classfication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlXGGfFq4_ug",
        "colab_type": "text"
      },
      "source": [
        "color dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcnqFPLl4rnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import copy\n",
        "import torch.utils.data as data_utils\n",
        "import requests, zipfile, io\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 40\n",
        "num_classes = 10\n",
        "batch_size = 8\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# ECE5470 dataset\n",
        "url = 'https://www.via.cornell.edu/ece5470/Lab9data2.zip'\n",
        "r=requests.get(url).content\n",
        "\n",
        "#save data in data dir\n",
        "z = zipfile.ZipFile(io.BytesIO(r))\n",
        "# os.mkdir('data1')\n",
        "z.extractall('./data1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb4rbN1e5NxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Custom datatset loader\n",
        "    based on https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import imageio\n",
        "\n",
        "class SimpleDataset():\n",
        "    def __init__(self, data_path, csv_name, transform = None ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): path to the folder where images and csv files are located\n",
        "            csv_name (string): name of the csv lablel file\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        # Set path\n",
        "        self.data_path = data_path\n",
        "        \n",
        "        # Read the csv file\n",
        "        self.data_info = pd.read_csv(data_path + csv_name, header=0)\n",
        "       \n",
        "        # First column contains the image paths\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
        "        \n",
        "        # Second column is the labels\n",
        "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "        # Calculate len\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # Get image name from the pandas df\n",
        "        single_image_name = self.image_arr[index]\n",
        "        # Open image\n",
        "        a=single_image_name[:-3] + \"png\"\n",
        "        single_image_name=a\n",
        "        img_as_img = imageio.imread(self.data_path + single_image_name)\n",
        "        # Open segmented mask\n",
        "        a = single_image_name[:2] + \"seg\" + single_image_name[2:]\n",
        "        imseg_name = a[:-3] + \"png\"\n",
        "        imgsg_as_img = imageio.imread(self.data_path + imseg_name)\n",
        "        \n",
        "        \n",
        "        # Get label(class) of the image based on the cropped pandas column\n",
        "        single_image_label = self.label_arr[index]\n",
        "        \n",
        "        return (img_as_img, single_image_label, imgsg_as_img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLlLjQWu5Rn3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec401a14-0c97-490f-f620-1f8e2854fcf5"
      },
      "source": [
        "mydata = SimpleDataset( \"./data1/\", \"labels.csv\")\n",
        "\n",
        "#splitting into images and labels \n",
        "X  = []\n",
        "y  = []\n",
        "Xs = []\n",
        "for i in range(len(mydata)):\n",
        "    X.append(mydata[i][0])\n",
        "    y.append((mydata[i][1]))\n",
        "    Xs.append(mydata[i][2])\n",
        "\n",
        "\n",
        "#converting into numpy arrays to enable easy reshaping and other array operations\n",
        "    \n",
        "X  = np.asarray(X)\n",
        "Xs = np.asarray(Xs)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape)\n",
        "y= np.asarray(y)\n",
        "\n",
        "X  = np.swapaxes(X,1,3)\n",
        "X  = np.swapaxes(X,2,3)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape,y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the input image (5000, 32, 32, 3) (5000, 32, 32)\n",
            "Shape of the input image (5000, 3, 32, 32) (5000, 32, 32) (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j4syQj25Vy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "61e20f9a-8e64-45f7-abe3-4caf601e351f"
      },
      "source": [
        "Xtr=X[:3500,:,:,:]/255\n",
        "Xstr=Xs[:3500,:,:]/255\n",
        "ytr=y[:3500]\n",
        "\n",
        "Xval=X[3500:4000,:,:,:]/255 #need to change validation size for 32x32 & 64x64 images\n",
        "Xsval=Xs[3500:4000,:,:]/255\n",
        "yval=y[3500:4000]\n",
        "\n",
        "Xte=X[4000:5000,:,:,:]/255 #need to change test size for 32x32 & 64x64 images\n",
        "Xste=Xs[4000:5000,:,:]/255\n",
        "yte=y[4000:5000]\n",
        "\n",
        "\n",
        "print(Xtr.shape,Xstr.shape,ytr.shape)\n",
        "print(Xval.shape,Xsval.shape,yval.shape)\n",
        "print(Xte.shape,Xste.shape,yte.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3500, 3, 32, 32) (3500, 32, 32) (3500,)\n",
            "(500, 3, 32, 32) (500, 32, 32) (500,)\n",
            "(1000, 3, 32, 32) (1000, 32, 32) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1CzmUES6BHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0b825987-937e-4a88-8081-8a1bf3083adb"
      },
      "source": [
        "batch_size = 8\n",
        "'''\n",
        "inputs and segs are your data. \n",
        "'''\n",
        "targets=ytr\n",
        "\n",
        "inputs = torch.from_numpy(Xtr).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xstr).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "trainset = data_utils.TensorDataset(inputs, segs, targets)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size= batch_size, \n",
        "                                          shuffle=True,drop_last=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([3500, 3, 32, 32])\n",
            "Size of ground truth: torch.Size([3500, 32, 32])\n",
            "torch.Size([3500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wugM_zQ6Ezd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d7f7d3c-1274-4417-b1c9-c23662741e41"
      },
      "source": [
        "targets=yte\n",
        "inputs = torch.from_numpy(Xte).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xste).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "testset = data_utils.TensorDataset(inputs, segs,targets)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size, \n",
        "                                          shuffle=False, drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([1000, 3, 32, 32])\n",
            "Size of ground truth: torch.Size([1000, 32, 32])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX7wscjA6SlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(2*32*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uYesZsH6xtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WTJD7Hx60ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1ea63d6a-2bac-4afd-a2e4-ae7a880491d4"
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "resultstr = []\n",
        "resultsval = []\n",
        "correct = 0\n",
        "total = 0\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, segs, targets) in enumerate(train_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,32,32))\n",
        "        labels = targets.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images.cuda())\n",
        "        loss = criterion(outputs, labels.to(torch.long))\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # O\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], TrLoss: {:.4f}' \n",
        "                   .format(epoch+1,num_epochs,i+1, total_step, loss.data))\n",
        "    \n",
        "    resultstr.append(loss.data.cpu().to(torch.float))\n",
        "acc = correct/total\n",
        "print('Training accuracy: {} %'.format(100*acc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/40], Step [50/437], TrLoss: 2.4231\n",
            "Epoch [1/40], Step [100/437], TrLoss: 2.2072\n",
            "Epoch [1/40], Step [150/437], TrLoss: 2.4042\n",
            "Epoch [1/40], Step [200/437], TrLoss: 2.4027\n",
            "Epoch [1/40], Step [250/437], TrLoss: 2.5434\n",
            "Epoch [1/40], Step [300/437], TrLoss: 2.4217\n",
            "Epoch [1/40], Step [350/437], TrLoss: 2.4040\n",
            "Epoch [1/40], Step [400/437], TrLoss: 2.3233\n",
            "Epoch [2/40], Step [50/437], TrLoss: 2.3187\n",
            "Epoch [2/40], Step [100/437], TrLoss: 2.2253\n",
            "Epoch [2/40], Step [150/437], TrLoss: 2.1831\n",
            "Epoch [2/40], Step [200/437], TrLoss: 2.6189\n",
            "Epoch [2/40], Step [250/437], TrLoss: 2.1099\n",
            "Epoch [2/40], Step [300/437], TrLoss: 2.2383\n",
            "Epoch [2/40], Step [350/437], TrLoss: 2.2300\n",
            "Epoch [2/40], Step [400/437], TrLoss: 2.2038\n",
            "Epoch [3/40], Step [50/437], TrLoss: 2.3483\n",
            "Epoch [3/40], Step [100/437], TrLoss: 1.9925\n",
            "Epoch [3/40], Step [150/437], TrLoss: 2.1369\n",
            "Epoch [3/40], Step [200/437], TrLoss: 2.2160\n",
            "Epoch [3/40], Step [250/437], TrLoss: 2.2185\n",
            "Epoch [3/40], Step [300/437], TrLoss: 2.3163\n",
            "Epoch [3/40], Step [350/437], TrLoss: 2.0832\n",
            "Epoch [3/40], Step [400/437], TrLoss: 2.1073\n",
            "Epoch [4/40], Step [50/437], TrLoss: 2.2093\n",
            "Epoch [4/40], Step [100/437], TrLoss: 2.2377\n",
            "Epoch [4/40], Step [150/437], TrLoss: 2.1117\n",
            "Epoch [4/40], Step [200/437], TrLoss: 2.5767\n",
            "Epoch [4/40], Step [250/437], TrLoss: 1.9011\n",
            "Epoch [4/40], Step [300/437], TrLoss: 2.0660\n",
            "Epoch [4/40], Step [350/437], TrLoss: 2.3030\n",
            "Epoch [4/40], Step [400/437], TrLoss: 2.0243\n",
            "Epoch [5/40], Step [50/437], TrLoss: 1.9871\n",
            "Epoch [5/40], Step [100/437], TrLoss: 2.0506\n",
            "Epoch [5/40], Step [150/437], TrLoss: 1.5535\n",
            "Epoch [5/40], Step [200/437], TrLoss: 1.9190\n",
            "Epoch [5/40], Step [250/437], TrLoss: 2.1550\n",
            "Epoch [5/40], Step [300/437], TrLoss: 2.1771\n",
            "Epoch [5/40], Step [350/437], TrLoss: 2.0468\n",
            "Epoch [5/40], Step [400/437], TrLoss: 1.7430\n",
            "Epoch [6/40], Step [50/437], TrLoss: 1.8598\n",
            "Epoch [6/40], Step [100/437], TrLoss: 1.6675\n",
            "Epoch [6/40], Step [150/437], TrLoss: 1.7837\n",
            "Epoch [6/40], Step [200/437], TrLoss: 1.6607\n",
            "Epoch [6/40], Step [250/437], TrLoss: 1.8508\n",
            "Epoch [6/40], Step [300/437], TrLoss: 1.8972\n",
            "Epoch [6/40], Step [350/437], TrLoss: 2.1112\n",
            "Epoch [6/40], Step [400/437], TrLoss: 1.8094\n",
            "Epoch [7/40], Step [50/437], TrLoss: 1.6023\n",
            "Epoch [7/40], Step [100/437], TrLoss: 1.6563\n",
            "Epoch [7/40], Step [150/437], TrLoss: 2.1334\n",
            "Epoch [7/40], Step [200/437], TrLoss: 1.9150\n",
            "Epoch [7/40], Step [250/437], TrLoss: 1.7078\n",
            "Epoch [7/40], Step [300/437], TrLoss: 2.3257\n",
            "Epoch [7/40], Step [350/437], TrLoss: 1.9758\n",
            "Epoch [7/40], Step [400/437], TrLoss: 1.8600\n",
            "Epoch [8/40], Step [50/437], TrLoss: 1.6197\n",
            "Epoch [8/40], Step [100/437], TrLoss: 1.3014\n",
            "Epoch [8/40], Step [150/437], TrLoss: 1.4038\n",
            "Epoch [8/40], Step [200/437], TrLoss: 1.8555\n",
            "Epoch [8/40], Step [250/437], TrLoss: 1.8688\n",
            "Epoch [8/40], Step [300/437], TrLoss: 1.2845\n",
            "Epoch [8/40], Step [350/437], TrLoss: 1.6697\n",
            "Epoch [8/40], Step [400/437], TrLoss: 1.9172\n",
            "Epoch [9/40], Step [50/437], TrLoss: 1.5463\n",
            "Epoch [9/40], Step [100/437], TrLoss: 1.7588\n",
            "Epoch [9/40], Step [150/437], TrLoss: 1.5673\n",
            "Epoch [9/40], Step [200/437], TrLoss: 1.5776\n",
            "Epoch [9/40], Step [250/437], TrLoss: 1.4223\n",
            "Epoch [9/40], Step [300/437], TrLoss: 1.3176\n",
            "Epoch [9/40], Step [350/437], TrLoss: 2.0900\n",
            "Epoch [9/40], Step [400/437], TrLoss: 1.6611\n",
            "Epoch [10/40], Step [50/437], TrLoss: 1.4992\n",
            "Epoch [10/40], Step [100/437], TrLoss: 1.5113\n",
            "Epoch [10/40], Step [150/437], TrLoss: 1.6260\n",
            "Epoch [10/40], Step [200/437], TrLoss: 1.1042\n",
            "Epoch [10/40], Step [250/437], TrLoss: 1.5504\n",
            "Epoch [10/40], Step [300/437], TrLoss: 1.4282\n",
            "Epoch [10/40], Step [350/437], TrLoss: 1.5603\n",
            "Epoch [10/40], Step [400/437], TrLoss: 1.8560\n",
            "Epoch [11/40], Step [50/437], TrLoss: 1.8443\n",
            "Epoch [11/40], Step [100/437], TrLoss: 1.3885\n",
            "Epoch [11/40], Step [150/437], TrLoss: 1.3871\n",
            "Epoch [11/40], Step [200/437], TrLoss: 1.7952\n",
            "Epoch [11/40], Step [250/437], TrLoss: 1.3791\n",
            "Epoch [11/40], Step [300/437], TrLoss: 1.4288\n",
            "Epoch [11/40], Step [350/437], TrLoss: 1.8081\n",
            "Epoch [11/40], Step [400/437], TrLoss: 1.1500\n",
            "Epoch [12/40], Step [50/437], TrLoss: 1.5501\n",
            "Epoch [12/40], Step [100/437], TrLoss: 1.3051\n",
            "Epoch [12/40], Step [150/437], TrLoss: 1.1867\n",
            "Epoch [12/40], Step [200/437], TrLoss: 1.8231\n",
            "Epoch [12/40], Step [250/437], TrLoss: 1.4473\n",
            "Epoch [12/40], Step [300/437], TrLoss: 0.9848\n",
            "Epoch [12/40], Step [350/437], TrLoss: 1.0304\n",
            "Epoch [12/40], Step [400/437], TrLoss: 1.4622\n",
            "Epoch [13/40], Step [50/437], TrLoss: 1.2033\n",
            "Epoch [13/40], Step [100/437], TrLoss: 1.5124\n",
            "Epoch [13/40], Step [150/437], TrLoss: 1.3452\n",
            "Epoch [13/40], Step [200/437], TrLoss: 1.5184\n",
            "Epoch [13/40], Step [250/437], TrLoss: 1.2403\n",
            "Epoch [13/40], Step [300/437], TrLoss: 1.3321\n",
            "Epoch [13/40], Step [350/437], TrLoss: 2.3004\n",
            "Epoch [13/40], Step [400/437], TrLoss: 1.6266\n",
            "Epoch [14/40], Step [50/437], TrLoss: 0.9122\n",
            "Epoch [14/40], Step [100/437], TrLoss: 1.0275\n",
            "Epoch [14/40], Step [150/437], TrLoss: 1.0849\n",
            "Epoch [14/40], Step [200/437], TrLoss: 1.1089\n",
            "Epoch [14/40], Step [250/437], TrLoss: 1.4935\n",
            "Epoch [14/40], Step [300/437], TrLoss: 0.9025\n",
            "Epoch [14/40], Step [350/437], TrLoss: 1.1693\n",
            "Epoch [14/40], Step [400/437], TrLoss: 1.1295\n",
            "Epoch [15/40], Step [50/437], TrLoss: 0.9408\n",
            "Epoch [15/40], Step [100/437], TrLoss: 1.5193\n",
            "Epoch [15/40], Step [150/437], TrLoss: 0.9196\n",
            "Epoch [15/40], Step [200/437], TrLoss: 1.1881\n",
            "Epoch [15/40], Step [250/437], TrLoss: 1.3966\n",
            "Epoch [15/40], Step [300/437], TrLoss: 1.3314\n",
            "Epoch [15/40], Step [350/437], TrLoss: 0.8919\n",
            "Epoch [15/40], Step [400/437], TrLoss: 0.8583\n",
            "Epoch [16/40], Step [50/437], TrLoss: 0.7597\n",
            "Epoch [16/40], Step [100/437], TrLoss: 0.9684\n",
            "Epoch [16/40], Step [150/437], TrLoss: 0.9154\n",
            "Epoch [16/40], Step [200/437], TrLoss: 1.0162\n",
            "Epoch [16/40], Step [250/437], TrLoss: 0.9139\n",
            "Epoch [16/40], Step [300/437], TrLoss: 0.8701\n",
            "Epoch [16/40], Step [350/437], TrLoss: 1.3937\n",
            "Epoch [16/40], Step [400/437], TrLoss: 0.9621\n",
            "Epoch [17/40], Step [50/437], TrLoss: 0.8615\n",
            "Epoch [17/40], Step [100/437], TrLoss: 1.0269\n",
            "Epoch [17/40], Step [150/437], TrLoss: 0.8771\n",
            "Epoch [17/40], Step [200/437], TrLoss: 0.9578\n",
            "Epoch [17/40], Step [250/437], TrLoss: 0.9048\n",
            "Epoch [17/40], Step [300/437], TrLoss: 1.4755\n",
            "Epoch [17/40], Step [350/437], TrLoss: 1.1377\n",
            "Epoch [17/40], Step [400/437], TrLoss: 0.9553\n",
            "Epoch [18/40], Step [50/437], TrLoss: 0.8142\n",
            "Epoch [18/40], Step [100/437], TrLoss: 0.9335\n",
            "Epoch [18/40], Step [150/437], TrLoss: 0.6630\n",
            "Epoch [18/40], Step [200/437], TrLoss: 1.0494\n",
            "Epoch [18/40], Step [250/437], TrLoss: 0.8587\n",
            "Epoch [18/40], Step [300/437], TrLoss: 0.8131\n",
            "Epoch [18/40], Step [350/437], TrLoss: 0.7211\n",
            "Epoch [18/40], Step [400/437], TrLoss: 1.1247\n",
            "Epoch [19/40], Step [50/437], TrLoss: 0.6928\n",
            "Epoch [19/40], Step [100/437], TrLoss: 0.8431\n",
            "Epoch [19/40], Step [150/437], TrLoss: 0.4954\n",
            "Epoch [19/40], Step [200/437], TrLoss: 0.6518\n",
            "Epoch [19/40], Step [250/437], TrLoss: 0.5812\n",
            "Epoch [19/40], Step [300/437], TrLoss: 0.6239\n",
            "Epoch [19/40], Step [350/437], TrLoss: 1.2253\n",
            "Epoch [19/40], Step [400/437], TrLoss: 0.6850\n",
            "Epoch [20/40], Step [50/437], TrLoss: 0.5103\n",
            "Epoch [20/40], Step [100/437], TrLoss: 0.6342\n",
            "Epoch [20/40], Step [150/437], TrLoss: 0.8497\n",
            "Epoch [20/40], Step [200/437], TrLoss: 0.8444\n",
            "Epoch [20/40], Step [250/437], TrLoss: 0.5901\n",
            "Epoch [20/40], Step [300/437], TrLoss: 0.7028\n",
            "Epoch [20/40], Step [350/437], TrLoss: 0.6185\n",
            "Epoch [20/40], Step [400/437], TrLoss: 0.7067\n",
            "Epoch [21/40], Step [50/437], TrLoss: 0.5673\n",
            "Epoch [21/40], Step [100/437], TrLoss: 0.4751\n",
            "Epoch [21/40], Step [150/437], TrLoss: 0.8913\n",
            "Epoch [21/40], Step [200/437], TrLoss: 0.8009\n",
            "Epoch [21/40], Step [250/437], TrLoss: 0.9362\n",
            "Epoch [21/40], Step [300/437], TrLoss: 0.7572\n",
            "Epoch [21/40], Step [350/437], TrLoss: 1.1402\n",
            "Epoch [21/40], Step [400/437], TrLoss: 0.7779\n",
            "Epoch [22/40], Step [50/437], TrLoss: 0.5215\n",
            "Epoch [22/40], Step [100/437], TrLoss: 0.8300\n",
            "Epoch [22/40], Step [150/437], TrLoss: 0.9624\n",
            "Epoch [22/40], Step [200/437], TrLoss: 0.6347\n",
            "Epoch [22/40], Step [250/437], TrLoss: 0.7681\n",
            "Epoch [22/40], Step [300/437], TrLoss: 0.6059\n",
            "Epoch [22/40], Step [350/437], TrLoss: 0.5540\n",
            "Epoch [22/40], Step [400/437], TrLoss: 0.6803\n",
            "Epoch [23/40], Step [50/437], TrLoss: 0.4005\n",
            "Epoch [23/40], Step [100/437], TrLoss: 0.6404\n",
            "Epoch [23/40], Step [150/437], TrLoss: 0.5858\n",
            "Epoch [23/40], Step [200/437], TrLoss: 0.8298\n",
            "Epoch [23/40], Step [250/437], TrLoss: 0.6300\n",
            "Epoch [23/40], Step [300/437], TrLoss: 0.6048\n",
            "Epoch [23/40], Step [350/437], TrLoss: 0.6941\n",
            "Epoch [23/40], Step [400/437], TrLoss: 0.6525\n",
            "Epoch [24/40], Step [50/437], TrLoss: 0.5637\n",
            "Epoch [24/40], Step [100/437], TrLoss: 0.5721\n",
            "Epoch [24/40], Step [150/437], TrLoss: 0.5656\n",
            "Epoch [24/40], Step [200/437], TrLoss: 0.5233\n",
            "Epoch [24/40], Step [250/437], TrLoss: 0.6782\n",
            "Epoch [24/40], Step [300/437], TrLoss: 0.5612\n",
            "Epoch [24/40], Step [350/437], TrLoss: 0.7382\n",
            "Epoch [24/40], Step [400/437], TrLoss: 0.5086\n",
            "Epoch [25/40], Step [50/437], TrLoss: 0.1978\n",
            "Epoch [25/40], Step [100/437], TrLoss: 0.5534\n",
            "Epoch [25/40], Step [150/437], TrLoss: 0.4339\n",
            "Epoch [25/40], Step [200/437], TrLoss: 0.5342\n",
            "Epoch [25/40], Step [250/437], TrLoss: 0.7300\n",
            "Epoch [25/40], Step [300/437], TrLoss: 0.5937\n",
            "Epoch [25/40], Step [350/437], TrLoss: 0.6731\n",
            "Epoch [25/40], Step [400/437], TrLoss: 0.6360\n",
            "Epoch [26/40], Step [50/437], TrLoss: 0.4132\n",
            "Epoch [26/40], Step [100/437], TrLoss: 0.6647\n",
            "Epoch [26/40], Step [150/437], TrLoss: 0.4887\n",
            "Epoch [26/40], Step [200/437], TrLoss: 0.3411\n",
            "Epoch [26/40], Step [250/437], TrLoss: 0.3787\n",
            "Epoch [26/40], Step [300/437], TrLoss: 0.5964\n",
            "Epoch [26/40], Step [350/437], TrLoss: 0.7525\n",
            "Epoch [26/40], Step [400/437], TrLoss: 0.4436\n",
            "Epoch [27/40], Step [50/437], TrLoss: 0.3230\n",
            "Epoch [27/40], Step [100/437], TrLoss: 0.4952\n",
            "Epoch [27/40], Step [150/437], TrLoss: 0.2192\n",
            "Epoch [27/40], Step [200/437], TrLoss: 0.2904\n",
            "Epoch [27/40], Step [250/437], TrLoss: 0.3868\n",
            "Epoch [27/40], Step [300/437], TrLoss: 0.4499\n",
            "Epoch [27/40], Step [350/437], TrLoss: 0.5399\n",
            "Epoch [27/40], Step [400/437], TrLoss: 0.5253\n",
            "Epoch [28/40], Step [50/437], TrLoss: 0.2234\n",
            "Epoch [28/40], Step [100/437], TrLoss: 0.2552\n",
            "Epoch [28/40], Step [150/437], TrLoss: 0.4031\n",
            "Epoch [28/40], Step [200/437], TrLoss: 0.4516\n",
            "Epoch [28/40], Step [250/437], TrLoss: 0.3556\n",
            "Epoch [28/40], Step [300/437], TrLoss: 0.5018\n",
            "Epoch [28/40], Step [350/437], TrLoss: 0.5623\n",
            "Epoch [28/40], Step [400/437], TrLoss: 0.7636\n",
            "Epoch [29/40], Step [50/437], TrLoss: 0.3012\n",
            "Epoch [29/40], Step [100/437], TrLoss: 0.4098\n",
            "Epoch [29/40], Step [150/437], TrLoss: 0.2768\n",
            "Epoch [29/40], Step [200/437], TrLoss: 0.2659\n",
            "Epoch [29/40], Step [250/437], TrLoss: 0.2764\n",
            "Epoch [29/40], Step [300/437], TrLoss: 0.3937\n",
            "Epoch [29/40], Step [350/437], TrLoss: 0.3164\n",
            "Epoch [29/40], Step [400/437], TrLoss: 0.4331\n",
            "Epoch [30/40], Step [50/437], TrLoss: 0.3661\n",
            "Epoch [30/40], Step [100/437], TrLoss: 0.5961\n",
            "Epoch [30/40], Step [150/437], TrLoss: 0.3291\n",
            "Epoch [30/40], Step [200/437], TrLoss: 0.2289\n",
            "Epoch [30/40], Step [250/437], TrLoss: 0.5167\n",
            "Epoch [30/40], Step [300/437], TrLoss: 0.3164\n",
            "Epoch [30/40], Step [350/437], TrLoss: 0.4786\n",
            "Epoch [30/40], Step [400/437], TrLoss: 0.3611\n",
            "Epoch [31/40], Step [50/437], TrLoss: 0.3243\n",
            "Epoch [31/40], Step [100/437], TrLoss: 0.1921\n",
            "Epoch [31/40], Step [150/437], TrLoss: 0.2584\n",
            "Epoch [31/40], Step [200/437], TrLoss: 0.2612\n",
            "Epoch [31/40], Step [250/437], TrLoss: 0.2581\n",
            "Epoch [31/40], Step [300/437], TrLoss: 0.3697\n",
            "Epoch [31/40], Step [350/437], TrLoss: 0.3922\n",
            "Epoch [31/40], Step [400/437], TrLoss: 0.3368\n",
            "Epoch [32/40], Step [50/437], TrLoss: 0.2947\n",
            "Epoch [32/40], Step [100/437], TrLoss: 0.2345\n",
            "Epoch [32/40], Step [150/437], TrLoss: 0.2389\n",
            "Epoch [32/40], Step [200/437], TrLoss: 0.3112\n",
            "Epoch [32/40], Step [250/437], TrLoss: 0.3077\n",
            "Epoch [32/40], Step [300/437], TrLoss: 0.3001\n",
            "Epoch [32/40], Step [350/437], TrLoss: 0.3582\n",
            "Epoch [32/40], Step [400/437], TrLoss: 0.1873\n",
            "Epoch [33/40], Step [50/437], TrLoss: 0.3372\n",
            "Epoch [33/40], Step [100/437], TrLoss: 0.2057\n",
            "Epoch [33/40], Step [150/437], TrLoss: 0.2725\n",
            "Epoch [33/40], Step [200/437], TrLoss: 0.3174\n",
            "Epoch [33/40], Step [250/437], TrLoss: 0.2082\n",
            "Epoch [33/40], Step [300/437], TrLoss: 0.2361\n",
            "Epoch [33/40], Step [350/437], TrLoss: 0.3478\n",
            "Epoch [33/40], Step [400/437], TrLoss: 0.4185\n",
            "Epoch [34/40], Step [50/437], TrLoss: 0.2385\n",
            "Epoch [34/40], Step [100/437], TrLoss: 0.1312\n",
            "Epoch [34/40], Step [150/437], TrLoss: 0.1823\n",
            "Epoch [34/40], Step [200/437], TrLoss: 0.1848\n",
            "Epoch [34/40], Step [250/437], TrLoss: 0.1606\n",
            "Epoch [34/40], Step [300/437], TrLoss: 0.3598\n",
            "Epoch [34/40], Step [350/437], TrLoss: 0.3212\n",
            "Epoch [34/40], Step [400/437], TrLoss: 0.4788\n",
            "Epoch [35/40], Step [50/437], TrLoss: 0.1662\n",
            "Epoch [35/40], Step [100/437], TrLoss: 0.4139\n",
            "Epoch [35/40], Step [150/437], TrLoss: 0.2740\n",
            "Epoch [35/40], Step [200/437], TrLoss: 0.1749\n",
            "Epoch [35/40], Step [250/437], TrLoss: 0.2523\n",
            "Epoch [35/40], Step [300/437], TrLoss: 0.2644\n",
            "Epoch [35/40], Step [350/437], TrLoss: 0.1388\n",
            "Epoch [35/40], Step [400/437], TrLoss: 0.2453\n",
            "Epoch [36/40], Step [50/437], TrLoss: 0.1099\n",
            "Epoch [36/40], Step [100/437], TrLoss: 0.0906\n",
            "Epoch [36/40], Step [150/437], TrLoss: 0.1687\n",
            "Epoch [36/40], Step [200/437], TrLoss: 0.2139\n",
            "Epoch [36/40], Step [250/437], TrLoss: 0.3513\n",
            "Epoch [36/40], Step [300/437], TrLoss: 0.1970\n",
            "Epoch [36/40], Step [350/437], TrLoss: 0.1335\n",
            "Epoch [36/40], Step [400/437], TrLoss: 0.2205\n",
            "Epoch [37/40], Step [50/437], TrLoss: 0.1375\n",
            "Epoch [37/40], Step [100/437], TrLoss: 0.1691\n",
            "Epoch [37/40], Step [150/437], TrLoss: 0.1372\n",
            "Epoch [37/40], Step [200/437], TrLoss: 0.1266\n",
            "Epoch [37/40], Step [250/437], TrLoss: 0.2616\n",
            "Epoch [37/40], Step [300/437], TrLoss: 0.1665\n",
            "Epoch [37/40], Step [350/437], TrLoss: 0.2598\n",
            "Epoch [37/40], Step [400/437], TrLoss: 0.4517\n",
            "Epoch [38/40], Step [50/437], TrLoss: 0.2053\n",
            "Epoch [38/40], Step [100/437], TrLoss: 0.1148\n",
            "Epoch [38/40], Step [150/437], TrLoss: 0.0809\n",
            "Epoch [38/40], Step [200/437], TrLoss: 0.1341\n",
            "Epoch [38/40], Step [250/437], TrLoss: 0.1684\n",
            "Epoch [38/40], Step [300/437], TrLoss: 0.1021\n",
            "Epoch [38/40], Step [350/437], TrLoss: 0.1269\n",
            "Epoch [38/40], Step [400/437], TrLoss: 0.1290\n",
            "Epoch [39/40], Step [50/437], TrLoss: 0.0649\n",
            "Epoch [39/40], Step [100/437], TrLoss: 0.1261\n",
            "Epoch [39/40], Step [150/437], TrLoss: 0.0911\n",
            "Epoch [39/40], Step [200/437], TrLoss: 0.2549\n",
            "Epoch [39/40], Step [250/437], TrLoss: 0.0756\n",
            "Epoch [39/40], Step [300/437], TrLoss: 0.1401\n",
            "Epoch [39/40], Step [350/437], TrLoss: 0.2622\n",
            "Epoch [39/40], Step [400/437], TrLoss: 0.1456\n",
            "Epoch [40/40], Step [50/437], TrLoss: 0.0812\n",
            "Epoch [40/40], Step [100/437], TrLoss: 0.0694\n",
            "Epoch [40/40], Step [150/437], TrLoss: 0.0645\n",
            "Epoch [40/40], Step [200/437], TrLoss: 0.1044\n",
            "Epoch [40/40], Step [250/437], TrLoss: 0.1224\n",
            "Epoch [40/40], Step [300/437], TrLoss: 0.1027\n",
            "Epoch [40/40], Step [350/437], TrLoss: 0.1325\n",
            "Epoch [40/40], Step [400/437], TrLoss: 0.1801\n",
            "Training accuracy: 74.16690503432494 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbnVIiZn8PFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14722e4d-974d-4d17-9afe-89aa012670d9"
      },
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    OP = []\n",
        "    PR = []\n",
        "    LB = []\n",
        "    for i, (images, segs, targets) in enumerate(test_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,32,32))\n",
        "        labels = targets.to(device)\n",
        "        LB.append(labels.cpu().numpy())\n",
        "        outputs=model(images.cuda())\n",
        "        OP.append(outputs.cpu().numpy())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        PR.append(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the 1000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 1000 test images: 21.1 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoXjl4HF8dmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d80d7dd4-bbad-4656-f655-3e25c2351e3f"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = np.array(PR)\n",
        "pred = pred.reshape(1000)\n",
        "print(np.shape(pred))\n",
        "label = np.array(LB)\n",
        "label = label.reshape(1000)\n",
        "print(np.shape(label))\n",
        "cfm=confusion_matrix(pred, label)\n",
        "print(cfm)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "[[31  9  6  5 12  5 12 14  6  9]\n",
            " [ 0 29  0  1  5  0  1  2  0  0]\n",
            " [17 11 30 33 14 22 21 16 19 19]\n",
            " [10  8 30 29  3 16  7 11 19 16]\n",
            " [ 9 15  4  1 16  3  6  4  6  3]\n",
            " [ 8  6 11 18  3 14  6  7 12 10]\n",
            " [ 7  9  3  3 14  4 21 10  4  7]\n",
            " [11 20  8  2 17  2  7 19  7 10]\n",
            " [ 7  4  9 12 12  4  8  5 10 15]\n",
            " [ 7 14  5  2  9  1  5  7  7 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}