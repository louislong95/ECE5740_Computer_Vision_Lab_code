{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab9_part1_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM4DfBf4_QFt",
        "colab_type": "text"
      },
      "source": [
        "part1.classification color dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP1GSAPQLgSy",
        "colab_type": "text"
      },
      "source": [
        "In this part, we are doing classification based on the color dataset, using the UNET model. Firstly, we need to download the color dataset from the provided url."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AoKXw91yZec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import copy\n",
        "import torch.utils.data as data_utils\n",
        "import requests, zipfile, io\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 40\n",
        "num_classes = 10\n",
        "batch_size = 8\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# ECE5470 dataset\n",
        "url = 'https://www.via.cornell.edu/ece5470/Lab9data1.zip'\n",
        "r=requests.get(url).content\n",
        "\n",
        "#save data in data dir\n",
        "z = zipfile.ZipFile(io.BytesIO(r))\n",
        "# os.mkdir('data1')\n",
        "z.extractall('./data1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lplCTuhv0Yaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Custom datatset loader\n",
        "    based on https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import imageio\n",
        "\n",
        "class SimpleDataset():\n",
        "    def __init__(self, data_path, csv_name, transform = None ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): path to the folder where images and csv files are located\n",
        "            csv_name (string): name of the csv lablel file\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        # Set path\n",
        "        self.data_path = data_path\n",
        "        \n",
        "        # Read the csv file\n",
        "        self.data_info = pd.read_csv(data_path + csv_name, header=0)\n",
        "       \n",
        "        # First column contains the image paths\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
        "        \n",
        "        # Second column is the labels\n",
        "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "        # Calculate len\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # Get image name from the pandas df\n",
        "        single_image_name = self.image_arr[index]\n",
        "        # Open image\n",
        "        a=single_image_name[:-3] + \"png\"\n",
        "        single_image_name=a\n",
        "        img_as_img = imageio.imread(self.data_path + single_image_name)\n",
        "        # Open segmented mask\n",
        "        a = single_image_name[:2] + \"seg\" + single_image_name[2:]\n",
        "        imseg_name = a[:-3] + \"png\"\n",
        "        imgsg_as_img = imageio.imread(self.data_path + imseg_name)\n",
        "        \n",
        "        \n",
        "        # Get label(class) of the image based on the cropped pandas column\n",
        "        single_image_label = self.label_arr[index]\n",
        "        \n",
        "        return (img_as_img, single_image_label, imgsg_as_img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn433CC60khN",
        "colab_type": "code",
        "outputId": "aac1fe6c-df98-4410-cdc2-70f57172e036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mydata = SimpleDataset( \"./data1/\", \"labels.csv\")\n",
        "\n",
        "#splitting into images and labels \n",
        "X  = []\n",
        "y  = []\n",
        "Xs = []\n",
        "for i in range(len(mydata)):\n",
        "    X.append(mydata[i][0])\n",
        "    y.append((mydata[i][1]))\n",
        "    Xs.append(mydata[i][2])\n",
        "\n",
        "\n",
        "#converting into numpy arrays to enable easy reshaping and other array operations\n",
        "    \n",
        "X  = np.asarray(X)\n",
        "Xs = np.asarray(Xs)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape)\n",
        "y= np.asarray(y)\n",
        "\n",
        "X  = np.swapaxes(X,1,3)\n",
        "X  = np.swapaxes(X,2,3)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape,y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the input image (10000, 16, 16, 3) (10000, 16, 16)\n",
            "Shape of the input image (10000, 3, 16, 16) (10000, 16, 16) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE1cmvJALnyC",
        "colab_type": "text"
      },
      "source": [
        "Then we need to seperate the dataset into three parts- training dataset: 8500 datas; validation dataset: 500 datas; testing dataset: 1000 datas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlH1oJy107Px",
        "colab_type": "code",
        "outputId": "2bdf520e-cfc3-4f04-a996-b99577fe9da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Xtr=X[:8500,:,:,:]/255\n",
        "Xstr=Xs[:8500,:,:]/255\n",
        "ytr=y[:8500]\n",
        "\n",
        "Xval=X[8500:9000,:,:,:]/255 #need to change validation size for 32x32 & 64x64 images\n",
        "Xsval=Xs[8500:9000,:,:]/255\n",
        "yval=y[8500:9000]\n",
        "\n",
        "Xte=X[-1000:,:,:,:]/255 #need to change test size for 32x32 & 64x64 images\n",
        "Xste=Xs[-1000:,:,:]/255\n",
        "yte=y[-1000:]\n",
        "\n",
        "\n",
        "print(Xtr.shape,Xstr.shape,ytr.shape)\n",
        "print(Xval.shape,Xsval.shape,yval.shape)\n",
        "print(Xte.shape,Xste.shape,yte.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8500, 3, 16, 16) (8500, 16, 16) (8500,)\n",
            "(500, 3, 16, 16) (500, 16, 16) (500,)\n",
            "(1000, 3, 16, 16) (1000, 16, 16) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaB0xR46LsU2",
        "colab_type": "text"
      },
      "source": [
        "Then we need to set the train datset dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmHM3M9P1Oax",
        "colab_type": "code",
        "outputId": "bc5df862-53f8-4f9e-940a-adb86cfa65b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 8\n",
        "'''\n",
        "inputs and segs are your data. \n",
        "'''\n",
        "targets=ytr\n",
        "\n",
        "inputs = torch.from_numpy(Xtr).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xstr).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "trainset = data_utils.TensorDataset(inputs, segs, targets)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size= batch_size, \n",
        "                                          shuffle=True,drop_last=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([8500, 3, 16, 16])\n",
            "Size of ground truth: torch.Size([8500, 16, 16])\n",
            "torch.Size([8500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzzYUBznLvMj",
        "colab_type": "text"
      },
      "source": [
        "Next comes the test dataset dataloader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZmg4Mj_36ij",
        "colab_type": "code",
        "outputId": "acfd00bc-19c8-4b27-fde3-3252c9ae03b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "targets=yte\n",
        "inputs = torch.from_numpy(Xte).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xste).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "testset = data_utils.TensorDataset(inputs, segs,targets)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size, \n",
        "                                          shuffle=False, drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([1000, 3, 16, 16])\n",
            "Size of ground truth: torch.Size([1000, 16, 16])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN3dNn5FLyKs",
        "colab_type": "text"
      },
      "source": [
        "Build the Convolutional neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNh-PC_X4b16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(2*16*16, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p26K5l374czl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r6ElTyWL2p8",
        "colab_type": "text"
      },
      "source": [
        "Then we begin to train the model using the training dataset, and the training accuracy is 89.5%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpaXPbwe4f-D",
        "colab_type": "code",
        "outputId": "bfaff9cd-2957-46a4-844a-006c80828078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "resultstr = []\n",
        "resultsval = []\n",
        "correct = 0\n",
        "total = 0\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, segs, targets) in enumerate(train_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,16,16))\n",
        "        labels = targets.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images.cuda())\n",
        "        loss = criterion(outputs, labels.to(torch.long))\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # O\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], TrLoss: {:.4f}' \n",
        "                   .format(epoch+1,num_epochs,i+1, total_step, loss.data))\n",
        "    \n",
        "    resultstr.append(loss.data.cpu().to(torch.float))\n",
        "acc = correct/total\n",
        "print('Training accuracy: {} %'.format(100*acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/40], Step [50/1062], TrLoss: 2.4452\n",
            "Epoch [1/40], Step [100/1062], TrLoss: 2.2346\n",
            "Epoch [1/40], Step [150/1062], TrLoss: 2.1296\n",
            "Epoch [1/40], Step [200/1062], TrLoss: 2.4211\n",
            "Epoch [1/40], Step [250/1062], TrLoss: 2.3590\n",
            "Epoch [1/40], Step [300/1062], TrLoss: 2.1951\n",
            "Epoch [1/40], Step [350/1062], TrLoss: 1.9597\n",
            "Epoch [1/40], Step [400/1062], TrLoss: 2.4298\n",
            "Epoch [1/40], Step [450/1062], TrLoss: 2.2214\n",
            "Epoch [1/40], Step [500/1062], TrLoss: 2.0130\n",
            "Epoch [1/40], Step [550/1062], TrLoss: 1.8672\n",
            "Epoch [1/40], Step [600/1062], TrLoss: 1.8156\n",
            "Epoch [1/40], Step [650/1062], TrLoss: 2.1528\n",
            "Epoch [1/40], Step [700/1062], TrLoss: 1.9352\n",
            "Epoch [1/40], Step [750/1062], TrLoss: 1.9456\n",
            "Epoch [1/40], Step [800/1062], TrLoss: 2.2027\n",
            "Epoch [1/40], Step [850/1062], TrLoss: 1.7835\n",
            "Epoch [1/40], Step [900/1062], TrLoss: 1.8281\n",
            "Epoch [1/40], Step [950/1062], TrLoss: 1.8375\n",
            "Epoch [1/40], Step [1000/1062], TrLoss: 1.9021\n",
            "Epoch [1/40], Step [1050/1062], TrLoss: 1.7821\n",
            "Epoch [2/40], Step [50/1062], TrLoss: 1.7392\n",
            "Epoch [2/40], Step [100/1062], TrLoss: 1.6535\n",
            "Epoch [2/40], Step [150/1062], TrLoss: 1.7293\n",
            "Epoch [2/40], Step [200/1062], TrLoss: 1.8436\n",
            "Epoch [2/40], Step [250/1062], TrLoss: 1.2070\n",
            "Epoch [2/40], Step [300/1062], TrLoss: 1.7598\n",
            "Epoch [2/40], Step [350/1062], TrLoss: 1.4737\n",
            "Epoch [2/40], Step [400/1062], TrLoss: 0.9607\n",
            "Epoch [2/40], Step [450/1062], TrLoss: 1.6321\n",
            "Epoch [2/40], Step [500/1062], TrLoss: 1.9612\n",
            "Epoch [2/40], Step [550/1062], TrLoss: 1.6942\n",
            "Epoch [2/40], Step [600/1062], TrLoss: 1.3359\n",
            "Epoch [2/40], Step [650/1062], TrLoss: 1.6143\n",
            "Epoch [2/40], Step [700/1062], TrLoss: 1.9142\n",
            "Epoch [2/40], Step [750/1062], TrLoss: 1.1309\n",
            "Epoch [2/40], Step [800/1062], TrLoss: 1.5695\n",
            "Epoch [2/40], Step [850/1062], TrLoss: 1.1543\n",
            "Epoch [2/40], Step [900/1062], TrLoss: 1.1037\n",
            "Epoch [2/40], Step [950/1062], TrLoss: 1.3991\n",
            "Epoch [2/40], Step [1000/1062], TrLoss: 1.6314\n",
            "Epoch [2/40], Step [1050/1062], TrLoss: 1.6278\n",
            "Epoch [3/40], Step [50/1062], TrLoss: 0.6010\n",
            "Epoch [3/40], Step [100/1062], TrLoss: 1.8238\n",
            "Epoch [3/40], Step [150/1062], TrLoss: 0.6673\n",
            "Epoch [3/40], Step [200/1062], TrLoss: 2.0314\n",
            "Epoch [3/40], Step [250/1062], TrLoss: 1.1081\n",
            "Epoch [3/40], Step [300/1062], TrLoss: 1.1906\n",
            "Epoch [3/40], Step [350/1062], TrLoss: 1.1537\n",
            "Epoch [3/40], Step [400/1062], TrLoss: 1.0296\n",
            "Epoch [3/40], Step [450/1062], TrLoss: 1.1616\n",
            "Epoch [3/40], Step [500/1062], TrLoss: 1.1262\n",
            "Epoch [3/40], Step [550/1062], TrLoss: 0.8023\n",
            "Epoch [3/40], Step [600/1062], TrLoss: 0.9786\n",
            "Epoch [3/40], Step [650/1062], TrLoss: 1.2924\n",
            "Epoch [3/40], Step [700/1062], TrLoss: 1.9076\n",
            "Epoch [3/40], Step [750/1062], TrLoss: 1.2300\n",
            "Epoch [3/40], Step [800/1062], TrLoss: 1.3467\n",
            "Epoch [3/40], Step [850/1062], TrLoss: 1.2878\n",
            "Epoch [3/40], Step [900/1062], TrLoss: 1.3968\n",
            "Epoch [3/40], Step [950/1062], TrLoss: 1.3998\n",
            "Epoch [3/40], Step [1000/1062], TrLoss: 1.1026\n",
            "Epoch [3/40], Step [1050/1062], TrLoss: 1.2971\n",
            "Epoch [4/40], Step [50/1062], TrLoss: 0.9058\n",
            "Epoch [4/40], Step [100/1062], TrLoss: 0.5761\n",
            "Epoch [4/40], Step [150/1062], TrLoss: 1.5070\n",
            "Epoch [4/40], Step [200/1062], TrLoss: 1.1835\n",
            "Epoch [4/40], Step [250/1062], TrLoss: 0.9372\n",
            "Epoch [4/40], Step [300/1062], TrLoss: 1.4456\n",
            "Epoch [4/40], Step [350/1062], TrLoss: 1.2582\n",
            "Epoch [4/40], Step [400/1062], TrLoss: 1.1102\n",
            "Epoch [4/40], Step [450/1062], TrLoss: 0.7771\n",
            "Epoch [4/40], Step [500/1062], TrLoss: 0.4969\n",
            "Epoch [4/40], Step [550/1062], TrLoss: 0.6926\n",
            "Epoch [4/40], Step [600/1062], TrLoss: 0.7618\n",
            "Epoch [4/40], Step [650/1062], TrLoss: 1.2110\n",
            "Epoch [4/40], Step [700/1062], TrLoss: 1.4635\n",
            "Epoch [4/40], Step [750/1062], TrLoss: 0.6940\n",
            "Epoch [4/40], Step [800/1062], TrLoss: 1.6725\n",
            "Epoch [4/40], Step [850/1062], TrLoss: 0.7144\n",
            "Epoch [4/40], Step [900/1062], TrLoss: 0.6267\n",
            "Epoch [4/40], Step [950/1062], TrLoss: 0.4804\n",
            "Epoch [4/40], Step [1000/1062], TrLoss: 1.1573\n",
            "Epoch [4/40], Step [1050/1062], TrLoss: 0.6954\n",
            "Epoch [5/40], Step [50/1062], TrLoss: 0.9263\n",
            "Epoch [5/40], Step [100/1062], TrLoss: 0.7775\n",
            "Epoch [5/40], Step [150/1062], TrLoss: 1.2447\n",
            "Epoch [5/40], Step [200/1062], TrLoss: 1.1108\n",
            "Epoch [5/40], Step [250/1062], TrLoss: 1.0443\n",
            "Epoch [5/40], Step [300/1062], TrLoss: 1.0951\n",
            "Epoch [5/40], Step [350/1062], TrLoss: 0.6187\n",
            "Epoch [5/40], Step [400/1062], TrLoss: 1.0790\n",
            "Epoch [5/40], Step [450/1062], TrLoss: 0.6165\n",
            "Epoch [5/40], Step [500/1062], TrLoss: 0.5645\n",
            "Epoch [5/40], Step [550/1062], TrLoss: 0.6521\n",
            "Epoch [5/40], Step [600/1062], TrLoss: 0.7584\n",
            "Epoch [5/40], Step [650/1062], TrLoss: 1.2773\n",
            "Epoch [5/40], Step [700/1062], TrLoss: 0.6590\n",
            "Epoch [5/40], Step [750/1062], TrLoss: 0.7574\n",
            "Epoch [5/40], Step [800/1062], TrLoss: 0.7756\n",
            "Epoch [5/40], Step [850/1062], TrLoss: 0.4165\n",
            "Epoch [5/40], Step [900/1062], TrLoss: 0.7723\n",
            "Epoch [5/40], Step [950/1062], TrLoss: 0.8301\n",
            "Epoch [5/40], Step [1000/1062], TrLoss: 0.7331\n",
            "Epoch [5/40], Step [1050/1062], TrLoss: 0.6960\n",
            "Epoch [6/40], Step [50/1062], TrLoss: 0.6711\n",
            "Epoch [6/40], Step [100/1062], TrLoss: 0.9389\n",
            "Epoch [6/40], Step [150/1062], TrLoss: 0.5746\n",
            "Epoch [6/40], Step [200/1062], TrLoss: 0.8054\n",
            "Epoch [6/40], Step [250/1062], TrLoss: 0.3762\n",
            "Epoch [6/40], Step [300/1062], TrLoss: 0.4309\n",
            "Epoch [6/40], Step [350/1062], TrLoss: 0.7663\n",
            "Epoch [6/40], Step [400/1062], TrLoss: 0.7578\n",
            "Epoch [6/40], Step [450/1062], TrLoss: 0.3636\n",
            "Epoch [6/40], Step [500/1062], TrLoss: 0.6808\n",
            "Epoch [6/40], Step [550/1062], TrLoss: 0.5518\n",
            "Epoch [6/40], Step [600/1062], TrLoss: 0.5661\n",
            "Epoch [6/40], Step [650/1062], TrLoss: 0.3507\n",
            "Epoch [6/40], Step [700/1062], TrLoss: 0.5558\n",
            "Epoch [6/40], Step [750/1062], TrLoss: 0.7072\n",
            "Epoch [6/40], Step [800/1062], TrLoss: 1.4057\n",
            "Epoch [6/40], Step [850/1062], TrLoss: 0.6962\n",
            "Epoch [6/40], Step [900/1062], TrLoss: 0.7077\n",
            "Epoch [6/40], Step [950/1062], TrLoss: 0.6797\n",
            "Epoch [6/40], Step [1000/1062], TrLoss: 0.9045\n",
            "Epoch [6/40], Step [1050/1062], TrLoss: 0.7394\n",
            "Epoch [7/40], Step [50/1062], TrLoss: 1.1241\n",
            "Epoch [7/40], Step [100/1062], TrLoss: 0.7383\n",
            "Epoch [7/40], Step [150/1062], TrLoss: 0.6781\n",
            "Epoch [7/40], Step [200/1062], TrLoss: 0.7105\n",
            "Epoch [7/40], Step [250/1062], TrLoss: 0.2165\n",
            "Epoch [7/40], Step [300/1062], TrLoss: 0.5018\n",
            "Epoch [7/40], Step [350/1062], TrLoss: 0.5519\n",
            "Epoch [7/40], Step [400/1062], TrLoss: 0.7501\n",
            "Epoch [7/40], Step [450/1062], TrLoss: 0.5040\n",
            "Epoch [7/40], Step [500/1062], TrLoss: 0.6576\n",
            "Epoch [7/40], Step [550/1062], TrLoss: 1.2697\n",
            "Epoch [7/40], Step [600/1062], TrLoss: 0.5039\n",
            "Epoch [7/40], Step [650/1062], TrLoss: 0.3270\n",
            "Epoch [7/40], Step [700/1062], TrLoss: 0.7725\n",
            "Epoch [7/40], Step [750/1062], TrLoss: 0.9609\n",
            "Epoch [7/40], Step [800/1062], TrLoss: 0.7763\n",
            "Epoch [7/40], Step [850/1062], TrLoss: 0.6888\n",
            "Epoch [7/40], Step [900/1062], TrLoss: 0.2215\n",
            "Epoch [7/40], Step [950/1062], TrLoss: 0.8475\n",
            "Epoch [7/40], Step [1000/1062], TrLoss: 0.2058\n",
            "Epoch [7/40], Step [1050/1062], TrLoss: 0.6490\n",
            "Epoch [8/40], Step [50/1062], TrLoss: 0.6345\n",
            "Epoch [8/40], Step [100/1062], TrLoss: 0.9059\n",
            "Epoch [8/40], Step [150/1062], TrLoss: 0.7442\n",
            "Epoch [8/40], Step [200/1062], TrLoss: 0.3674\n",
            "Epoch [8/40], Step [250/1062], TrLoss: 0.4239\n",
            "Epoch [8/40], Step [300/1062], TrLoss: 0.3518\n",
            "Epoch [8/40], Step [350/1062], TrLoss: 0.8933\n",
            "Epoch [8/40], Step [400/1062], TrLoss: 0.5359\n",
            "Epoch [8/40], Step [450/1062], TrLoss: 0.5913\n",
            "Epoch [8/40], Step [500/1062], TrLoss: 0.5091\n",
            "Epoch [8/40], Step [550/1062], TrLoss: 0.2630\n",
            "Epoch [8/40], Step [600/1062], TrLoss: 0.1563\n",
            "Epoch [8/40], Step [650/1062], TrLoss: 1.0586\n",
            "Epoch [8/40], Step [700/1062], TrLoss: 0.2161\n",
            "Epoch [8/40], Step [750/1062], TrLoss: 0.1768\n",
            "Epoch [8/40], Step [800/1062], TrLoss: 0.3325\n",
            "Epoch [8/40], Step [850/1062], TrLoss: 0.5285\n",
            "Epoch [8/40], Step [900/1062], TrLoss: 0.6227\n",
            "Epoch [8/40], Step [950/1062], TrLoss: 0.6073\n",
            "Epoch [8/40], Step [1000/1062], TrLoss: 0.4115\n",
            "Epoch [8/40], Step [1050/1062], TrLoss: 0.1988\n",
            "Epoch [9/40], Step [50/1062], TrLoss: 0.7019\n",
            "Epoch [9/40], Step [100/1062], TrLoss: 0.5352\n",
            "Epoch [9/40], Step [150/1062], TrLoss: 0.3247\n",
            "Epoch [9/40], Step [200/1062], TrLoss: 0.2749\n",
            "Epoch [9/40], Step [250/1062], TrLoss: 0.6656\n",
            "Epoch [9/40], Step [300/1062], TrLoss: 0.6924\n",
            "Epoch [9/40], Step [350/1062], TrLoss: 0.3866\n",
            "Epoch [9/40], Step [400/1062], TrLoss: 0.9252\n",
            "Epoch [9/40], Step [450/1062], TrLoss: 0.3798\n",
            "Epoch [9/40], Step [500/1062], TrLoss: 0.4902\n",
            "Epoch [9/40], Step [550/1062], TrLoss: 0.2823\n",
            "Epoch [9/40], Step [600/1062], TrLoss: 0.5431\n",
            "Epoch [9/40], Step [650/1062], TrLoss: 0.1464\n",
            "Epoch [9/40], Step [700/1062], TrLoss: 0.3262\n",
            "Epoch [9/40], Step [750/1062], TrLoss: 0.2279\n",
            "Epoch [9/40], Step [800/1062], TrLoss: 0.3314\n",
            "Epoch [9/40], Step [850/1062], TrLoss: 0.7676\n",
            "Epoch [9/40], Step [900/1062], TrLoss: 0.6768\n",
            "Epoch [9/40], Step [950/1062], TrLoss: 0.5390\n",
            "Epoch [9/40], Step [1000/1062], TrLoss: 0.2015\n",
            "Epoch [9/40], Step [1050/1062], TrLoss: 0.2340\n",
            "Epoch [10/40], Step [50/1062], TrLoss: 0.1058\n",
            "Epoch [10/40], Step [100/1062], TrLoss: 1.0728\n",
            "Epoch [10/40], Step [150/1062], TrLoss: 0.2715\n",
            "Epoch [10/40], Step [200/1062], TrLoss: 0.3828\n",
            "Epoch [10/40], Step [250/1062], TrLoss: 0.3717\n",
            "Epoch [10/40], Step [300/1062], TrLoss: 0.1027\n",
            "Epoch [10/40], Step [350/1062], TrLoss: 0.4205\n",
            "Epoch [10/40], Step [400/1062], TrLoss: 0.5115\n",
            "Epoch [10/40], Step [450/1062], TrLoss: 0.5777\n",
            "Epoch [10/40], Step [500/1062], TrLoss: 0.9619\n",
            "Epoch [10/40], Step [550/1062], TrLoss: 0.3680\n",
            "Epoch [10/40], Step [600/1062], TrLoss: 0.7092\n",
            "Epoch [10/40], Step [650/1062], TrLoss: 0.7969\n",
            "Epoch [10/40], Step [700/1062], TrLoss: 0.6406\n",
            "Epoch [10/40], Step [750/1062], TrLoss: 0.9377\n",
            "Epoch [10/40], Step [800/1062], TrLoss: 0.5735\n",
            "Epoch [10/40], Step [850/1062], TrLoss: 0.4552\n",
            "Epoch [10/40], Step [900/1062], TrLoss: 0.1029\n",
            "Epoch [10/40], Step [950/1062], TrLoss: 0.4320\n",
            "Epoch [10/40], Step [1000/1062], TrLoss: 0.4414\n",
            "Epoch [10/40], Step [1050/1062], TrLoss: 0.4094\n",
            "Epoch [11/40], Step [50/1062], TrLoss: 0.2072\n",
            "Epoch [11/40], Step [100/1062], TrLoss: 0.3246\n",
            "Epoch [11/40], Step [150/1062], TrLoss: 0.2329\n",
            "Epoch [11/40], Step [200/1062], TrLoss: 0.3203\n",
            "Epoch [11/40], Step [250/1062], TrLoss: 0.4529\n",
            "Epoch [11/40], Step [300/1062], TrLoss: 0.3425\n",
            "Epoch [11/40], Step [350/1062], TrLoss: 0.1248\n",
            "Epoch [11/40], Step [400/1062], TrLoss: 0.2396\n",
            "Epoch [11/40], Step [450/1062], TrLoss: 0.2286\n",
            "Epoch [11/40], Step [500/1062], TrLoss: 0.6452\n",
            "Epoch [11/40], Step [550/1062], TrLoss: 0.3072\n",
            "Epoch [11/40], Step [600/1062], TrLoss: 0.7206\n",
            "Epoch [11/40], Step [650/1062], TrLoss: 0.6459\n",
            "Epoch [11/40], Step [700/1062], TrLoss: 0.3055\n",
            "Epoch [11/40], Step [750/1062], TrLoss: 0.2885\n",
            "Epoch [11/40], Step [800/1062], TrLoss: 0.2991\n",
            "Epoch [11/40], Step [850/1062], TrLoss: 0.8607\n",
            "Epoch [11/40], Step [900/1062], TrLoss: 0.6336\n",
            "Epoch [11/40], Step [950/1062], TrLoss: 0.1316\n",
            "Epoch [11/40], Step [1000/1062], TrLoss: 0.2755\n",
            "Epoch [11/40], Step [1050/1062], TrLoss: 0.8077\n",
            "Epoch [12/40], Step [50/1062], TrLoss: 0.0766\n",
            "Epoch [12/40], Step [100/1062], TrLoss: 0.4826\n",
            "Epoch [12/40], Step [150/1062], TrLoss: 0.2277\n",
            "Epoch [12/40], Step [200/1062], TrLoss: 0.4586\n",
            "Epoch [12/40], Step [250/1062], TrLoss: 0.2505\n",
            "Epoch [12/40], Step [300/1062], TrLoss: 0.2559\n",
            "Epoch [12/40], Step [350/1062], TrLoss: 0.4617\n",
            "Epoch [12/40], Step [400/1062], TrLoss: 0.5842\n",
            "Epoch [12/40], Step [450/1062], TrLoss: 0.7027\n",
            "Epoch [12/40], Step [500/1062], TrLoss: 0.2160\n",
            "Epoch [12/40], Step [550/1062], TrLoss: 0.4448\n",
            "Epoch [12/40], Step [600/1062], TrLoss: 0.3951\n",
            "Epoch [12/40], Step [650/1062], TrLoss: 0.1696\n",
            "Epoch [12/40], Step [700/1062], TrLoss: 0.5985\n",
            "Epoch [12/40], Step [750/1062], TrLoss: 0.7644\n",
            "Epoch [12/40], Step [800/1062], TrLoss: 0.7983\n",
            "Epoch [12/40], Step [850/1062], TrLoss: 0.1613\n",
            "Epoch [12/40], Step [900/1062], TrLoss: 0.2933\n",
            "Epoch [12/40], Step [950/1062], TrLoss: 0.2570\n",
            "Epoch [12/40], Step [1000/1062], TrLoss: 0.4059\n",
            "Epoch [12/40], Step [1050/1062], TrLoss: 0.3239\n",
            "Epoch [13/40], Step [50/1062], TrLoss: 0.1140\n",
            "Epoch [13/40], Step [100/1062], TrLoss: 0.4716\n",
            "Epoch [13/40], Step [150/1062], TrLoss: 0.3939\n",
            "Epoch [13/40], Step [200/1062], TrLoss: 0.1173\n",
            "Epoch [13/40], Step [250/1062], TrLoss: 0.1596\n",
            "Epoch [13/40], Step [300/1062], TrLoss: 0.9806\n",
            "Epoch [13/40], Step [350/1062], TrLoss: 0.4991\n",
            "Epoch [13/40], Step [400/1062], TrLoss: 0.4843\n",
            "Epoch [13/40], Step [450/1062], TrLoss: 0.5744\n",
            "Epoch [13/40], Step [500/1062], TrLoss: 0.2957\n",
            "Epoch [13/40], Step [550/1062], TrLoss: 0.1541\n",
            "Epoch [13/40], Step [600/1062], TrLoss: 0.3275\n",
            "Epoch [13/40], Step [650/1062], TrLoss: 0.3978\n",
            "Epoch [13/40], Step [700/1062], TrLoss: 0.1706\n",
            "Epoch [13/40], Step [750/1062], TrLoss: 0.2175\n",
            "Epoch [13/40], Step [800/1062], TrLoss: 0.1788\n",
            "Epoch [13/40], Step [850/1062], TrLoss: 0.5168\n",
            "Epoch [13/40], Step [900/1062], TrLoss: 0.3693\n",
            "Epoch [13/40], Step [950/1062], TrLoss: 0.5595\n",
            "Epoch [13/40], Step [1000/1062], TrLoss: 0.1310\n",
            "Epoch [13/40], Step [1050/1062], TrLoss: 0.2073\n",
            "Epoch [14/40], Step [50/1062], TrLoss: 0.2034\n",
            "Epoch [14/40], Step [100/1062], TrLoss: 0.6151\n",
            "Epoch [14/40], Step [150/1062], TrLoss: 0.4419\n",
            "Epoch [14/40], Step [200/1062], TrLoss: 0.0946\n",
            "Epoch [14/40], Step [250/1062], TrLoss: 0.1594\n",
            "Epoch [14/40], Step [300/1062], TrLoss: 0.2324\n",
            "Epoch [14/40], Step [350/1062], TrLoss: 0.1705\n",
            "Epoch [14/40], Step [400/1062], TrLoss: 0.8920\n",
            "Epoch [14/40], Step [450/1062], TrLoss: 0.2738\n",
            "Epoch [14/40], Step [500/1062], TrLoss: 0.0738\n",
            "Epoch [14/40], Step [550/1062], TrLoss: 0.3631\n",
            "Epoch [14/40], Step [600/1062], TrLoss: 0.8716\n",
            "Epoch [14/40], Step [650/1062], TrLoss: 1.0056\n",
            "Epoch [14/40], Step [700/1062], TrLoss: 0.2578\n",
            "Epoch [14/40], Step [750/1062], TrLoss: 0.3878\n",
            "Epoch [14/40], Step [800/1062], TrLoss: 0.5827\n",
            "Epoch [14/40], Step [850/1062], TrLoss: 0.4444\n",
            "Epoch [14/40], Step [900/1062], TrLoss: 0.2837\n",
            "Epoch [14/40], Step [950/1062], TrLoss: 1.1031\n",
            "Epoch [14/40], Step [1000/1062], TrLoss: 0.2922\n",
            "Epoch [14/40], Step [1050/1062], TrLoss: 0.7718\n",
            "Epoch [15/40], Step [50/1062], TrLoss: 0.3960\n",
            "Epoch [15/40], Step [100/1062], TrLoss: 0.3585\n",
            "Epoch [15/40], Step [150/1062], TrLoss: 0.1392\n",
            "Epoch [15/40], Step [200/1062], TrLoss: 0.5292\n",
            "Epoch [15/40], Step [250/1062], TrLoss: 0.2375\n",
            "Epoch [15/40], Step [300/1062], TrLoss: 0.1881\n",
            "Epoch [15/40], Step [350/1062], TrLoss: 0.0717\n",
            "Epoch [15/40], Step [400/1062], TrLoss: 0.1639\n",
            "Epoch [15/40], Step [450/1062], TrLoss: 0.3091\n",
            "Epoch [15/40], Step [500/1062], TrLoss: 0.5507\n",
            "Epoch [15/40], Step [550/1062], TrLoss: 0.7202\n",
            "Epoch [15/40], Step [600/1062], TrLoss: 0.2296\n",
            "Epoch [15/40], Step [650/1062], TrLoss: 0.3305\n",
            "Epoch [15/40], Step [700/1062], TrLoss: 0.4022\n",
            "Epoch [15/40], Step [750/1062], TrLoss: 0.2079\n",
            "Epoch [15/40], Step [800/1062], TrLoss: 1.6801\n",
            "Epoch [15/40], Step [850/1062], TrLoss: 0.1601\n",
            "Epoch [15/40], Step [900/1062], TrLoss: 0.0880\n",
            "Epoch [15/40], Step [950/1062], TrLoss: 0.2022\n",
            "Epoch [15/40], Step [1000/1062], TrLoss: 0.4109\n",
            "Epoch [15/40], Step [1050/1062], TrLoss: 0.3326\n",
            "Epoch [16/40], Step [50/1062], TrLoss: 0.3386\n",
            "Epoch [16/40], Step [100/1062], TrLoss: 0.0743\n",
            "Epoch [16/40], Step [150/1062], TrLoss: 0.2843\n",
            "Epoch [16/40], Step [200/1062], TrLoss: 0.5827\n",
            "Epoch [16/40], Step [250/1062], TrLoss: 0.0505\n",
            "Epoch [16/40], Step [300/1062], TrLoss: 0.0654\n",
            "Epoch [16/40], Step [350/1062], TrLoss: 0.1973\n",
            "Epoch [16/40], Step [400/1062], TrLoss: 0.2977\n",
            "Epoch [16/40], Step [450/1062], TrLoss: 0.2024\n",
            "Epoch [16/40], Step [500/1062], TrLoss: 0.4715\n",
            "Epoch [16/40], Step [550/1062], TrLoss: 0.3097\n",
            "Epoch [16/40], Step [600/1062], TrLoss: 0.5145\n",
            "Epoch [16/40], Step [650/1062], TrLoss: 0.3310\n",
            "Epoch [16/40], Step [700/1062], TrLoss: 0.6118\n",
            "Epoch [16/40], Step [750/1062], TrLoss: 0.2943\n",
            "Epoch [16/40], Step [800/1062], TrLoss: 0.3160\n",
            "Epoch [16/40], Step [850/1062], TrLoss: 0.0903\n",
            "Epoch [16/40], Step [900/1062], TrLoss: 0.4601\n",
            "Epoch [16/40], Step [950/1062], TrLoss: 0.1239\n",
            "Epoch [16/40], Step [1000/1062], TrLoss: 0.3819\n",
            "Epoch [16/40], Step [1050/1062], TrLoss: 0.4998\n",
            "Epoch [17/40], Step [50/1062], TrLoss: 0.3413\n",
            "Epoch [17/40], Step [100/1062], TrLoss: 0.0971\n",
            "Epoch [17/40], Step [150/1062], TrLoss: 0.4582\n",
            "Epoch [17/40], Step [200/1062], TrLoss: 0.2909\n",
            "Epoch [17/40], Step [250/1062], TrLoss: 0.8033\n",
            "Epoch [17/40], Step [300/1062], TrLoss: 0.4372\n",
            "Epoch [17/40], Step [350/1062], TrLoss: 0.3594\n",
            "Epoch [17/40], Step [400/1062], TrLoss: 0.1711\n",
            "Epoch [17/40], Step [450/1062], TrLoss: 0.3338\n",
            "Epoch [17/40], Step [500/1062], TrLoss: 0.6522\n",
            "Epoch [17/40], Step [550/1062], TrLoss: 0.5508\n",
            "Epoch [17/40], Step [600/1062], TrLoss: 0.0984\n",
            "Epoch [17/40], Step [650/1062], TrLoss: 0.3018\n",
            "Epoch [17/40], Step [700/1062], TrLoss: 0.7478\n",
            "Epoch [17/40], Step [750/1062], TrLoss: 0.2885\n",
            "Epoch [17/40], Step [800/1062], TrLoss: 0.2215\n",
            "Epoch [17/40], Step [850/1062], TrLoss: 0.4823\n",
            "Epoch [17/40], Step [900/1062], TrLoss: 0.3180\n",
            "Epoch [17/40], Step [950/1062], TrLoss: 0.4512\n",
            "Epoch [17/40], Step [1000/1062], TrLoss: 0.9868\n",
            "Epoch [17/40], Step [1050/1062], TrLoss: 0.3511\n",
            "Epoch [18/40], Step [50/1062], TrLoss: 0.1667\n",
            "Epoch [18/40], Step [100/1062], TrLoss: 0.1548\n",
            "Epoch [18/40], Step [150/1062], TrLoss: 0.3052\n",
            "Epoch [18/40], Step [200/1062], TrLoss: 0.1147\n",
            "Epoch [18/40], Step [250/1062], TrLoss: 0.3636\n",
            "Epoch [18/40], Step [300/1062], TrLoss: 0.1350\n",
            "Epoch [18/40], Step [350/1062], TrLoss: 0.2456\n",
            "Epoch [18/40], Step [400/1062], TrLoss: 0.0808\n",
            "Epoch [18/40], Step [450/1062], TrLoss: 0.1503\n",
            "Epoch [18/40], Step [500/1062], TrLoss: 0.2396\n",
            "Epoch [18/40], Step [550/1062], TrLoss: 0.1012\n",
            "Epoch [18/40], Step [600/1062], TrLoss: 0.0809\n",
            "Epoch [18/40], Step [650/1062], TrLoss: 0.3773\n",
            "Epoch [18/40], Step [700/1062], TrLoss: 0.2162\n",
            "Epoch [18/40], Step [750/1062], TrLoss: 0.3037\n",
            "Epoch [18/40], Step [800/1062], TrLoss: 0.1439\n",
            "Epoch [18/40], Step [850/1062], TrLoss: 0.1383\n",
            "Epoch [18/40], Step [900/1062], TrLoss: 0.0614\n",
            "Epoch [18/40], Step [950/1062], TrLoss: 0.2818\n",
            "Epoch [18/40], Step [1000/1062], TrLoss: 0.2960\n",
            "Epoch [18/40], Step [1050/1062], TrLoss: 0.1099\n",
            "Epoch [19/40], Step [50/1062], TrLoss: 0.0787\n",
            "Epoch [19/40], Step [100/1062], TrLoss: 0.4895\n",
            "Epoch [19/40], Step [150/1062], TrLoss: 0.1027\n",
            "Epoch [19/40], Step [200/1062], TrLoss: 0.1308\n",
            "Epoch [19/40], Step [250/1062], TrLoss: 0.2902\n",
            "Epoch [19/40], Step [300/1062], TrLoss: 0.3565\n",
            "Epoch [19/40], Step [350/1062], TrLoss: 0.3591\n",
            "Epoch [19/40], Step [400/1062], TrLoss: 0.3093\n",
            "Epoch [19/40], Step [450/1062], TrLoss: 0.2406\n",
            "Epoch [19/40], Step [500/1062], TrLoss: 0.4750\n",
            "Epoch [19/40], Step [550/1062], TrLoss: 0.3535\n",
            "Epoch [19/40], Step [600/1062], TrLoss: 0.6996\n",
            "Epoch [19/40], Step [650/1062], TrLoss: 0.1316\n",
            "Epoch [19/40], Step [700/1062], TrLoss: 0.1922\n",
            "Epoch [19/40], Step [750/1062], TrLoss: 0.1177\n",
            "Epoch [19/40], Step [800/1062], TrLoss: 0.2928\n",
            "Epoch [19/40], Step [850/1062], TrLoss: 0.0358\n",
            "Epoch [19/40], Step [900/1062], TrLoss: 0.1267\n",
            "Epoch [19/40], Step [950/1062], TrLoss: 0.0794\n",
            "Epoch [19/40], Step [1000/1062], TrLoss: 0.1286\n",
            "Epoch [19/40], Step [1050/1062], TrLoss: 0.3280\n",
            "Epoch [20/40], Step [50/1062], TrLoss: 0.3864\n",
            "Epoch [20/40], Step [100/1062], TrLoss: 0.1878\n",
            "Epoch [20/40], Step [150/1062], TrLoss: 0.1176\n",
            "Epoch [20/40], Step [200/1062], TrLoss: 0.1662\n",
            "Epoch [20/40], Step [250/1062], TrLoss: 0.2161\n",
            "Epoch [20/40], Step [300/1062], TrLoss: 0.6383\n",
            "Epoch [20/40], Step [350/1062], TrLoss: 0.5308\n",
            "Epoch [20/40], Step [400/1062], TrLoss: 0.0944\n",
            "Epoch [20/40], Step [450/1062], TrLoss: 0.1897\n",
            "Epoch [20/40], Step [500/1062], TrLoss: 0.1424\n",
            "Epoch [20/40], Step [550/1062], TrLoss: 0.0927\n",
            "Epoch [20/40], Step [600/1062], TrLoss: 0.2851\n",
            "Epoch [20/40], Step [650/1062], TrLoss: 0.1571\n",
            "Epoch [20/40], Step [700/1062], TrLoss: 0.1411\n",
            "Epoch [20/40], Step [750/1062], TrLoss: 0.0896\n",
            "Epoch [20/40], Step [800/1062], TrLoss: 0.1238\n",
            "Epoch [20/40], Step [850/1062], TrLoss: 0.2024\n",
            "Epoch [20/40], Step [900/1062], TrLoss: 0.4022\n",
            "Epoch [20/40], Step [950/1062], TrLoss: 0.0326\n",
            "Epoch [20/40], Step [1000/1062], TrLoss: 0.1844\n",
            "Epoch [20/40], Step [1050/1062], TrLoss: 0.1056\n",
            "Epoch [21/40], Step [50/1062], TrLoss: 0.0196\n",
            "Epoch [21/40], Step [100/1062], TrLoss: 0.2511\n",
            "Epoch [21/40], Step [150/1062], TrLoss: 0.0240\n",
            "Epoch [21/40], Step [200/1062], TrLoss: 0.0185\n",
            "Epoch [21/40], Step [250/1062], TrLoss: 0.0942\n",
            "Epoch [21/40], Step [300/1062], TrLoss: 0.0474\n",
            "Epoch [21/40], Step [350/1062], TrLoss: 0.2656\n",
            "Epoch [21/40], Step [400/1062], TrLoss: 0.2277\n",
            "Epoch [21/40], Step [450/1062], TrLoss: 0.0233\n",
            "Epoch [21/40], Step [500/1062], TrLoss: 0.0754\n",
            "Epoch [21/40], Step [550/1062], TrLoss: 0.0806\n",
            "Epoch [21/40], Step [600/1062], TrLoss: 0.4931\n",
            "Epoch [21/40], Step [650/1062], TrLoss: 0.2347\n",
            "Epoch [21/40], Step [700/1062], TrLoss: 0.4787\n",
            "Epoch [21/40], Step [750/1062], TrLoss: 0.0360\n",
            "Epoch [21/40], Step [800/1062], TrLoss: 0.0851\n",
            "Epoch [21/40], Step [850/1062], TrLoss: 0.0357\n",
            "Epoch [21/40], Step [900/1062], TrLoss: 0.1559\n",
            "Epoch [21/40], Step [950/1062], TrLoss: 0.2853\n",
            "Epoch [21/40], Step [1000/1062], TrLoss: 0.2005\n",
            "Epoch [21/40], Step [1050/1062], TrLoss: 0.0498\n",
            "Epoch [22/40], Step [50/1062], TrLoss: 0.0802\n",
            "Epoch [22/40], Step [100/1062], TrLoss: 0.1112\n",
            "Epoch [22/40], Step [150/1062], TrLoss: 0.1566\n",
            "Epoch [22/40], Step [200/1062], TrLoss: 0.1676\n",
            "Epoch [22/40], Step [250/1062], TrLoss: 0.0558\n",
            "Epoch [22/40], Step [300/1062], TrLoss: 0.2607\n",
            "Epoch [22/40], Step [350/1062], TrLoss: 0.1615\n",
            "Epoch [22/40], Step [400/1062], TrLoss: 0.0217\n",
            "Epoch [22/40], Step [450/1062], TrLoss: 0.1513\n",
            "Epoch [22/40], Step [500/1062], TrLoss: 0.0394\n",
            "Epoch [22/40], Step [550/1062], TrLoss: 0.3082\n",
            "Epoch [22/40], Step [600/1062], TrLoss: 0.0638\n",
            "Epoch [22/40], Step [650/1062], TrLoss: 0.1841\n",
            "Epoch [22/40], Step [700/1062], TrLoss: 0.2796\n",
            "Epoch [22/40], Step [750/1062], TrLoss: 0.1776\n",
            "Epoch [22/40], Step [800/1062], TrLoss: 0.1294\n",
            "Epoch [22/40], Step [850/1062], TrLoss: 0.0564\n",
            "Epoch [22/40], Step [900/1062], TrLoss: 0.0590\n",
            "Epoch [22/40], Step [950/1062], TrLoss: 0.1348\n",
            "Epoch [22/40], Step [1000/1062], TrLoss: 0.2708\n",
            "Epoch [22/40], Step [1050/1062], TrLoss: 0.0703\n",
            "Epoch [23/40], Step [50/1062], TrLoss: 0.1768\n",
            "Epoch [23/40], Step [100/1062], TrLoss: 0.1585\n",
            "Epoch [23/40], Step [150/1062], TrLoss: 0.1136\n",
            "Epoch [23/40], Step [200/1062], TrLoss: 0.0156\n",
            "Epoch [23/40], Step [250/1062], TrLoss: 0.1482\n",
            "Epoch [23/40], Step [300/1062], TrLoss: 0.1653\n",
            "Epoch [23/40], Step [350/1062], TrLoss: 0.1684\n",
            "Epoch [23/40], Step [400/1062], TrLoss: 0.2490\n",
            "Epoch [23/40], Step [450/1062], TrLoss: 0.2207\n",
            "Epoch [23/40], Step [500/1062], TrLoss: 0.0292\n",
            "Epoch [23/40], Step [550/1062], TrLoss: 0.1559\n",
            "Epoch [23/40], Step [600/1062], TrLoss: 0.0237\n",
            "Epoch [23/40], Step [650/1062], TrLoss: 0.0740\n",
            "Epoch [23/40], Step [700/1062], TrLoss: 0.2569\n",
            "Epoch [23/40], Step [750/1062], TrLoss: 0.0666\n",
            "Epoch [23/40], Step [800/1062], TrLoss: 0.0485\n",
            "Epoch [23/40], Step [850/1062], TrLoss: 0.2718\n",
            "Epoch [23/40], Step [900/1062], TrLoss: 0.3149\n",
            "Epoch [23/40], Step [950/1062], TrLoss: 0.1745\n",
            "Epoch [23/40], Step [1000/1062], TrLoss: 0.2260\n",
            "Epoch [23/40], Step [1050/1062], TrLoss: 0.1650\n",
            "Epoch [24/40], Step [50/1062], TrLoss: 0.0956\n",
            "Epoch [24/40], Step [100/1062], TrLoss: 0.3049\n",
            "Epoch [24/40], Step [150/1062], TrLoss: 0.0396\n",
            "Epoch [24/40], Step [200/1062], TrLoss: 0.1150\n",
            "Epoch [24/40], Step [250/1062], TrLoss: 0.0634\n",
            "Epoch [24/40], Step [300/1062], TrLoss: 0.1521\n",
            "Epoch [24/40], Step [350/1062], TrLoss: 0.0757\n",
            "Epoch [24/40], Step [400/1062], TrLoss: 0.0730\n",
            "Epoch [24/40], Step [450/1062], TrLoss: 0.2862\n",
            "Epoch [24/40], Step [500/1062], TrLoss: 0.0803\n",
            "Epoch [24/40], Step [550/1062], TrLoss: 0.0620\n",
            "Epoch [24/40], Step [600/1062], TrLoss: 0.2515\n",
            "Epoch [24/40], Step [650/1062], TrLoss: 0.0509\n",
            "Epoch [24/40], Step [700/1062], TrLoss: 0.2386\n",
            "Epoch [24/40], Step [750/1062], TrLoss: 0.2400\n",
            "Epoch [24/40], Step [800/1062], TrLoss: 0.1019\n",
            "Epoch [24/40], Step [850/1062], TrLoss: 0.3644\n",
            "Epoch [24/40], Step [900/1062], TrLoss: 0.4697\n",
            "Epoch [24/40], Step [950/1062], TrLoss: 0.2471\n",
            "Epoch [24/40], Step [1000/1062], TrLoss: 0.1373\n",
            "Epoch [24/40], Step [1050/1062], TrLoss: 0.0578\n",
            "Epoch [25/40], Step [50/1062], TrLoss: 0.2082\n",
            "Epoch [25/40], Step [100/1062], TrLoss: 0.1160\n",
            "Epoch [25/40], Step [150/1062], TrLoss: 0.2771\n",
            "Epoch [25/40], Step [200/1062], TrLoss: 0.1703\n",
            "Epoch [25/40], Step [250/1062], TrLoss: 0.1415\n",
            "Epoch [25/40], Step [300/1062], TrLoss: 0.1342\n",
            "Epoch [25/40], Step [350/1062], TrLoss: 0.2064\n",
            "Epoch [25/40], Step [400/1062], TrLoss: 0.0955\n",
            "Epoch [25/40], Step [450/1062], TrLoss: 0.1270\n",
            "Epoch [25/40], Step [500/1062], TrLoss: 0.1238\n",
            "Epoch [25/40], Step [550/1062], TrLoss: 0.0542\n",
            "Epoch [25/40], Step [600/1062], TrLoss: 0.2017\n",
            "Epoch [25/40], Step [650/1062], TrLoss: 0.0299\n",
            "Epoch [25/40], Step [700/1062], TrLoss: 0.0491\n",
            "Epoch [25/40], Step [750/1062], TrLoss: 0.1177\n",
            "Epoch [25/40], Step [800/1062], TrLoss: 0.1184\n",
            "Epoch [25/40], Step [850/1062], TrLoss: 0.0792\n",
            "Epoch [25/40], Step [900/1062], TrLoss: 0.0488\n",
            "Epoch [25/40], Step [950/1062], TrLoss: 0.4357\n",
            "Epoch [25/40], Step [1000/1062], TrLoss: 0.1964\n",
            "Epoch [25/40], Step [1050/1062], TrLoss: 0.0676\n",
            "Epoch [26/40], Step [50/1062], TrLoss: 0.1165\n",
            "Epoch [26/40], Step [100/1062], TrLoss: 0.0718\n",
            "Epoch [26/40], Step [150/1062], TrLoss: 0.0535\n",
            "Epoch [26/40], Step [200/1062], TrLoss: 0.0833\n",
            "Epoch [26/40], Step [250/1062], TrLoss: 0.1982\n",
            "Epoch [26/40], Step [300/1062], TrLoss: 0.3260\n",
            "Epoch [26/40], Step [350/1062], TrLoss: 0.2876\n",
            "Epoch [26/40], Step [400/1062], TrLoss: 0.0649\n",
            "Epoch [26/40], Step [450/1062], TrLoss: 0.1399\n",
            "Epoch [26/40], Step [500/1062], TrLoss: 0.0765\n",
            "Epoch [26/40], Step [550/1062], TrLoss: 0.3462\n",
            "Epoch [26/40], Step [600/1062], TrLoss: 0.0964\n",
            "Epoch [26/40], Step [650/1062], TrLoss: 0.0179\n",
            "Epoch [26/40], Step [700/1062], TrLoss: 0.1146\n",
            "Epoch [26/40], Step [750/1062], TrLoss: 0.1119\n",
            "Epoch [26/40], Step [800/1062], TrLoss: 0.2397\n",
            "Epoch [26/40], Step [850/1062], TrLoss: 0.3610\n",
            "Epoch [26/40], Step [900/1062], TrLoss: 0.1226\n",
            "Epoch [26/40], Step [950/1062], TrLoss: 0.0526\n",
            "Epoch [26/40], Step [1000/1062], TrLoss: 0.0645\n",
            "Epoch [26/40], Step [1050/1062], TrLoss: 0.1613\n",
            "Epoch [27/40], Step [50/1062], TrLoss: 0.2083\n",
            "Epoch [27/40], Step [100/1062], TrLoss: 0.0830\n",
            "Epoch [27/40], Step [150/1062], TrLoss: 0.1241\n",
            "Epoch [27/40], Step [200/1062], TrLoss: 0.0547\n",
            "Epoch [27/40], Step [250/1062], TrLoss: 0.0893\n",
            "Epoch [27/40], Step [300/1062], TrLoss: 0.0669\n",
            "Epoch [27/40], Step [350/1062], TrLoss: 0.0592\n",
            "Epoch [27/40], Step [400/1062], TrLoss: 0.1156\n",
            "Epoch [27/40], Step [450/1062], TrLoss: 0.1985\n",
            "Epoch [27/40], Step [500/1062], TrLoss: 0.1147\n",
            "Epoch [27/40], Step [550/1062], TrLoss: 0.1788\n",
            "Epoch [27/40], Step [600/1062], TrLoss: 0.1307\n",
            "Epoch [27/40], Step [650/1062], TrLoss: 0.0952\n",
            "Epoch [27/40], Step [700/1062], TrLoss: 0.0229\n",
            "Epoch [27/40], Step [750/1062], TrLoss: 0.0918\n",
            "Epoch [27/40], Step [800/1062], TrLoss: 0.1176\n",
            "Epoch [27/40], Step [850/1062], TrLoss: 0.0670\n",
            "Epoch [27/40], Step [900/1062], TrLoss: 0.1162\n",
            "Epoch [27/40], Step [950/1062], TrLoss: 0.1909\n",
            "Epoch [27/40], Step [1000/1062], TrLoss: 0.0704\n",
            "Epoch [27/40], Step [1050/1062], TrLoss: 0.2278\n",
            "Epoch [28/40], Step [50/1062], TrLoss: 0.1972\n",
            "Epoch [28/40], Step [100/1062], TrLoss: 0.0886\n",
            "Epoch [28/40], Step [150/1062], TrLoss: 0.1529\n",
            "Epoch [28/40], Step [200/1062], TrLoss: 0.0400\n",
            "Epoch [28/40], Step [250/1062], TrLoss: 0.1303\n",
            "Epoch [28/40], Step [300/1062], TrLoss: 0.0299\n",
            "Epoch [28/40], Step [350/1062], TrLoss: 0.3129\n",
            "Epoch [28/40], Step [400/1062], TrLoss: 0.1926\n",
            "Epoch [28/40], Step [450/1062], TrLoss: 0.0874\n",
            "Epoch [28/40], Step [500/1062], TrLoss: 0.1985\n",
            "Epoch [28/40], Step [550/1062], TrLoss: 0.0459\n",
            "Epoch [28/40], Step [600/1062], TrLoss: 0.0105\n",
            "Epoch [28/40], Step [650/1062], TrLoss: 0.1278\n",
            "Epoch [28/40], Step [700/1062], TrLoss: 0.0550\n",
            "Epoch [28/40], Step [750/1062], TrLoss: 0.1989\n",
            "Epoch [28/40], Step [800/1062], TrLoss: 0.0088\n",
            "Epoch [28/40], Step [850/1062], TrLoss: 0.0250\n",
            "Epoch [28/40], Step [900/1062], TrLoss: 0.2042\n",
            "Epoch [28/40], Step [950/1062], TrLoss: 0.0402\n",
            "Epoch [28/40], Step [1000/1062], TrLoss: 0.2560\n",
            "Epoch [28/40], Step [1050/1062], TrLoss: 0.1154\n",
            "Epoch [29/40], Step [50/1062], TrLoss: 0.0842\n",
            "Epoch [29/40], Step [100/1062], TrLoss: 0.0303\n",
            "Epoch [29/40], Step [150/1062], TrLoss: 0.0236\n",
            "Epoch [29/40], Step [200/1062], TrLoss: 0.0444\n",
            "Epoch [29/40], Step [250/1062], TrLoss: 0.0456\n",
            "Epoch [29/40], Step [300/1062], TrLoss: 0.0483\n",
            "Epoch [29/40], Step [350/1062], TrLoss: 0.1734\n",
            "Epoch [29/40], Step [400/1062], TrLoss: 0.0331\n",
            "Epoch [29/40], Step [450/1062], TrLoss: 0.1021\n",
            "Epoch [29/40], Step [500/1062], TrLoss: 0.1320\n",
            "Epoch [29/40], Step [550/1062], TrLoss: 0.0571\n",
            "Epoch [29/40], Step [600/1062], TrLoss: 0.0433\n",
            "Epoch [29/40], Step [650/1062], TrLoss: 0.1085\n",
            "Epoch [29/40], Step [700/1062], TrLoss: 0.0255\n",
            "Epoch [29/40], Step [750/1062], TrLoss: 0.1090\n",
            "Epoch [29/40], Step [800/1062], TrLoss: 0.0486\n",
            "Epoch [29/40], Step [850/1062], TrLoss: 0.2623\n",
            "Epoch [29/40], Step [900/1062], TrLoss: 0.0681\n",
            "Epoch [29/40], Step [950/1062], TrLoss: 0.0990\n",
            "Epoch [29/40], Step [1000/1062], TrLoss: 0.1056\n",
            "Epoch [29/40], Step [1050/1062], TrLoss: 0.0944\n",
            "Epoch [30/40], Step [50/1062], TrLoss: 0.0389\n",
            "Epoch [30/40], Step [100/1062], TrLoss: 0.0307\n",
            "Epoch [30/40], Step [150/1062], TrLoss: 0.0416\n",
            "Epoch [30/40], Step [200/1062], TrLoss: 0.0339\n",
            "Epoch [30/40], Step [250/1062], TrLoss: 0.0235\n",
            "Epoch [30/40], Step [300/1062], TrLoss: 0.0282\n",
            "Epoch [30/40], Step [350/1062], TrLoss: 0.0637\n",
            "Epoch [30/40], Step [400/1062], TrLoss: 0.0388\n",
            "Epoch [30/40], Step [450/1062], TrLoss: 0.0445\n",
            "Epoch [30/40], Step [500/1062], TrLoss: 0.0137\n",
            "Epoch [30/40], Step [550/1062], TrLoss: 0.0219\n",
            "Epoch [30/40], Step [600/1062], TrLoss: 0.0400\n",
            "Epoch [30/40], Step [650/1062], TrLoss: 0.0920\n",
            "Epoch [30/40], Step [700/1062], TrLoss: 0.0901\n",
            "Epoch [30/40], Step [750/1062], TrLoss: 0.0429\n",
            "Epoch [30/40], Step [800/1062], TrLoss: 0.2081\n",
            "Epoch [30/40], Step [850/1062], TrLoss: 0.2370\n",
            "Epoch [30/40], Step [900/1062], TrLoss: 0.1390\n",
            "Epoch [30/40], Step [950/1062], TrLoss: 0.1307\n",
            "Epoch [30/40], Step [1000/1062], TrLoss: 0.0165\n",
            "Epoch [30/40], Step [1050/1062], TrLoss: 0.0555\n",
            "Epoch [31/40], Step [50/1062], TrLoss: 0.1285\n",
            "Epoch [31/40], Step [100/1062], TrLoss: 0.0324\n",
            "Epoch [31/40], Step [150/1062], TrLoss: 0.2155\n",
            "Epoch [31/40], Step [200/1062], TrLoss: 0.0843\n",
            "Epoch [31/40], Step [250/1062], TrLoss: 0.0924\n",
            "Epoch [31/40], Step [300/1062], TrLoss: 0.1436\n",
            "Epoch [31/40], Step [350/1062], TrLoss: 0.2079\n",
            "Epoch [31/40], Step [400/1062], TrLoss: 0.0751\n",
            "Epoch [31/40], Step [450/1062], TrLoss: 0.0657\n",
            "Epoch [31/40], Step [500/1062], TrLoss: 0.0758\n",
            "Epoch [31/40], Step [550/1062], TrLoss: 0.1397\n",
            "Epoch [31/40], Step [600/1062], TrLoss: 0.0621\n",
            "Epoch [31/40], Step [650/1062], TrLoss: 0.0349\n",
            "Epoch [31/40], Step [700/1062], TrLoss: 0.0305\n",
            "Epoch [31/40], Step [750/1062], TrLoss: 0.1043\n",
            "Epoch [31/40], Step [800/1062], TrLoss: 0.0916\n",
            "Epoch [31/40], Step [850/1062], TrLoss: 0.0453\n",
            "Epoch [31/40], Step [900/1062], TrLoss: 0.0726\n",
            "Epoch [31/40], Step [950/1062], TrLoss: 0.0271\n",
            "Epoch [31/40], Step [1000/1062], TrLoss: 0.2250\n",
            "Epoch [31/40], Step [1050/1062], TrLoss: 0.0223\n",
            "Epoch [32/40], Step [50/1062], TrLoss: 0.0591\n",
            "Epoch [32/40], Step [100/1062], TrLoss: 0.0242\n",
            "Epoch [32/40], Step [150/1062], TrLoss: 0.0206\n",
            "Epoch [32/40], Step [200/1062], TrLoss: 0.0213\n",
            "Epoch [32/40], Step [250/1062], TrLoss: 0.0599\n",
            "Epoch [32/40], Step [300/1062], TrLoss: 0.0331\n",
            "Epoch [32/40], Step [350/1062], TrLoss: 0.0810\n",
            "Epoch [32/40], Step [400/1062], TrLoss: 0.0471\n",
            "Epoch [32/40], Step [450/1062], TrLoss: 0.2511\n",
            "Epoch [32/40], Step [500/1062], TrLoss: 0.2820\n",
            "Epoch [32/40], Step [550/1062], TrLoss: 0.1083\n",
            "Epoch [32/40], Step [600/1062], TrLoss: 0.0097\n",
            "Epoch [32/40], Step [650/1062], TrLoss: 0.0335\n",
            "Epoch [32/40], Step [700/1062], TrLoss: 0.1485\n",
            "Epoch [32/40], Step [750/1062], TrLoss: 0.0686\n",
            "Epoch [32/40], Step [800/1062], TrLoss: 0.1445\n",
            "Epoch [32/40], Step [850/1062], TrLoss: 0.0516\n",
            "Epoch [32/40], Step [900/1062], TrLoss: 0.0202\n",
            "Epoch [32/40], Step [950/1062], TrLoss: 0.0416\n",
            "Epoch [32/40], Step [1000/1062], TrLoss: 0.0511\n",
            "Epoch [32/40], Step [1050/1062], TrLoss: 0.0534\n",
            "Epoch [33/40], Step [50/1062], TrLoss: 0.0398\n",
            "Epoch [33/40], Step [100/1062], TrLoss: 0.0858\n",
            "Epoch [33/40], Step [150/1062], TrLoss: 0.0572\n",
            "Epoch [33/40], Step [200/1062], TrLoss: 0.4125\n",
            "Epoch [33/40], Step [250/1062], TrLoss: 0.1287\n",
            "Epoch [33/40], Step [300/1062], TrLoss: 0.1518\n",
            "Epoch [33/40], Step [350/1062], TrLoss: 0.0360\n",
            "Epoch [33/40], Step [400/1062], TrLoss: 0.0262\n",
            "Epoch [33/40], Step [450/1062], TrLoss: 0.0887\n",
            "Epoch [33/40], Step [500/1062], TrLoss: 0.0285\n",
            "Epoch [33/40], Step [550/1062], TrLoss: 0.1715\n",
            "Epoch [33/40], Step [600/1062], TrLoss: 0.0396\n",
            "Epoch [33/40], Step [650/1062], TrLoss: 0.1077\n",
            "Epoch [33/40], Step [700/1062], TrLoss: 0.0748\n",
            "Epoch [33/40], Step [750/1062], TrLoss: 0.0340\n",
            "Epoch [33/40], Step [800/1062], TrLoss: 0.8047\n",
            "Epoch [33/40], Step [850/1062], TrLoss: 0.1589\n",
            "Epoch [33/40], Step [900/1062], TrLoss: 0.0241\n",
            "Epoch [33/40], Step [950/1062], TrLoss: 0.0835\n",
            "Epoch [33/40], Step [1000/1062], TrLoss: 0.2129\n",
            "Epoch [33/40], Step [1050/1062], TrLoss: 0.0660\n",
            "Epoch [34/40], Step [50/1062], TrLoss: 0.1686\n",
            "Epoch [34/40], Step [100/1062], TrLoss: 0.0369\n",
            "Epoch [34/40], Step [150/1062], TrLoss: 0.0067\n",
            "Epoch [34/40], Step [200/1062], TrLoss: 0.0320\n",
            "Epoch [34/40], Step [250/1062], TrLoss: 0.0858\n",
            "Epoch [34/40], Step [300/1062], TrLoss: 0.0657\n",
            "Epoch [34/40], Step [350/1062], TrLoss: 0.0128\n",
            "Epoch [34/40], Step [400/1062], TrLoss: 0.0130\n",
            "Epoch [34/40], Step [450/1062], TrLoss: 0.0646\n",
            "Epoch [34/40], Step [500/1062], TrLoss: 0.1241\n",
            "Epoch [34/40], Step [550/1062], TrLoss: 0.0856\n",
            "Epoch [34/40], Step [600/1062], TrLoss: 0.0229\n",
            "Epoch [34/40], Step [650/1062], TrLoss: 0.0251\n",
            "Epoch [34/40], Step [700/1062], TrLoss: 0.0022\n",
            "Epoch [34/40], Step [750/1062], TrLoss: 0.0829\n",
            "Epoch [34/40], Step [800/1062], TrLoss: 0.0733\n",
            "Epoch [34/40], Step [850/1062], TrLoss: 0.1150\n",
            "Epoch [34/40], Step [900/1062], TrLoss: 0.0273\n",
            "Epoch [34/40], Step [950/1062], TrLoss: 0.1192\n",
            "Epoch [34/40], Step [1000/1062], TrLoss: 0.0048\n",
            "Epoch [34/40], Step [1050/1062], TrLoss: 0.0514\n",
            "Epoch [35/40], Step [50/1062], TrLoss: 0.0264\n",
            "Epoch [35/40], Step [100/1062], TrLoss: 0.0669\n",
            "Epoch [35/40], Step [150/1062], TrLoss: 0.0712\n",
            "Epoch [35/40], Step [200/1062], TrLoss: 0.0277\n",
            "Epoch [35/40], Step [250/1062], TrLoss: 0.1257\n",
            "Epoch [35/40], Step [300/1062], TrLoss: 0.0617\n",
            "Epoch [35/40], Step [350/1062], TrLoss: 0.0437\n",
            "Epoch [35/40], Step [400/1062], TrLoss: 0.1360\n",
            "Epoch [35/40], Step [450/1062], TrLoss: 0.2659\n",
            "Epoch [35/40], Step [500/1062], TrLoss: 0.0716\n",
            "Epoch [35/40], Step [550/1062], TrLoss: 0.0750\n",
            "Epoch [35/40], Step [600/1062], TrLoss: 0.0198\n",
            "Epoch [35/40], Step [650/1062], TrLoss: 0.1437\n",
            "Epoch [35/40], Step [700/1062], TrLoss: 0.0729\n",
            "Epoch [35/40], Step [750/1062], TrLoss: 0.0388\n",
            "Epoch [35/40], Step [800/1062], TrLoss: 0.3309\n",
            "Epoch [35/40], Step [850/1062], TrLoss: 0.0490\n",
            "Epoch [35/40], Step [900/1062], TrLoss: 0.0908\n",
            "Epoch [35/40], Step [950/1062], TrLoss: 0.0198\n",
            "Epoch [35/40], Step [1000/1062], TrLoss: 0.0552\n",
            "Epoch [35/40], Step [1050/1062], TrLoss: 0.0706\n",
            "Epoch [36/40], Step [50/1062], TrLoss: 0.0456\n",
            "Epoch [36/40], Step [100/1062], TrLoss: 0.0224\n",
            "Epoch [36/40], Step [150/1062], TrLoss: 0.1397\n",
            "Epoch [36/40], Step [200/1062], TrLoss: 0.0617\n",
            "Epoch [36/40], Step [250/1062], TrLoss: 0.0414\n",
            "Epoch [36/40], Step [300/1062], TrLoss: 0.1173\n",
            "Epoch [36/40], Step [350/1062], TrLoss: 0.0534\n",
            "Epoch [36/40], Step [400/1062], TrLoss: 0.0585\n",
            "Epoch [36/40], Step [450/1062], TrLoss: 0.0289\n",
            "Epoch [36/40], Step [500/1062], TrLoss: 0.0262\n",
            "Epoch [36/40], Step [550/1062], TrLoss: 0.0412\n",
            "Epoch [36/40], Step [600/1062], TrLoss: 0.0213\n",
            "Epoch [36/40], Step [650/1062], TrLoss: 0.0168\n",
            "Epoch [36/40], Step [700/1062], TrLoss: 0.0968\n",
            "Epoch [36/40], Step [750/1062], TrLoss: 0.0218\n",
            "Epoch [36/40], Step [800/1062], TrLoss: 0.0278\n",
            "Epoch [36/40], Step [850/1062], TrLoss: 0.0741\n",
            "Epoch [36/40], Step [900/1062], TrLoss: 0.0500\n",
            "Epoch [36/40], Step [950/1062], TrLoss: 0.0321\n",
            "Epoch [36/40], Step [1000/1062], TrLoss: 0.0115\n",
            "Epoch [36/40], Step [1050/1062], TrLoss: 0.1242\n",
            "Epoch [37/40], Step [50/1062], TrLoss: 0.0575\n",
            "Epoch [37/40], Step [100/1062], TrLoss: 0.0393\n",
            "Epoch [37/40], Step [150/1062], TrLoss: 0.0301\n",
            "Epoch [37/40], Step [200/1062], TrLoss: 0.0605\n",
            "Epoch [37/40], Step [250/1062], TrLoss: 0.1936\n",
            "Epoch [37/40], Step [300/1062], TrLoss: 0.0242\n",
            "Epoch [37/40], Step [350/1062], TrLoss: 0.0274\n",
            "Epoch [37/40], Step [400/1062], TrLoss: 0.0857\n",
            "Epoch [37/40], Step [450/1062], TrLoss: 0.1649\n",
            "Epoch [37/40], Step [500/1062], TrLoss: 0.0730\n",
            "Epoch [37/40], Step [550/1062], TrLoss: 0.0219\n",
            "Epoch [37/40], Step [600/1062], TrLoss: 0.0806\n",
            "Epoch [37/40], Step [650/1062], TrLoss: 0.1731\n",
            "Epoch [37/40], Step [700/1062], TrLoss: 0.0288\n",
            "Epoch [37/40], Step [750/1062], TrLoss: 0.1185\n",
            "Epoch [37/40], Step [800/1062], TrLoss: 0.0417\n",
            "Epoch [37/40], Step [850/1062], TrLoss: 0.0166\n",
            "Epoch [37/40], Step [900/1062], TrLoss: 0.1260\n",
            "Epoch [37/40], Step [950/1062], TrLoss: 0.0477\n",
            "Epoch [37/40], Step [1000/1062], TrLoss: 0.1026\n",
            "Epoch [37/40], Step [1050/1062], TrLoss: 0.0704\n",
            "Epoch [38/40], Step [50/1062], TrLoss: 0.1370\n",
            "Epoch [38/40], Step [100/1062], TrLoss: 0.0201\n",
            "Epoch [38/40], Step [150/1062], TrLoss: 0.0345\n",
            "Epoch [38/40], Step [200/1062], TrLoss: 0.0436\n",
            "Epoch [38/40], Step [250/1062], TrLoss: 0.0857\n",
            "Epoch [38/40], Step [300/1062], TrLoss: 0.0433\n",
            "Epoch [38/40], Step [350/1062], TrLoss: 0.4013\n",
            "Epoch [38/40], Step [400/1062], TrLoss: 0.0370\n",
            "Epoch [38/40], Step [450/1062], TrLoss: 0.0779\n",
            "Epoch [38/40], Step [500/1062], TrLoss: 0.0219\n",
            "Epoch [38/40], Step [550/1062], TrLoss: 0.0229\n",
            "Epoch [38/40], Step [600/1062], TrLoss: 0.0814\n",
            "Epoch [38/40], Step [650/1062], TrLoss: 0.0379\n",
            "Epoch [38/40], Step [700/1062], TrLoss: 0.0865\n",
            "Epoch [38/40], Step [750/1062], TrLoss: 0.1035\n",
            "Epoch [38/40], Step [800/1062], TrLoss: 0.0620\n",
            "Epoch [38/40], Step [850/1062], TrLoss: 0.1546\n",
            "Epoch [38/40], Step [900/1062], TrLoss: 0.0100\n",
            "Epoch [38/40], Step [950/1062], TrLoss: 0.0560\n",
            "Epoch [38/40], Step [1000/1062], TrLoss: 0.0143\n",
            "Epoch [38/40], Step [1050/1062], TrLoss: 0.0272\n",
            "Epoch [39/40], Step [50/1062], TrLoss: 0.1119\n",
            "Epoch [39/40], Step [100/1062], TrLoss: 0.0151\n",
            "Epoch [39/40], Step [150/1062], TrLoss: 0.1151\n",
            "Epoch [39/40], Step [200/1062], TrLoss: 0.1875\n",
            "Epoch [39/40], Step [250/1062], TrLoss: 0.0262\n",
            "Epoch [39/40], Step [300/1062], TrLoss: 0.0047\n",
            "Epoch [39/40], Step [350/1062], TrLoss: 0.0450\n",
            "Epoch [39/40], Step [400/1062], TrLoss: 0.0841\n",
            "Epoch [39/40], Step [450/1062], TrLoss: 0.1285\n",
            "Epoch [39/40], Step [500/1062], TrLoss: 0.0212\n",
            "Epoch [39/40], Step [550/1062], TrLoss: 0.0832\n",
            "Epoch [39/40], Step [600/1062], TrLoss: 0.0216\n",
            "Epoch [39/40], Step [650/1062], TrLoss: 0.0043\n",
            "Epoch [39/40], Step [700/1062], TrLoss: 0.0199\n",
            "Epoch [39/40], Step [750/1062], TrLoss: 0.0336\n",
            "Epoch [39/40], Step [800/1062], TrLoss: 0.1580\n",
            "Epoch [39/40], Step [850/1062], TrLoss: 0.0555\n",
            "Epoch [39/40], Step [900/1062], TrLoss: 0.0086\n",
            "Epoch [39/40], Step [950/1062], TrLoss: 0.0809\n",
            "Epoch [39/40], Step [1000/1062], TrLoss: 0.0096\n",
            "Epoch [39/40], Step [1050/1062], TrLoss: 0.1301\n",
            "Epoch [40/40], Step [50/1062], TrLoss: 0.0163\n",
            "Epoch [40/40], Step [100/1062], TrLoss: 0.0243\n",
            "Epoch [40/40], Step [150/1062], TrLoss: 0.0269\n",
            "Epoch [40/40], Step [200/1062], TrLoss: 0.0067\n",
            "Epoch [40/40], Step [250/1062], TrLoss: 0.0304\n",
            "Epoch [40/40], Step [300/1062], TrLoss: 0.1140\n",
            "Epoch [40/40], Step [350/1062], TrLoss: 0.0863\n",
            "Epoch [40/40], Step [400/1062], TrLoss: 0.0236\n",
            "Epoch [40/40], Step [450/1062], TrLoss: 0.0443\n",
            "Epoch [40/40], Step [500/1062], TrLoss: 0.0390\n",
            "Epoch [40/40], Step [550/1062], TrLoss: 0.0450\n",
            "Epoch [40/40], Step [600/1062], TrLoss: 0.0797\n",
            "Epoch [40/40], Step [650/1062], TrLoss: 0.0104\n",
            "Epoch [40/40], Step [700/1062], TrLoss: 0.0739\n",
            "Epoch [40/40], Step [750/1062], TrLoss: 0.0155\n",
            "Epoch [40/40], Step [800/1062], TrLoss: 0.0209\n",
            "Epoch [40/40], Step [850/1062], TrLoss: 0.0723\n",
            "Epoch [40/40], Step [900/1062], TrLoss: 0.0229\n",
            "Epoch [40/40], Step [950/1062], TrLoss: 0.1001\n",
            "Epoch [40/40], Step [1000/1062], TrLoss: 0.1870\n",
            "Epoch [40/40], Step [1050/1062], TrLoss: 0.0195\n",
            "Training accuracy: 89.49476224105462 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zOXzll3MCf3",
        "colab_type": "text"
      },
      "source": [
        "Test the model, the test accuracy is shown to be 82.7%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2gc7pH381vL",
        "colab_type": "code",
        "outputId": "c63f6254-9159-4cae-8556-e4bd000ec26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    OP = []\n",
        "    PR = []\n",
        "    LB = []\n",
        "    for i, (images, segs, targets) in enumerate(test_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,16,16))\n",
        "        labels = targets.to(device)\n",
        "        LB.append(labels.cpu().numpy())\n",
        "        outputs=model(images.cuda())\n",
        "        OP.append(outputs.cpu().numpy())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        PR.append(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the 1000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 1000 test images: 82.7 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WFN5bFVdjLW",
        "colab_type": "code",
        "outputId": "7659f189-7d4c-4fa0-b3df-8059a738982c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = np.array(PR)\n",
        "pred = pred.reshape(1000)\n",
        "print(np.shape(pred))\n",
        "label = np.array(LB)\n",
        "label = label.reshape(1000)\n",
        "print(np.shape(label))\n",
        "cfm=confusion_matrix(pred, label)\n",
        "print(cfm)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "[[ 83   1   0   3   1   1   9   0   4   1]\n",
            " [  0 100   2   0   1   1   2   2   2   2]\n",
            " [  1   5  63   6   1   1   1   4   7   0]\n",
            " [  0   0   3 100   1   2   0   0   3   3]\n",
            " [  0   1   1   1  83   3   1   1   3   8]\n",
            " [  0   0   1   5   0  89   0   0   5   1]\n",
            " [  5   1   2   1   1   1  77   0   3   0]\n",
            " [  0   1   2   5   0   1   0  84   4   4]\n",
            " [  0   1   3   7   3   0   1   1  69   0]\n",
            " [  1   0   1   1   6   4   0   7   5  79]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BptjYEYp_VDT",
        "colab_type": "text"
      },
      "source": [
        "Then we are going to perform clasification based on the red dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoTf5aQT_YNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ECE5470 dataset\n",
        "url = 'https://www.via.cornell.edu/ece5470/Lab9data1r.zip'\n",
        "r=requests.get(url).content\n",
        "\n",
        "#save data in data dir\n",
        "z = zipfile.ZipFile(io.BytesIO(r))\n",
        "# os.mkdir('data1')\n",
        "z.extractall('./data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnAkIL_x_y2P",
        "colab_type": "code",
        "outputId": "6f3ab7b8-4b3b-449d-a540-c5766f947c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mydata = SimpleDataset( \"./data/\", \"labels.csv\")\n",
        "\n",
        "#splitting into images and labels \n",
        "X  = []\n",
        "y  = []\n",
        "Xs = []\n",
        "for i in range(len(mydata)):\n",
        "    X.append(mydata[i][0])\n",
        "    y.append((mydata[i][1]))\n",
        "    Xs.append(mydata[i][2])\n",
        "\n",
        "\n",
        "#converting into numpy arrays to enable easy reshaping and other array operations\n",
        "    \n",
        "X  = np.asarray(X)\n",
        "Xs = np.asarray(Xs)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape)\n",
        "y= np.asarray(y)\n",
        "\n",
        "X  = np.swapaxes(X,1,3)\n",
        "X  = np.swapaxes(X,2,3)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape,y.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the input image (10000, 16, 16, 3) (10000, 16, 16)\n",
            "Shape of the input image (10000, 3, 16, 16) (10000, 16, 16) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6jptx9OAaQh",
        "colab_type": "code",
        "outputId": "92d7fb36-eea6-49a1-e606-6789ef8c942f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Xtr=X[:8500,:,:,:]/255\n",
        "Xstr=Xs[:8500,:,:]/255\n",
        "ytr=y[:8500]\n",
        "\n",
        "Xval=X[8500:9000,:,:,:]/255 #need to change validation size for 32x32 & 64x64 images\n",
        "Xsval=Xs[8500:9000,:,:]/255\n",
        "yval=y[8500:9000]\n",
        "\n",
        "Xte=X[-1000:,:,:,:]/255 #need to change test size for 32x32 & 64x64 images\n",
        "Xste=Xs[-1000:,:,:]/255\n",
        "yte=y[-1000:]\n",
        "\n",
        "\n",
        "print(Xtr.shape,Xstr.shape,ytr.shape)\n",
        "print(Xval.shape,Xsval.shape,yval.shape)\n",
        "print(Xte.shape,Xste.shape,yte.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8500, 3, 16, 16) (8500, 16, 16) (8500,)\n",
            "(500, 3, 16, 16) (500, 16, 16) (500,)\n",
            "(1000, 3, 16, 16) (1000, 16, 16) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atRGIXdjAefo",
        "colab_type": "code",
        "outputId": "8056c24a-7e8a-4b09-f95f-dbb2473fac4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 8\n",
        "'''\n",
        "inputs and segs are your data. \n",
        "'''\n",
        "targets=ytr\n",
        "\n",
        "inputs = torch.from_numpy(Xtr).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xstr).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "trainset = data_utils.TensorDataset(inputs, segs, targets)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size= batch_size, \n",
        "                                          shuffle=True,drop_last=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([8500, 3, 16, 16])\n",
            "Size of ground truth: torch.Size([8500, 16, 16])\n",
            "torch.Size([8500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W07_drimAikI",
        "colab_type": "code",
        "outputId": "20823837-323a-4f01-9610-ab9eb404b1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "targets=yte\n",
        "inputs = torch.from_numpy(Xte).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xste).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "testset = data_utils.TensorDataset(inputs, segs,targets)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size, \n",
        "                                          shuffle=False, drop_last=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([1000, 3, 16, 16])\n",
            "Size of ground truth: torch.Size([1000, 16, 16])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoIY1HyiAmIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(2*16*16, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAKO1aFAnoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZzRPbgiMRt-",
        "colab_type": "text"
      },
      "source": [
        "Then train the model. The training accuracy is shown to be 94%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5pnefzAucJ",
        "colab_type": "code",
        "outputId": "da7a33de-0248-47c0-92ed-7fb079f7c698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "resultstr = []\n",
        "resultsval = []\n",
        "correct = 0\n",
        "total = 0\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, segs, targets) in enumerate(train_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,16,16))\n",
        "        labels = targets.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images.cuda())\n",
        "        loss = criterion(outputs, labels.to(torch.long))\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # O\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], TrLoss: {:.4f}' \n",
        "                   .format(epoch+1,num_epochs,i+1, total_step, loss.data))\n",
        "    \n",
        "    resultstr.append(loss.data.cpu().to(torch.float))\n",
        "acc = correct/total\n",
        "print('Training accuracy: {} %'.format(100*acc))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/40], Step [50/1062], TrLoss: 2.1846\n",
            "Epoch [1/40], Step [100/1062], TrLoss: 2.3537\n",
            "Epoch [1/40], Step [150/1062], TrLoss: 2.2107\n",
            "Epoch [1/40], Step [200/1062], TrLoss: 2.2016\n",
            "Epoch [1/40], Step [250/1062], TrLoss: 2.0200\n",
            "Epoch [1/40], Step [300/1062], TrLoss: 2.1747\n",
            "Epoch [1/40], Step [350/1062], TrLoss: 2.0467\n",
            "Epoch [1/40], Step [400/1062], TrLoss: 1.8984\n",
            "Epoch [1/40], Step [450/1062], TrLoss: 2.1191\n",
            "Epoch [1/40], Step [500/1062], TrLoss: 1.6439\n",
            "Epoch [1/40], Step [550/1062], TrLoss: 1.7665\n",
            "Epoch [1/40], Step [600/1062], TrLoss: 1.9131\n",
            "Epoch [1/40], Step [650/1062], TrLoss: 1.3672\n",
            "Epoch [1/40], Step [700/1062], TrLoss: 1.2580\n",
            "Epoch [1/40], Step [750/1062], TrLoss: 1.4217\n",
            "Epoch [1/40], Step [800/1062], TrLoss: 1.5680\n",
            "Epoch [1/40], Step [850/1062], TrLoss: 1.3829\n",
            "Epoch [1/40], Step [900/1062], TrLoss: 1.0815\n",
            "Epoch [1/40], Step [950/1062], TrLoss: 1.1230\n",
            "Epoch [1/40], Step [1000/1062], TrLoss: 1.0205\n",
            "Epoch [1/40], Step [1050/1062], TrLoss: 1.6397\n",
            "Epoch [2/40], Step [50/1062], TrLoss: 1.2882\n",
            "Epoch [2/40], Step [100/1062], TrLoss: 1.3813\n",
            "Epoch [2/40], Step [150/1062], TrLoss: 1.6810\n",
            "Epoch [2/40], Step [200/1062], TrLoss: 0.7039\n",
            "Epoch [2/40], Step [250/1062], TrLoss: 1.0834\n",
            "Epoch [2/40], Step [300/1062], TrLoss: 1.3588\n",
            "Epoch [2/40], Step [350/1062], TrLoss: 1.2494\n",
            "Epoch [2/40], Step [400/1062], TrLoss: 1.0063\n",
            "Epoch [2/40], Step [450/1062], TrLoss: 1.0328\n",
            "Epoch [2/40], Step [500/1062], TrLoss: 1.3274\n",
            "Epoch [2/40], Step [550/1062], TrLoss: 0.8652\n",
            "Epoch [2/40], Step [600/1062], TrLoss: 1.5933\n",
            "Epoch [2/40], Step [650/1062], TrLoss: 0.9796\n",
            "Epoch [2/40], Step [700/1062], TrLoss: 1.1637\n",
            "Epoch [2/40], Step [750/1062], TrLoss: 0.4266\n",
            "Epoch [2/40], Step [800/1062], TrLoss: 0.5132\n",
            "Epoch [2/40], Step [850/1062], TrLoss: 0.7892\n",
            "Epoch [2/40], Step [900/1062], TrLoss: 0.6217\n",
            "Epoch [2/40], Step [950/1062], TrLoss: 0.6322\n",
            "Epoch [2/40], Step [1000/1062], TrLoss: 0.5425\n",
            "Epoch [2/40], Step [1050/1062], TrLoss: 0.8947\n",
            "Epoch [3/40], Step [50/1062], TrLoss: 0.6127\n",
            "Epoch [3/40], Step [100/1062], TrLoss: 0.3484\n",
            "Epoch [3/40], Step [150/1062], TrLoss: 0.6101\n",
            "Epoch [3/40], Step [200/1062], TrLoss: 0.2711\n",
            "Epoch [3/40], Step [250/1062], TrLoss: 0.7287\n",
            "Epoch [3/40], Step [300/1062], TrLoss: 0.7652\n",
            "Epoch [3/40], Step [350/1062], TrLoss: 0.4821\n",
            "Epoch [3/40], Step [400/1062], TrLoss: 0.2971\n",
            "Epoch [3/40], Step [450/1062], TrLoss: 0.8420\n",
            "Epoch [3/40], Step [500/1062], TrLoss: 0.5829\n",
            "Epoch [3/40], Step [550/1062], TrLoss: 0.9721\n",
            "Epoch [3/40], Step [600/1062], TrLoss: 1.1271\n",
            "Epoch [3/40], Step [650/1062], TrLoss: 0.6480\n",
            "Epoch [3/40], Step [700/1062], TrLoss: 0.7065\n",
            "Epoch [3/40], Step [750/1062], TrLoss: 0.5147\n",
            "Epoch [3/40], Step [800/1062], TrLoss: 0.6529\n",
            "Epoch [3/40], Step [850/1062], TrLoss: 0.5096\n",
            "Epoch [3/40], Step [900/1062], TrLoss: 0.5999\n",
            "Epoch [3/40], Step [950/1062], TrLoss: 0.3208\n",
            "Epoch [3/40], Step [1000/1062], TrLoss: 0.3119\n",
            "Epoch [3/40], Step [1050/1062], TrLoss: 0.7725\n",
            "Epoch [4/40], Step [50/1062], TrLoss: 0.4389\n",
            "Epoch [4/40], Step [100/1062], TrLoss: 0.7351\n",
            "Epoch [4/40], Step [150/1062], TrLoss: 0.4617\n",
            "Epoch [4/40], Step [200/1062], TrLoss: 0.1835\n",
            "Epoch [4/40], Step [250/1062], TrLoss: 0.5274\n",
            "Epoch [4/40], Step [300/1062], TrLoss: 0.4905\n",
            "Epoch [4/40], Step [350/1062], TrLoss: 0.4840\n",
            "Epoch [4/40], Step [400/1062], TrLoss: 0.4690\n",
            "Epoch [4/40], Step [450/1062], TrLoss: 0.5665\n",
            "Epoch [4/40], Step [500/1062], TrLoss: 0.6987\n",
            "Epoch [4/40], Step [550/1062], TrLoss: 0.5506\n",
            "Epoch [4/40], Step [600/1062], TrLoss: 1.4680\n",
            "Epoch [4/40], Step [650/1062], TrLoss: 0.7836\n",
            "Epoch [4/40], Step [700/1062], TrLoss: 0.5930\n",
            "Epoch [4/40], Step [750/1062], TrLoss: 0.6320\n",
            "Epoch [4/40], Step [800/1062], TrLoss: 0.4212\n",
            "Epoch [4/40], Step [850/1062], TrLoss: 0.4158\n",
            "Epoch [4/40], Step [900/1062], TrLoss: 0.3008\n",
            "Epoch [4/40], Step [950/1062], TrLoss: 0.6555\n",
            "Epoch [4/40], Step [1000/1062], TrLoss: 0.4139\n",
            "Epoch [4/40], Step [1050/1062], TrLoss: 0.5635\n",
            "Epoch [5/40], Step [50/1062], TrLoss: 0.4913\n",
            "Epoch [5/40], Step [100/1062], TrLoss: 0.8112\n",
            "Epoch [5/40], Step [150/1062], TrLoss: 0.8484\n",
            "Epoch [5/40], Step [200/1062], TrLoss: 0.2803\n",
            "Epoch [5/40], Step [250/1062], TrLoss: 0.4125\n",
            "Epoch [5/40], Step [300/1062], TrLoss: 0.5861\n",
            "Epoch [5/40], Step [350/1062], TrLoss: 0.8272\n",
            "Epoch [5/40], Step [400/1062], TrLoss: 0.5339\n",
            "Epoch [5/40], Step [450/1062], TrLoss: 0.3082\n",
            "Epoch [5/40], Step [500/1062], TrLoss: 0.4775\n",
            "Epoch [5/40], Step [550/1062], TrLoss: 0.1794\n",
            "Epoch [5/40], Step [600/1062], TrLoss: 0.0740\n",
            "Epoch [5/40], Step [650/1062], TrLoss: 0.8133\n",
            "Epoch [5/40], Step [700/1062], TrLoss: 0.2649\n",
            "Epoch [5/40], Step [750/1062], TrLoss: 0.1547\n",
            "Epoch [5/40], Step [800/1062], TrLoss: 0.5547\n",
            "Epoch [5/40], Step [850/1062], TrLoss: 0.9899\n",
            "Epoch [5/40], Step [900/1062], TrLoss: 0.3953\n",
            "Epoch [5/40], Step [950/1062], TrLoss: 1.0156\n",
            "Epoch [5/40], Step [1000/1062], TrLoss: 1.0955\n",
            "Epoch [5/40], Step [1050/1062], TrLoss: 0.5871\n",
            "Epoch [6/40], Step [50/1062], TrLoss: 0.3480\n",
            "Epoch [6/40], Step [100/1062], TrLoss: 0.3173\n",
            "Epoch [6/40], Step [150/1062], TrLoss: 0.3137\n",
            "Epoch [6/40], Step [200/1062], TrLoss: 0.3325\n",
            "Epoch [6/40], Step [250/1062], TrLoss: 0.2772\n",
            "Epoch [6/40], Step [300/1062], TrLoss: 0.5801\n",
            "Epoch [6/40], Step [350/1062], TrLoss: 0.4865\n",
            "Epoch [6/40], Step [400/1062], TrLoss: 0.5849\n",
            "Epoch [6/40], Step [450/1062], TrLoss: 0.1478\n",
            "Epoch [6/40], Step [500/1062], TrLoss: 0.2598\n",
            "Epoch [6/40], Step [550/1062], TrLoss: 0.1131\n",
            "Epoch [6/40], Step [600/1062], TrLoss: 0.2158\n",
            "Epoch [6/40], Step [650/1062], TrLoss: 0.5353\n",
            "Epoch [6/40], Step [700/1062], TrLoss: 0.0501\n",
            "Epoch [6/40], Step [750/1062], TrLoss: 0.1417\n",
            "Epoch [6/40], Step [800/1062], TrLoss: 0.1078\n",
            "Epoch [6/40], Step [850/1062], TrLoss: 0.1969\n",
            "Epoch [6/40], Step [900/1062], TrLoss: 0.5931\n",
            "Epoch [6/40], Step [950/1062], TrLoss: 0.4471\n",
            "Epoch [6/40], Step [1000/1062], TrLoss: 0.6474\n",
            "Epoch [6/40], Step [1050/1062], TrLoss: 0.7801\n",
            "Epoch [7/40], Step [50/1062], TrLoss: 0.1551\n",
            "Epoch [7/40], Step [100/1062], TrLoss: 0.6470\n",
            "Epoch [7/40], Step [150/1062], TrLoss: 0.1883\n",
            "Epoch [7/40], Step [200/1062], TrLoss: 0.2207\n",
            "Epoch [7/40], Step [250/1062], TrLoss: 0.1871\n",
            "Epoch [7/40], Step [300/1062], TrLoss: 0.3261\n",
            "Epoch [7/40], Step [350/1062], TrLoss: 0.4478\n",
            "Epoch [7/40], Step [400/1062], TrLoss: 0.1091\n",
            "Epoch [7/40], Step [450/1062], TrLoss: 0.2037\n",
            "Epoch [7/40], Step [500/1062], TrLoss: 0.3127\n",
            "Epoch [7/40], Step [550/1062], TrLoss: 0.1595\n",
            "Epoch [7/40], Step [600/1062], TrLoss: 0.2249\n",
            "Epoch [7/40], Step [650/1062], TrLoss: 0.1286\n",
            "Epoch [7/40], Step [700/1062], TrLoss: 0.1775\n",
            "Epoch [7/40], Step [750/1062], TrLoss: 0.0962\n",
            "Epoch [7/40], Step [800/1062], TrLoss: 0.1157\n",
            "Epoch [7/40], Step [850/1062], TrLoss: 0.3507\n",
            "Epoch [7/40], Step [900/1062], TrLoss: 0.0836\n",
            "Epoch [7/40], Step [950/1062], TrLoss: 0.2079\n",
            "Epoch [7/40], Step [1000/1062], TrLoss: 0.5866\n",
            "Epoch [7/40], Step [1050/1062], TrLoss: 0.0433\n",
            "Epoch [8/40], Step [50/1062], TrLoss: 0.2244\n",
            "Epoch [8/40], Step [100/1062], TrLoss: 0.5749\n",
            "Epoch [8/40], Step [150/1062], TrLoss: 0.0364\n",
            "Epoch [8/40], Step [200/1062], TrLoss: 0.1934\n",
            "Epoch [8/40], Step [250/1062], TrLoss: 0.2667\n",
            "Epoch [8/40], Step [300/1062], TrLoss: 0.4363\n",
            "Epoch [8/40], Step [350/1062], TrLoss: 0.4587\n",
            "Epoch [8/40], Step [400/1062], TrLoss: 0.5474\n",
            "Epoch [8/40], Step [450/1062], TrLoss: 0.3131\n",
            "Epoch [8/40], Step [500/1062], TrLoss: 0.1111\n",
            "Epoch [8/40], Step [550/1062], TrLoss: 0.1572\n",
            "Epoch [8/40], Step [600/1062], TrLoss: 0.1771\n",
            "Epoch [8/40], Step [650/1062], TrLoss: 0.1641\n",
            "Epoch [8/40], Step [700/1062], TrLoss: 0.5574\n",
            "Epoch [8/40], Step [750/1062], TrLoss: 1.2019\n",
            "Epoch [8/40], Step [800/1062], TrLoss: 0.4448\n",
            "Epoch [8/40], Step [850/1062], TrLoss: 0.0978\n",
            "Epoch [8/40], Step [900/1062], TrLoss: 0.8486\n",
            "Epoch [8/40], Step [950/1062], TrLoss: 0.2884\n",
            "Epoch [8/40], Step [1000/1062], TrLoss: 0.0943\n",
            "Epoch [8/40], Step [1050/1062], TrLoss: 0.0858\n",
            "Epoch [9/40], Step [50/1062], TrLoss: 0.7052\n",
            "Epoch [9/40], Step [100/1062], TrLoss: 0.9205\n",
            "Epoch [9/40], Step [150/1062], TrLoss: 0.3672\n",
            "Epoch [9/40], Step [200/1062], TrLoss: 0.0284\n",
            "Epoch [9/40], Step [250/1062], TrLoss: 0.1202\n",
            "Epoch [9/40], Step [300/1062], TrLoss: 0.1790\n",
            "Epoch [9/40], Step [350/1062], TrLoss: 0.2303\n",
            "Epoch [9/40], Step [400/1062], TrLoss: 0.4057\n",
            "Epoch [9/40], Step [450/1062], TrLoss: 0.3931\n",
            "Epoch [9/40], Step [500/1062], TrLoss: 0.2825\n",
            "Epoch [9/40], Step [550/1062], TrLoss: 0.5529\n",
            "Epoch [9/40], Step [600/1062], TrLoss: 0.0568\n",
            "Epoch [9/40], Step [650/1062], TrLoss: 0.2388\n",
            "Epoch [9/40], Step [700/1062], TrLoss: 0.1867\n",
            "Epoch [9/40], Step [750/1062], TrLoss: 0.3620\n",
            "Epoch [9/40], Step [800/1062], TrLoss: 0.0266\n",
            "Epoch [9/40], Step [850/1062], TrLoss: 0.1165\n",
            "Epoch [9/40], Step [900/1062], TrLoss: 0.4003\n",
            "Epoch [9/40], Step [950/1062], TrLoss: 0.2268\n",
            "Epoch [9/40], Step [1000/1062], TrLoss: 0.0525\n",
            "Epoch [9/40], Step [1050/1062], TrLoss: 0.3486\n",
            "Epoch [10/40], Step [50/1062], TrLoss: 0.2068\n",
            "Epoch [10/40], Step [100/1062], TrLoss: 0.4646\n",
            "Epoch [10/40], Step [150/1062], TrLoss: 0.2175\n",
            "Epoch [10/40], Step [200/1062], TrLoss: 0.2412\n",
            "Epoch [10/40], Step [250/1062], TrLoss: 0.1627\n",
            "Epoch [10/40], Step [300/1062], TrLoss: 0.0866\n",
            "Epoch [10/40], Step [350/1062], TrLoss: 0.1236\n",
            "Epoch [10/40], Step [400/1062], TrLoss: 0.0482\n",
            "Epoch [10/40], Step [450/1062], TrLoss: 0.0932\n",
            "Epoch [10/40], Step [500/1062], TrLoss: 0.2876\n",
            "Epoch [10/40], Step [550/1062], TrLoss: 0.0445\n",
            "Epoch [10/40], Step [600/1062], TrLoss: 0.1045\n",
            "Epoch [10/40], Step [650/1062], TrLoss: 0.2932\n",
            "Epoch [10/40], Step [700/1062], TrLoss: 0.3186\n",
            "Epoch [10/40], Step [750/1062], TrLoss: 0.1886\n",
            "Epoch [10/40], Step [800/1062], TrLoss: 0.4366\n",
            "Epoch [10/40], Step [850/1062], TrLoss: 0.8341\n",
            "Epoch [10/40], Step [900/1062], TrLoss: 0.3587\n",
            "Epoch [10/40], Step [950/1062], TrLoss: 0.4260\n",
            "Epoch [10/40], Step [1000/1062], TrLoss: 0.2402\n",
            "Epoch [10/40], Step [1050/1062], TrLoss: 0.3423\n",
            "Epoch [11/40], Step [50/1062], TrLoss: 0.0936\n",
            "Epoch [11/40], Step [100/1062], TrLoss: 0.1199\n",
            "Epoch [11/40], Step [150/1062], TrLoss: 0.1735\n",
            "Epoch [11/40], Step [200/1062], TrLoss: 0.1462\n",
            "Epoch [11/40], Step [250/1062], TrLoss: 0.2270\n",
            "Epoch [11/40], Step [300/1062], TrLoss: 0.3821\n",
            "Epoch [11/40], Step [350/1062], TrLoss: 0.0757\n",
            "Epoch [11/40], Step [400/1062], TrLoss: 0.5816\n",
            "Epoch [11/40], Step [450/1062], TrLoss: 0.3546\n",
            "Epoch [11/40], Step [500/1062], TrLoss: 0.2524\n",
            "Epoch [11/40], Step [550/1062], TrLoss: 0.0624\n",
            "Epoch [11/40], Step [600/1062], TrLoss: 0.2696\n",
            "Epoch [11/40], Step [650/1062], TrLoss: 0.0284\n",
            "Epoch [11/40], Step [700/1062], TrLoss: 0.1556\n",
            "Epoch [11/40], Step [750/1062], TrLoss: 0.0746\n",
            "Epoch [11/40], Step [800/1062], TrLoss: 0.1896\n",
            "Epoch [11/40], Step [850/1062], TrLoss: 0.0667\n",
            "Epoch [11/40], Step [900/1062], TrLoss: 0.2919\n",
            "Epoch [11/40], Step [950/1062], TrLoss: 0.5724\n",
            "Epoch [11/40], Step [1000/1062], TrLoss: 0.0417\n",
            "Epoch [11/40], Step [1050/1062], TrLoss: 0.0618\n",
            "Epoch [12/40], Step [50/1062], TrLoss: 0.0928\n",
            "Epoch [12/40], Step [100/1062], TrLoss: 0.3078\n",
            "Epoch [12/40], Step [150/1062], TrLoss: 0.0953\n",
            "Epoch [12/40], Step [200/1062], TrLoss: 0.0175\n",
            "Epoch [12/40], Step [250/1062], TrLoss: 0.5996\n",
            "Epoch [12/40], Step [300/1062], TrLoss: 0.2135\n",
            "Epoch [12/40], Step [350/1062], TrLoss: 0.0997\n",
            "Epoch [12/40], Step [400/1062], TrLoss: 0.0527\n",
            "Epoch [12/40], Step [450/1062], TrLoss: 0.0347\n",
            "Epoch [12/40], Step [500/1062], TrLoss: 0.2160\n",
            "Epoch [12/40], Step [550/1062], TrLoss: 0.1213\n",
            "Epoch [12/40], Step [600/1062], TrLoss: 0.1310\n",
            "Epoch [12/40], Step [650/1062], TrLoss: 0.2974\n",
            "Epoch [12/40], Step [700/1062], TrLoss: 0.0596\n",
            "Epoch [12/40], Step [750/1062], TrLoss: 0.3469\n",
            "Epoch [12/40], Step [800/1062], TrLoss: 0.1236\n",
            "Epoch [12/40], Step [850/1062], TrLoss: 0.5704\n",
            "Epoch [12/40], Step [900/1062], TrLoss: 0.2543\n",
            "Epoch [12/40], Step [950/1062], TrLoss: 0.5192\n",
            "Epoch [12/40], Step [1000/1062], TrLoss: 0.1497\n",
            "Epoch [12/40], Step [1050/1062], TrLoss: 0.0733\n",
            "Epoch [13/40], Step [50/1062], TrLoss: 0.0549\n",
            "Epoch [13/40], Step [100/1062], TrLoss: 0.8959\n",
            "Epoch [13/40], Step [150/1062], TrLoss: 0.1424\n",
            "Epoch [13/40], Step [200/1062], TrLoss: 0.0248\n",
            "Epoch [13/40], Step [250/1062], TrLoss: 0.0328\n",
            "Epoch [13/40], Step [300/1062], TrLoss: 0.4206\n",
            "Epoch [13/40], Step [350/1062], TrLoss: 0.1017\n",
            "Epoch [13/40], Step [400/1062], TrLoss: 0.1742\n",
            "Epoch [13/40], Step [450/1062], TrLoss: 0.0843\n",
            "Epoch [13/40], Step [500/1062], TrLoss: 0.1276\n",
            "Epoch [13/40], Step [550/1062], TrLoss: 0.3027\n",
            "Epoch [13/40], Step [600/1062], TrLoss: 0.1583\n",
            "Epoch [13/40], Step [650/1062], TrLoss: 0.2609\n",
            "Epoch [13/40], Step [700/1062], TrLoss: 0.5530\n",
            "Epoch [13/40], Step [750/1062], TrLoss: 0.1205\n",
            "Epoch [13/40], Step [800/1062], TrLoss: 0.8784\n",
            "Epoch [13/40], Step [850/1062], TrLoss: 0.1073\n",
            "Epoch [13/40], Step [900/1062], TrLoss: 0.1887\n",
            "Epoch [13/40], Step [950/1062], TrLoss: 0.4238\n",
            "Epoch [13/40], Step [1000/1062], TrLoss: 0.1826\n",
            "Epoch [13/40], Step [1050/1062], TrLoss: 0.0492\n",
            "Epoch [14/40], Step [50/1062], TrLoss: 0.3421\n",
            "Epoch [14/40], Step [100/1062], TrLoss: 0.0741\n",
            "Epoch [14/40], Step [150/1062], TrLoss: 0.4097\n",
            "Epoch [14/40], Step [200/1062], TrLoss: 0.8414\n",
            "Epoch [14/40], Step [250/1062], TrLoss: 0.1195\n",
            "Epoch [14/40], Step [300/1062], TrLoss: 0.1275\n",
            "Epoch [14/40], Step [350/1062], TrLoss: 0.1512\n",
            "Epoch [14/40], Step [400/1062], TrLoss: 0.6020\n",
            "Epoch [14/40], Step [450/1062], TrLoss: 0.0754\n",
            "Epoch [14/40], Step [500/1062], TrLoss: 0.1293\n",
            "Epoch [14/40], Step [550/1062], TrLoss: 0.3193\n",
            "Epoch [14/40], Step [600/1062], TrLoss: 0.2007\n",
            "Epoch [14/40], Step [650/1062], TrLoss: 0.0983\n",
            "Epoch [14/40], Step [700/1062], TrLoss: 0.0573\n",
            "Epoch [14/40], Step [750/1062], TrLoss: 0.1500\n",
            "Epoch [14/40], Step [800/1062], TrLoss: 0.4301\n",
            "Epoch [14/40], Step [850/1062], TrLoss: 0.0902\n",
            "Epoch [14/40], Step [900/1062], TrLoss: 0.0582\n",
            "Epoch [14/40], Step [950/1062], TrLoss: 0.1721\n",
            "Epoch [14/40], Step [1000/1062], TrLoss: 0.2606\n",
            "Epoch [14/40], Step [1050/1062], TrLoss: 0.0588\n",
            "Epoch [15/40], Step [50/1062], TrLoss: 0.2234\n",
            "Epoch [15/40], Step [100/1062], TrLoss: 0.2752\n",
            "Epoch [15/40], Step [150/1062], TrLoss: 0.2543\n",
            "Epoch [15/40], Step [200/1062], TrLoss: 0.1328\n",
            "Epoch [15/40], Step [250/1062], TrLoss: 0.0328\n",
            "Epoch [15/40], Step [300/1062], TrLoss: 0.1259\n",
            "Epoch [15/40], Step [350/1062], TrLoss: 0.1045\n",
            "Epoch [15/40], Step [400/1062], TrLoss: 0.0096\n",
            "Epoch [15/40], Step [450/1062], TrLoss: 0.0942\n",
            "Epoch [15/40], Step [500/1062], TrLoss: 0.0468\n",
            "Epoch [15/40], Step [550/1062], TrLoss: 0.3227\n",
            "Epoch [15/40], Step [600/1062], TrLoss: 0.0486\n",
            "Epoch [15/40], Step [650/1062], TrLoss: 0.2291\n",
            "Epoch [15/40], Step [700/1062], TrLoss: 0.3164\n",
            "Epoch [15/40], Step [750/1062], TrLoss: 0.2386\n",
            "Epoch [15/40], Step [800/1062], TrLoss: 0.0640\n",
            "Epoch [15/40], Step [850/1062], TrLoss: 0.3023\n",
            "Epoch [15/40], Step [900/1062], TrLoss: 0.0748\n",
            "Epoch [15/40], Step [950/1062], TrLoss: 0.3103\n",
            "Epoch [15/40], Step [1000/1062], TrLoss: 0.0697\n",
            "Epoch [15/40], Step [1050/1062], TrLoss: 0.0393\n",
            "Epoch [16/40], Step [50/1062], TrLoss: 0.3309\n",
            "Epoch [16/40], Step [100/1062], TrLoss: 0.1997\n",
            "Epoch [16/40], Step [150/1062], TrLoss: 0.2708\n",
            "Epoch [16/40], Step [200/1062], TrLoss: 0.0649\n",
            "Epoch [16/40], Step [250/1062], TrLoss: 0.1028\n",
            "Epoch [16/40], Step [300/1062], TrLoss: 0.0423\n",
            "Epoch [16/40], Step [350/1062], TrLoss: 0.3630\n",
            "Epoch [16/40], Step [400/1062], TrLoss: 0.1133\n",
            "Epoch [16/40], Step [450/1062], TrLoss: 0.0334\n",
            "Epoch [16/40], Step [500/1062], TrLoss: 0.0880\n",
            "Epoch [16/40], Step [550/1062], TrLoss: 0.0481\n",
            "Epoch [16/40], Step [600/1062], TrLoss: 0.1000\n",
            "Epoch [16/40], Step [650/1062], TrLoss: 0.0316\n",
            "Epoch [16/40], Step [700/1062], TrLoss: 0.0901\n",
            "Epoch [16/40], Step [750/1062], TrLoss: 0.6150\n",
            "Epoch [16/40], Step [800/1062], TrLoss: 0.3066\n",
            "Epoch [16/40], Step [850/1062], TrLoss: 0.0199\n",
            "Epoch [16/40], Step [900/1062], TrLoss: 0.0994\n",
            "Epoch [16/40], Step [950/1062], TrLoss: 0.5173\n",
            "Epoch [16/40], Step [1000/1062], TrLoss: 0.7680\n",
            "Epoch [16/40], Step [1050/1062], TrLoss: 0.0877\n",
            "Epoch [17/40], Step [50/1062], TrLoss: 0.0616\n",
            "Epoch [17/40], Step [100/1062], TrLoss: 0.0625\n",
            "Epoch [17/40], Step [150/1062], TrLoss: 0.0988\n",
            "Epoch [17/40], Step [200/1062], TrLoss: 0.0614\n",
            "Epoch [17/40], Step [250/1062], TrLoss: 0.3981\n",
            "Epoch [17/40], Step [300/1062], TrLoss: 0.2075\n",
            "Epoch [17/40], Step [350/1062], TrLoss: 0.1413\n",
            "Epoch [17/40], Step [400/1062], TrLoss: 0.0615\n",
            "Epoch [17/40], Step [450/1062], TrLoss: 0.2835\n",
            "Epoch [17/40], Step [500/1062], TrLoss: 0.0599\n",
            "Epoch [17/40], Step [550/1062], TrLoss: 0.1393\n",
            "Epoch [17/40], Step [600/1062], TrLoss: 0.0306\n",
            "Epoch [17/40], Step [650/1062], TrLoss: 0.1400\n",
            "Epoch [17/40], Step [700/1062], TrLoss: 0.0829\n",
            "Epoch [17/40], Step [750/1062], TrLoss: 0.0149\n",
            "Epoch [17/40], Step [800/1062], TrLoss: 0.2061\n",
            "Epoch [17/40], Step [850/1062], TrLoss: 0.0314\n",
            "Epoch [17/40], Step [900/1062], TrLoss: 0.0537\n",
            "Epoch [17/40], Step [950/1062], TrLoss: 0.4697\n",
            "Epoch [17/40], Step [1000/1062], TrLoss: 0.1096\n",
            "Epoch [17/40], Step [1050/1062], TrLoss: 0.0284\n",
            "Epoch [18/40], Step [50/1062], TrLoss: 0.2816\n",
            "Epoch [18/40], Step [100/1062], TrLoss: 0.6840\n",
            "Epoch [18/40], Step [150/1062], TrLoss: 0.0423\n",
            "Epoch [18/40], Step [200/1062], TrLoss: 0.2975\n",
            "Epoch [18/40], Step [250/1062], TrLoss: 0.2670\n",
            "Epoch [18/40], Step [300/1062], TrLoss: 0.5370\n",
            "Epoch [18/40], Step [350/1062], TrLoss: 0.0502\n",
            "Epoch [18/40], Step [400/1062], TrLoss: 0.2659\n",
            "Epoch [18/40], Step [450/1062], TrLoss: 0.1422\n",
            "Epoch [18/40], Step [500/1062], TrLoss: 0.0534\n",
            "Epoch [18/40], Step [550/1062], TrLoss: 0.0520\n",
            "Epoch [18/40], Step [600/1062], TrLoss: 0.2754\n",
            "Epoch [18/40], Step [650/1062], TrLoss: 0.0829\n",
            "Epoch [18/40], Step [700/1062], TrLoss: 0.0055\n",
            "Epoch [18/40], Step [750/1062], TrLoss: 0.0189\n",
            "Epoch [18/40], Step [800/1062], TrLoss: 0.2292\n",
            "Epoch [18/40], Step [850/1062], TrLoss: 0.0972\n",
            "Epoch [18/40], Step [900/1062], TrLoss: 0.0736\n",
            "Epoch [18/40], Step [950/1062], TrLoss: 0.1726\n",
            "Epoch [18/40], Step [1000/1062], TrLoss: 0.0474\n",
            "Epoch [18/40], Step [1050/1062], TrLoss: 0.3436\n",
            "Epoch [19/40], Step [50/1062], TrLoss: 0.1779\n",
            "Epoch [19/40], Step [100/1062], TrLoss: 0.0160\n",
            "Epoch [19/40], Step [150/1062], TrLoss: 0.0698\n",
            "Epoch [19/40], Step [200/1062], TrLoss: 0.0237\n",
            "Epoch [19/40], Step [250/1062], TrLoss: 0.2073\n",
            "Epoch [19/40], Step [300/1062], TrLoss: 0.1531\n",
            "Epoch [19/40], Step [350/1062], TrLoss: 0.1483\n",
            "Epoch [19/40], Step [400/1062], TrLoss: 0.2050\n",
            "Epoch [19/40], Step [450/1062], TrLoss: 0.0034\n",
            "Epoch [19/40], Step [500/1062], TrLoss: 0.1261\n",
            "Epoch [19/40], Step [550/1062], TrLoss: 0.0662\n",
            "Epoch [19/40], Step [600/1062], TrLoss: 0.0531\n",
            "Epoch [19/40], Step [650/1062], TrLoss: 0.0771\n",
            "Epoch [19/40], Step [700/1062], TrLoss: 0.1148\n",
            "Epoch [19/40], Step [750/1062], TrLoss: 0.1399\n",
            "Epoch [19/40], Step [800/1062], TrLoss: 0.0784\n",
            "Epoch [19/40], Step [850/1062], TrLoss: 0.1847\n",
            "Epoch [19/40], Step [900/1062], TrLoss: 0.1545\n",
            "Epoch [19/40], Step [950/1062], TrLoss: 0.0406\n",
            "Epoch [19/40], Step [1000/1062], TrLoss: 0.0364\n",
            "Epoch [19/40], Step [1050/1062], TrLoss: 0.2635\n",
            "Epoch [20/40], Step [50/1062], TrLoss: 0.0182\n",
            "Epoch [20/40], Step [100/1062], TrLoss: 0.1765\n",
            "Epoch [20/40], Step [150/1062], TrLoss: 0.0638\n",
            "Epoch [20/40], Step [200/1062], TrLoss: 0.1639\n",
            "Epoch [20/40], Step [250/1062], TrLoss: 0.2022\n",
            "Epoch [20/40], Step [300/1062], TrLoss: 0.0730\n",
            "Epoch [20/40], Step [350/1062], TrLoss: 0.0559\n",
            "Epoch [20/40], Step [400/1062], TrLoss: 0.2014\n",
            "Epoch [20/40], Step [450/1062], TrLoss: 0.0982\n",
            "Epoch [20/40], Step [500/1062], TrLoss: 0.0130\n",
            "Epoch [20/40], Step [550/1062], TrLoss: 0.0298\n",
            "Epoch [20/40], Step [600/1062], TrLoss: 0.0786\n",
            "Epoch [20/40], Step [650/1062], TrLoss: 0.1855\n",
            "Epoch [20/40], Step [700/1062], TrLoss: 0.0531\n",
            "Epoch [20/40], Step [750/1062], TrLoss: 0.6899\n",
            "Epoch [20/40], Step [800/1062], TrLoss: 0.0299\n",
            "Epoch [20/40], Step [850/1062], TrLoss: 0.2123\n",
            "Epoch [20/40], Step [900/1062], TrLoss: 0.0046\n",
            "Epoch [20/40], Step [950/1062], TrLoss: 0.0453\n",
            "Epoch [20/40], Step [1000/1062], TrLoss: 0.0061\n",
            "Epoch [20/40], Step [1050/1062], TrLoss: 0.0233\n",
            "Epoch [21/40], Step [50/1062], TrLoss: 0.0238\n",
            "Epoch [21/40], Step [100/1062], TrLoss: 0.0570\n",
            "Epoch [21/40], Step [150/1062], TrLoss: 0.1136\n",
            "Epoch [21/40], Step [200/1062], TrLoss: 0.1646\n",
            "Epoch [21/40], Step [250/1062], TrLoss: 0.0156\n",
            "Epoch [21/40], Step [300/1062], TrLoss: 0.0257\n",
            "Epoch [21/40], Step [350/1062], TrLoss: 0.0772\n",
            "Epoch [21/40], Step [400/1062], TrLoss: 0.0838\n",
            "Epoch [21/40], Step [450/1062], TrLoss: 0.0528\n",
            "Epoch [21/40], Step [500/1062], TrLoss: 0.1910\n",
            "Epoch [21/40], Step [550/1062], TrLoss: 0.0534\n",
            "Epoch [21/40], Step [600/1062], TrLoss: 0.0082\n",
            "Epoch [21/40], Step [650/1062], TrLoss: 0.1869\n",
            "Epoch [21/40], Step [700/1062], TrLoss: 0.1275\n",
            "Epoch [21/40], Step [750/1062], TrLoss: 0.1314\n",
            "Epoch [21/40], Step [800/1062], TrLoss: 0.0456\n",
            "Epoch [21/40], Step [850/1062], TrLoss: 0.0207\n",
            "Epoch [21/40], Step [900/1062], TrLoss: 0.0371\n",
            "Epoch [21/40], Step [950/1062], TrLoss: 0.3437\n",
            "Epoch [21/40], Step [1000/1062], TrLoss: 0.1289\n",
            "Epoch [21/40], Step [1050/1062], TrLoss: 0.0497\n",
            "Epoch [22/40], Step [50/1062], TrLoss: 0.0389\n",
            "Epoch [22/40], Step [100/1062], TrLoss: 0.1070\n",
            "Epoch [22/40], Step [150/1062], TrLoss: 0.1142\n",
            "Epoch [22/40], Step [200/1062], TrLoss: 0.1214\n",
            "Epoch [22/40], Step [250/1062], TrLoss: 0.1841\n",
            "Epoch [22/40], Step [300/1062], TrLoss: 0.2840\n",
            "Epoch [22/40], Step [350/1062], TrLoss: 0.0818\n",
            "Epoch [22/40], Step [400/1062], TrLoss: 0.0332\n",
            "Epoch [22/40], Step [450/1062], TrLoss: 0.1058\n",
            "Epoch [22/40], Step [500/1062], TrLoss: 0.0098\n",
            "Epoch [22/40], Step [550/1062], TrLoss: 0.0384\n",
            "Epoch [22/40], Step [600/1062], TrLoss: 0.5578\n",
            "Epoch [22/40], Step [650/1062], TrLoss: 0.0970\n",
            "Epoch [22/40], Step [700/1062], TrLoss: 0.1831\n",
            "Epoch [22/40], Step [750/1062], TrLoss: 0.0511\n",
            "Epoch [22/40], Step [800/1062], TrLoss: 0.2071\n",
            "Epoch [22/40], Step [850/1062], TrLoss: 0.2011\n",
            "Epoch [22/40], Step [900/1062], TrLoss: 0.1237\n",
            "Epoch [22/40], Step [950/1062], TrLoss: 0.0443\n",
            "Epoch [22/40], Step [1000/1062], TrLoss: 0.4163\n",
            "Epoch [22/40], Step [1050/1062], TrLoss: 0.0141\n",
            "Epoch [23/40], Step [50/1062], TrLoss: 0.0131\n",
            "Epoch [23/40], Step [100/1062], TrLoss: 0.1769\n",
            "Epoch [23/40], Step [150/1062], TrLoss: 0.0406\n",
            "Epoch [23/40], Step [200/1062], TrLoss: 0.0372\n",
            "Epoch [23/40], Step [250/1062], TrLoss: 0.0849\n",
            "Epoch [23/40], Step [300/1062], TrLoss: 0.5460\n",
            "Epoch [23/40], Step [350/1062], TrLoss: 0.0987\n",
            "Epoch [23/40], Step [400/1062], TrLoss: 0.0207\n",
            "Epoch [23/40], Step [450/1062], TrLoss: 0.0338\n",
            "Epoch [23/40], Step [500/1062], TrLoss: 0.1447\n",
            "Epoch [23/40], Step [550/1062], TrLoss: 0.0974\n",
            "Epoch [23/40], Step [600/1062], TrLoss: 0.0483\n",
            "Epoch [23/40], Step [650/1062], TrLoss: 0.0514\n",
            "Epoch [23/40], Step [700/1062], TrLoss: 0.1217\n",
            "Epoch [23/40], Step [750/1062], TrLoss: 0.0139\n",
            "Epoch [23/40], Step [800/1062], TrLoss: 0.1684\n",
            "Epoch [23/40], Step [850/1062], TrLoss: 0.0057\n",
            "Epoch [23/40], Step [900/1062], TrLoss: 0.0516\n",
            "Epoch [23/40], Step [950/1062], TrLoss: 0.4321\n",
            "Epoch [23/40], Step [1000/1062], TrLoss: 0.0177\n",
            "Epoch [23/40], Step [1050/1062], TrLoss: 0.0470\n",
            "Epoch [24/40], Step [50/1062], TrLoss: 0.0586\n",
            "Epoch [24/40], Step [100/1062], TrLoss: 0.0293\n",
            "Epoch [24/40], Step [150/1062], TrLoss: 0.0832\n",
            "Epoch [24/40], Step [200/1062], TrLoss: 0.1030\n",
            "Epoch [24/40], Step [250/1062], TrLoss: 0.0180\n",
            "Epoch [24/40], Step [300/1062], TrLoss: 0.1739\n",
            "Epoch [24/40], Step [350/1062], TrLoss: 0.0150\n",
            "Epoch [24/40], Step [400/1062], TrLoss: 0.0276\n",
            "Epoch [24/40], Step [450/1062], TrLoss: 0.4323\n",
            "Epoch [24/40], Step [500/1062], TrLoss: 0.1387\n",
            "Epoch [24/40], Step [550/1062], TrLoss: 0.0086\n",
            "Epoch [24/40], Step [600/1062], TrLoss: 0.0653\n",
            "Epoch [24/40], Step [650/1062], TrLoss: 0.4860\n",
            "Epoch [24/40], Step [700/1062], TrLoss: 0.0258\n",
            "Epoch [24/40], Step [750/1062], TrLoss: 0.0044\n",
            "Epoch [24/40], Step [800/1062], TrLoss: 0.0370\n",
            "Epoch [24/40], Step [850/1062], TrLoss: 0.0425\n",
            "Epoch [24/40], Step [900/1062], TrLoss: 0.1249\n",
            "Epoch [24/40], Step [950/1062], TrLoss: 0.0384\n",
            "Epoch [24/40], Step [1000/1062], TrLoss: 0.1523\n",
            "Epoch [24/40], Step [1050/1062], TrLoss: 0.3314\n",
            "Epoch [25/40], Step [50/1062], TrLoss: 0.0134\n",
            "Epoch [25/40], Step [100/1062], TrLoss: 0.1750\n",
            "Epoch [25/40], Step [150/1062], TrLoss: 0.0191\n",
            "Epoch [25/40], Step [200/1062], TrLoss: 0.0235\n",
            "Epoch [25/40], Step [250/1062], TrLoss: 0.0160\n",
            "Epoch [25/40], Step [300/1062], TrLoss: 0.1426\n",
            "Epoch [25/40], Step [350/1062], TrLoss: 0.0660\n",
            "Epoch [25/40], Step [400/1062], TrLoss: 0.0176\n",
            "Epoch [25/40], Step [450/1062], TrLoss: 0.0302\n",
            "Epoch [25/40], Step [500/1062], TrLoss: 0.0218\n",
            "Epoch [25/40], Step [550/1062], TrLoss: 0.0689\n",
            "Epoch [25/40], Step [600/1062], TrLoss: 0.0433\n",
            "Epoch [25/40], Step [650/1062], TrLoss: 0.0240\n",
            "Epoch [25/40], Step [700/1062], TrLoss: 0.3131\n",
            "Epoch [25/40], Step [750/1062], TrLoss: 0.0661\n",
            "Epoch [25/40], Step [800/1062], TrLoss: 0.0387\n",
            "Epoch [25/40], Step [850/1062], TrLoss: 0.0105\n",
            "Epoch [25/40], Step [900/1062], TrLoss: 0.1717\n",
            "Epoch [25/40], Step [950/1062], TrLoss: 0.0411\n",
            "Epoch [25/40], Step [1000/1062], TrLoss: 0.3807\n",
            "Epoch [25/40], Step [1050/1062], TrLoss: 0.0112\n",
            "Epoch [26/40], Step [50/1062], TrLoss: 0.1478\n",
            "Epoch [26/40], Step [100/1062], TrLoss: 0.1255\n",
            "Epoch [26/40], Step [150/1062], TrLoss: 0.1455\n",
            "Epoch [26/40], Step [200/1062], TrLoss: 0.1021\n",
            "Epoch [26/40], Step [250/1062], TrLoss: 0.0564\n",
            "Epoch [26/40], Step [300/1062], TrLoss: 0.0538\n",
            "Epoch [26/40], Step [350/1062], TrLoss: 0.0014\n",
            "Epoch [26/40], Step [400/1062], TrLoss: 0.0623\n",
            "Epoch [26/40], Step [450/1062], TrLoss: 0.0468\n",
            "Epoch [26/40], Step [500/1062], TrLoss: 0.0174\n",
            "Epoch [26/40], Step [550/1062], TrLoss: 0.0087\n",
            "Epoch [26/40], Step [600/1062], TrLoss: 0.0185\n",
            "Epoch [26/40], Step [650/1062], TrLoss: 0.0457\n",
            "Epoch [26/40], Step [700/1062], TrLoss: 0.0186\n",
            "Epoch [26/40], Step [750/1062], TrLoss: 0.3513\n",
            "Epoch [26/40], Step [800/1062], TrLoss: 0.0345\n",
            "Epoch [26/40], Step [850/1062], TrLoss: 0.0811\n",
            "Epoch [26/40], Step [900/1062], TrLoss: 0.0506\n",
            "Epoch [26/40], Step [950/1062], TrLoss: 0.1625\n",
            "Epoch [26/40], Step [1000/1062], TrLoss: 0.0123\n",
            "Epoch [26/40], Step [1050/1062], TrLoss: 0.0158\n",
            "Epoch [27/40], Step [50/1062], TrLoss: 0.0094\n",
            "Epoch [27/40], Step [100/1062], TrLoss: 0.0441\n",
            "Epoch [27/40], Step [150/1062], TrLoss: 0.0356\n",
            "Epoch [27/40], Step [200/1062], TrLoss: 0.0738\n",
            "Epoch [27/40], Step [250/1062], TrLoss: 0.0110\n",
            "Epoch [27/40], Step [300/1062], TrLoss: 0.1166\n",
            "Epoch [27/40], Step [350/1062], TrLoss: 0.0200\n",
            "Epoch [27/40], Step [400/1062], TrLoss: 0.0708\n",
            "Epoch [27/40], Step [450/1062], TrLoss: 0.1792\n",
            "Epoch [27/40], Step [500/1062], TrLoss: 0.0622\n",
            "Epoch [27/40], Step [550/1062], TrLoss: 0.0097\n",
            "Epoch [27/40], Step [600/1062], TrLoss: 0.0026\n",
            "Epoch [27/40], Step [650/1062], TrLoss: 0.0176\n",
            "Epoch [27/40], Step [700/1062], TrLoss: 0.0923\n",
            "Epoch [27/40], Step [750/1062], TrLoss: 0.0229\n",
            "Epoch [27/40], Step [800/1062], TrLoss: 0.0982\n",
            "Epoch [27/40], Step [850/1062], TrLoss: 0.0171\n",
            "Epoch [27/40], Step [900/1062], TrLoss: 0.0297\n",
            "Epoch [27/40], Step [950/1062], TrLoss: 0.1382\n",
            "Epoch [27/40], Step [1000/1062], TrLoss: 0.0111\n",
            "Epoch [27/40], Step [1050/1062], TrLoss: 0.0098\n",
            "Epoch [28/40], Step [50/1062], TrLoss: 0.0457\n",
            "Epoch [28/40], Step [100/1062], TrLoss: 0.4050\n",
            "Epoch [28/40], Step [150/1062], TrLoss: 0.0348\n",
            "Epoch [28/40], Step [200/1062], TrLoss: 0.0185\n",
            "Epoch [28/40], Step [250/1062], TrLoss: 0.1004\n",
            "Epoch [28/40], Step [300/1062], TrLoss: 0.0902\n",
            "Epoch [28/40], Step [350/1062], TrLoss: 0.0629\n",
            "Epoch [28/40], Step [400/1062], TrLoss: 0.0701\n",
            "Epoch [28/40], Step [450/1062], TrLoss: 0.1139\n",
            "Epoch [28/40], Step [500/1062], TrLoss: 0.0508\n",
            "Epoch [28/40], Step [550/1062], TrLoss: 0.0349\n",
            "Epoch [28/40], Step [600/1062], TrLoss: 0.0021\n",
            "Epoch [28/40], Step [650/1062], TrLoss: 0.1118\n",
            "Epoch [28/40], Step [700/1062], TrLoss: 0.1074\n",
            "Epoch [28/40], Step [750/1062], TrLoss: 0.0019\n",
            "Epoch [28/40], Step [800/1062], TrLoss: 0.0209\n",
            "Epoch [28/40], Step [850/1062], TrLoss: 0.1064\n",
            "Epoch [28/40], Step [900/1062], TrLoss: 0.0250\n",
            "Epoch [28/40], Step [950/1062], TrLoss: 0.0277\n",
            "Epoch [28/40], Step [1000/1062], TrLoss: 0.0376\n",
            "Epoch [28/40], Step [1050/1062], TrLoss: 0.1608\n",
            "Epoch [29/40], Step [50/1062], TrLoss: 0.0394\n",
            "Epoch [29/40], Step [100/1062], TrLoss: 0.0771\n",
            "Epoch [29/40], Step [150/1062], TrLoss: 0.0518\n",
            "Epoch [29/40], Step [200/1062], TrLoss: 0.0465\n",
            "Epoch [29/40], Step [250/1062], TrLoss: 0.0411\n",
            "Epoch [29/40], Step [300/1062], TrLoss: 0.0353\n",
            "Epoch [29/40], Step [350/1062], TrLoss: 0.0490\n",
            "Epoch [29/40], Step [400/1062], TrLoss: 0.0051\n",
            "Epoch [29/40], Step [450/1062], TrLoss: 0.0455\n",
            "Epoch [29/40], Step [500/1062], TrLoss: 0.0133\n",
            "Epoch [29/40], Step [550/1062], TrLoss: 0.1067\n",
            "Epoch [29/40], Step [600/1062], TrLoss: 0.0093\n",
            "Epoch [29/40], Step [650/1062], TrLoss: 0.0196\n",
            "Epoch [29/40], Step [700/1062], TrLoss: 0.0374\n",
            "Epoch [29/40], Step [750/1062], TrLoss: 0.0976\n",
            "Epoch [29/40], Step [800/1062], TrLoss: 0.0082\n",
            "Epoch [29/40], Step [850/1062], TrLoss: 0.0090\n",
            "Epoch [29/40], Step [900/1062], TrLoss: 0.0579\n",
            "Epoch [29/40], Step [950/1062], TrLoss: 0.0500\n",
            "Epoch [29/40], Step [1000/1062], TrLoss: 0.0075\n",
            "Epoch [29/40], Step [1050/1062], TrLoss: 0.0725\n",
            "Epoch [30/40], Step [50/1062], TrLoss: 0.2054\n",
            "Epoch [30/40], Step [100/1062], TrLoss: 0.0481\n",
            "Epoch [30/40], Step [150/1062], TrLoss: 0.0132\n",
            "Epoch [30/40], Step [200/1062], TrLoss: 0.0148\n",
            "Epoch [30/40], Step [250/1062], TrLoss: 0.0368\n",
            "Epoch [30/40], Step [300/1062], TrLoss: 0.0088\n",
            "Epoch [30/40], Step [350/1062], TrLoss: 0.0546\n",
            "Epoch [30/40], Step [400/1062], TrLoss: 0.0702\n",
            "Epoch [30/40], Step [450/1062], TrLoss: 0.0780\n",
            "Epoch [30/40], Step [500/1062], TrLoss: 0.0017\n",
            "Epoch [30/40], Step [550/1062], TrLoss: 0.0126\n",
            "Epoch [30/40], Step [600/1062], TrLoss: 0.0592\n",
            "Epoch [30/40], Step [650/1062], TrLoss: 0.0351\n",
            "Epoch [30/40], Step [700/1062], TrLoss: 0.1182\n",
            "Epoch [30/40], Step [750/1062], TrLoss: 0.3619\n",
            "Epoch [30/40], Step [800/1062], TrLoss: 0.1162\n",
            "Epoch [30/40], Step [850/1062], TrLoss: 0.0377\n",
            "Epoch [30/40], Step [900/1062], TrLoss: 0.1640\n",
            "Epoch [30/40], Step [950/1062], TrLoss: 0.0108\n",
            "Epoch [30/40], Step [1000/1062], TrLoss: 0.0641\n",
            "Epoch [30/40], Step [1050/1062], TrLoss: 0.0757\n",
            "Epoch [31/40], Step [50/1062], TrLoss: 0.0458\n",
            "Epoch [31/40], Step [100/1062], TrLoss: 0.0599\n",
            "Epoch [31/40], Step [150/1062], TrLoss: 0.0117\n",
            "Epoch [31/40], Step [200/1062], TrLoss: 0.0344\n",
            "Epoch [31/40], Step [250/1062], TrLoss: 0.0066\n",
            "Epoch [31/40], Step [300/1062], TrLoss: 0.0479\n",
            "Epoch [31/40], Step [350/1062], TrLoss: 0.0263\n",
            "Epoch [31/40], Step [400/1062], TrLoss: 0.0134\n",
            "Epoch [31/40], Step [450/1062], TrLoss: 0.0222\n",
            "Epoch [31/40], Step [500/1062], TrLoss: 0.0108\n",
            "Epoch [31/40], Step [550/1062], TrLoss: 0.0180\n",
            "Epoch [31/40], Step [600/1062], TrLoss: 0.0270\n",
            "Epoch [31/40], Step [650/1062], TrLoss: 0.0084\n",
            "Epoch [31/40], Step [700/1062], TrLoss: 0.1968\n",
            "Epoch [31/40], Step [750/1062], TrLoss: 0.0201\n",
            "Epoch [31/40], Step [800/1062], TrLoss: 0.0182\n",
            "Epoch [31/40], Step [850/1062], TrLoss: 0.0395\n",
            "Epoch [31/40], Step [900/1062], TrLoss: 0.0869\n",
            "Epoch [31/40], Step [950/1062], TrLoss: 0.2964\n",
            "Epoch [31/40], Step [1000/1062], TrLoss: 0.0174\n",
            "Epoch [31/40], Step [1050/1062], TrLoss: 0.0812\n",
            "Epoch [32/40], Step [50/1062], TrLoss: 0.0106\n",
            "Epoch [32/40], Step [100/1062], TrLoss: 0.0724\n",
            "Epoch [32/40], Step [150/1062], TrLoss: 0.0128\n",
            "Epoch [32/40], Step [200/1062], TrLoss: 0.0259\n",
            "Epoch [32/40], Step [250/1062], TrLoss: 0.0060\n",
            "Epoch [32/40], Step [300/1062], TrLoss: 0.0314\n",
            "Epoch [32/40], Step [350/1062], TrLoss: 0.0674\n",
            "Epoch [32/40], Step [400/1062], TrLoss: 0.0203\n",
            "Epoch [32/40], Step [450/1062], TrLoss: 0.0384\n",
            "Epoch [32/40], Step [500/1062], TrLoss: 0.0592\n",
            "Epoch [32/40], Step [550/1062], TrLoss: 0.0456\n",
            "Epoch [32/40], Step [600/1062], TrLoss: 0.0285\n",
            "Epoch [32/40], Step [650/1062], TrLoss: 0.0033\n",
            "Epoch [32/40], Step [700/1062], TrLoss: 0.0032\n",
            "Epoch [32/40], Step [750/1062], TrLoss: 0.0137\n",
            "Epoch [32/40], Step [800/1062], TrLoss: 0.0057\n",
            "Epoch [32/40], Step [850/1062], TrLoss: 0.0185\n",
            "Epoch [32/40], Step [900/1062], TrLoss: 0.0494\n",
            "Epoch [32/40], Step [950/1062], TrLoss: 0.0237\n",
            "Epoch [32/40], Step [1000/1062], TrLoss: 0.1472\n",
            "Epoch [32/40], Step [1050/1062], TrLoss: 0.0045\n",
            "Epoch [33/40], Step [50/1062], TrLoss: 0.0868\n",
            "Epoch [33/40], Step [100/1062], TrLoss: 0.0086\n",
            "Epoch [33/40], Step [150/1062], TrLoss: 0.0042\n",
            "Epoch [33/40], Step [200/1062], TrLoss: 0.0853\n",
            "Epoch [33/40], Step [250/1062], TrLoss: 0.0188\n",
            "Epoch [33/40], Step [300/1062], TrLoss: 0.0834\n",
            "Epoch [33/40], Step [350/1062], TrLoss: 0.0341\n",
            "Epoch [33/40], Step [400/1062], TrLoss: 0.0226\n",
            "Epoch [33/40], Step [450/1062], TrLoss: 0.0625\n",
            "Epoch [33/40], Step [500/1062], TrLoss: 0.2844\n",
            "Epoch [33/40], Step [550/1062], TrLoss: 0.0070\n",
            "Epoch [33/40], Step [600/1062], TrLoss: 0.0446\n",
            "Epoch [33/40], Step [650/1062], TrLoss: 0.0312\n",
            "Epoch [33/40], Step [700/1062], TrLoss: 0.0398\n",
            "Epoch [33/40], Step [750/1062], TrLoss: 0.0274\n",
            "Epoch [33/40], Step [800/1062], TrLoss: 0.0187\n",
            "Epoch [33/40], Step [850/1062], TrLoss: 0.0236\n",
            "Epoch [33/40], Step [900/1062], TrLoss: 0.0647\n",
            "Epoch [33/40], Step [950/1062], TrLoss: 0.0391\n",
            "Epoch [33/40], Step [1000/1062], TrLoss: 0.0268\n",
            "Epoch [33/40], Step [1050/1062], TrLoss: 0.0055\n",
            "Epoch [34/40], Step [50/1062], TrLoss: 0.0054\n",
            "Epoch [34/40], Step [100/1062], TrLoss: 0.0271\n",
            "Epoch [34/40], Step [150/1062], TrLoss: 0.0038\n",
            "Epoch [34/40], Step [200/1062], TrLoss: 0.2581\n",
            "Epoch [34/40], Step [250/1062], TrLoss: 0.0211\n",
            "Epoch [34/40], Step [300/1062], TrLoss: 0.0100\n",
            "Epoch [34/40], Step [350/1062], TrLoss: 0.0284\n",
            "Epoch [34/40], Step [400/1062], TrLoss: 0.0231\n",
            "Epoch [34/40], Step [450/1062], TrLoss: 0.0539\n",
            "Epoch [34/40], Step [500/1062], TrLoss: 0.0052\n",
            "Epoch [34/40], Step [550/1062], TrLoss: 0.0710\n",
            "Epoch [34/40], Step [600/1062], TrLoss: 0.0263\n",
            "Epoch [34/40], Step [650/1062], TrLoss: 0.0502\n",
            "Epoch [34/40], Step [700/1062], TrLoss: 0.0485\n",
            "Epoch [34/40], Step [750/1062], TrLoss: 0.0045\n",
            "Epoch [34/40], Step [800/1062], TrLoss: 0.0938\n",
            "Epoch [34/40], Step [850/1062], TrLoss: 0.0113\n",
            "Epoch [34/40], Step [900/1062], TrLoss: 0.0215\n",
            "Epoch [34/40], Step [950/1062], TrLoss: 0.0346\n",
            "Epoch [34/40], Step [1000/1062], TrLoss: 0.0204\n",
            "Epoch [34/40], Step [1050/1062], TrLoss: 0.0372\n",
            "Epoch [35/40], Step [50/1062], TrLoss: 0.0212\n",
            "Epoch [35/40], Step [100/1062], TrLoss: 0.0023\n",
            "Epoch [35/40], Step [150/1062], TrLoss: 0.0186\n",
            "Epoch [35/40], Step [200/1062], TrLoss: 0.0169\n",
            "Epoch [35/40], Step [250/1062], TrLoss: 0.0176\n",
            "Epoch [35/40], Step [300/1062], TrLoss: 0.0765\n",
            "Epoch [35/40], Step [350/1062], TrLoss: 0.0419\n",
            "Epoch [35/40], Step [400/1062], TrLoss: 0.0084\n",
            "Epoch [35/40], Step [450/1062], TrLoss: 0.0127\n",
            "Epoch [35/40], Step [500/1062], TrLoss: 0.0064\n",
            "Epoch [35/40], Step [550/1062], TrLoss: 0.1145\n",
            "Epoch [35/40], Step [600/1062], TrLoss: 0.0327\n",
            "Epoch [35/40], Step [650/1062], TrLoss: 0.0048\n",
            "Epoch [35/40], Step [700/1062], TrLoss: 0.0215\n",
            "Epoch [35/40], Step [750/1062], TrLoss: 0.0306\n",
            "Epoch [35/40], Step [800/1062], TrLoss: 0.0149\n",
            "Epoch [35/40], Step [850/1062], TrLoss: 0.0228\n",
            "Epoch [35/40], Step [900/1062], TrLoss: 0.0150\n",
            "Epoch [35/40], Step [950/1062], TrLoss: 0.0184\n",
            "Epoch [35/40], Step [1000/1062], TrLoss: 0.0029\n",
            "Epoch [35/40], Step [1050/1062], TrLoss: 0.0507\n",
            "Epoch [36/40], Step [50/1062], TrLoss: 0.0219\n",
            "Epoch [36/40], Step [100/1062], TrLoss: 0.0295\n",
            "Epoch [36/40], Step [150/1062], TrLoss: 0.0030\n",
            "Epoch [36/40], Step [200/1062], TrLoss: 0.0173\n",
            "Epoch [36/40], Step [250/1062], TrLoss: 0.0303\n",
            "Epoch [36/40], Step [300/1062], TrLoss: 0.0038\n",
            "Epoch [36/40], Step [350/1062], TrLoss: 0.0586\n",
            "Epoch [36/40], Step [400/1062], TrLoss: 0.0060\n",
            "Epoch [36/40], Step [450/1062], TrLoss: 0.0192\n",
            "Epoch [36/40], Step [500/1062], TrLoss: 0.0494\n",
            "Epoch [36/40], Step [550/1062], TrLoss: 0.0141\n",
            "Epoch [36/40], Step [600/1062], TrLoss: 0.0274\n",
            "Epoch [36/40], Step [650/1062], TrLoss: 0.0121\n",
            "Epoch [36/40], Step [700/1062], TrLoss: 0.0528\n",
            "Epoch [36/40], Step [750/1062], TrLoss: 0.0425\n",
            "Epoch [36/40], Step [800/1062], TrLoss: 0.0237\n",
            "Epoch [36/40], Step [850/1062], TrLoss: 0.0043\n",
            "Epoch [36/40], Step [900/1062], TrLoss: 0.0023\n",
            "Epoch [36/40], Step [950/1062], TrLoss: 0.0206\n",
            "Epoch [36/40], Step [1000/1062], TrLoss: 0.0120\n",
            "Epoch [36/40], Step [1050/1062], TrLoss: 0.0330\n",
            "Epoch [37/40], Step [50/1062], TrLoss: 0.0395\n",
            "Epoch [37/40], Step [100/1062], TrLoss: 0.0162\n",
            "Epoch [37/40], Step [150/1062], TrLoss: 0.0147\n",
            "Epoch [37/40], Step [200/1062], TrLoss: 0.0242\n",
            "Epoch [37/40], Step [250/1062], TrLoss: 0.0057\n",
            "Epoch [37/40], Step [300/1062], TrLoss: 0.0087\n",
            "Epoch [37/40], Step [350/1062], TrLoss: 0.0011\n",
            "Epoch [37/40], Step [400/1062], TrLoss: 0.0052\n",
            "Epoch [37/40], Step [450/1062], TrLoss: 0.0314\n",
            "Epoch [37/40], Step [500/1062], TrLoss: 0.0099\n",
            "Epoch [37/40], Step [550/1062], TrLoss: 0.0018\n",
            "Epoch [37/40], Step [600/1062], TrLoss: 0.0535\n",
            "Epoch [37/40], Step [650/1062], TrLoss: 0.0306\n",
            "Epoch [37/40], Step [700/1062], TrLoss: 0.0316\n",
            "Epoch [37/40], Step [750/1062], TrLoss: 0.0509\n",
            "Epoch [37/40], Step [800/1062], TrLoss: 0.0116\n",
            "Epoch [37/40], Step [850/1062], TrLoss: 0.0458\n",
            "Epoch [37/40], Step [900/1062], TrLoss: 0.0325\n",
            "Epoch [37/40], Step [950/1062], TrLoss: 0.0102\n",
            "Epoch [37/40], Step [1000/1062], TrLoss: 0.1143\n",
            "Epoch [37/40], Step [1050/1062], TrLoss: 0.1080\n",
            "Epoch [38/40], Step [50/1062], TrLoss: 0.0345\n",
            "Epoch [38/40], Step [100/1062], TrLoss: 0.0085\n",
            "Epoch [38/40], Step [150/1062], TrLoss: 0.0010\n",
            "Epoch [38/40], Step [200/1062], TrLoss: 0.0114\n",
            "Epoch [38/40], Step [250/1062], TrLoss: 0.0471\n",
            "Epoch [38/40], Step [300/1062], TrLoss: 0.0094\n",
            "Epoch [38/40], Step [350/1062], TrLoss: 0.0451\n",
            "Epoch [38/40], Step [400/1062], TrLoss: 0.0081\n",
            "Epoch [38/40], Step [450/1062], TrLoss: 0.0304\n",
            "Epoch [38/40], Step [500/1062], TrLoss: 0.0068\n",
            "Epoch [38/40], Step [550/1062], TrLoss: 0.0354\n",
            "Epoch [38/40], Step [600/1062], TrLoss: 0.0036\n",
            "Epoch [38/40], Step [650/1062], TrLoss: 0.0018\n",
            "Epoch [38/40], Step [700/1062], TrLoss: 0.0110\n",
            "Epoch [38/40], Step [750/1062], TrLoss: 0.0275\n",
            "Epoch [38/40], Step [800/1062], TrLoss: 0.0233\n",
            "Epoch [38/40], Step [850/1062], TrLoss: 0.0110\n",
            "Epoch [38/40], Step [900/1062], TrLoss: 0.0106\n",
            "Epoch [38/40], Step [950/1062], TrLoss: 0.0223\n",
            "Epoch [38/40], Step [1000/1062], TrLoss: 0.0213\n",
            "Epoch [38/40], Step [1050/1062], TrLoss: 0.0393\n",
            "Epoch [39/40], Step [50/1062], TrLoss: 0.0130\n",
            "Epoch [39/40], Step [100/1062], TrLoss: 0.0058\n",
            "Epoch [39/40], Step [150/1062], TrLoss: 0.0057\n",
            "Epoch [39/40], Step [200/1062], TrLoss: 0.0445\n",
            "Epoch [39/40], Step [250/1062], TrLoss: 0.0292\n",
            "Epoch [39/40], Step [300/1062], TrLoss: 0.0246\n",
            "Epoch [39/40], Step [350/1062], TrLoss: 0.0266\n",
            "Epoch [39/40], Step [400/1062], TrLoss: 0.0095\n",
            "Epoch [39/40], Step [450/1062], TrLoss: 0.0089\n",
            "Epoch [39/40], Step [500/1062], TrLoss: 0.0140\n",
            "Epoch [39/40], Step [550/1062], TrLoss: 0.0157\n",
            "Epoch [39/40], Step [600/1062], TrLoss: 0.0045\n",
            "Epoch [39/40], Step [650/1062], TrLoss: 0.0437\n",
            "Epoch [39/40], Step [700/1062], TrLoss: 0.0163\n",
            "Epoch [39/40], Step [750/1062], TrLoss: 0.0648\n",
            "Epoch [39/40], Step [800/1062], TrLoss: 0.0076\n",
            "Epoch [39/40], Step [850/1062], TrLoss: 0.0838\n",
            "Epoch [39/40], Step [900/1062], TrLoss: 0.0044\n",
            "Epoch [39/40], Step [950/1062], TrLoss: 0.0476\n",
            "Epoch [39/40], Step [1000/1062], TrLoss: 0.1659\n",
            "Epoch [39/40], Step [1050/1062], TrLoss: 0.0121\n",
            "Epoch [40/40], Step [50/1062], TrLoss: 0.0164\n",
            "Epoch [40/40], Step [100/1062], TrLoss: 0.0199\n",
            "Epoch [40/40], Step [150/1062], TrLoss: 0.0084\n",
            "Epoch [40/40], Step [200/1062], TrLoss: 0.0105\n",
            "Epoch [40/40], Step [250/1062], TrLoss: 0.0109\n",
            "Epoch [40/40], Step [300/1062], TrLoss: 0.0036\n",
            "Epoch [40/40], Step [350/1062], TrLoss: 0.0113\n",
            "Epoch [40/40], Step [400/1062], TrLoss: 0.0160\n",
            "Epoch [40/40], Step [450/1062], TrLoss: 0.0012\n",
            "Epoch [40/40], Step [500/1062], TrLoss: 0.0503\n",
            "Epoch [40/40], Step [550/1062], TrLoss: 0.0058\n",
            "Epoch [40/40], Step [600/1062], TrLoss: 0.0049\n",
            "Epoch [40/40], Step [650/1062], TrLoss: 0.0137\n",
            "Epoch [40/40], Step [700/1062], TrLoss: 0.0005\n",
            "Epoch [40/40], Step [750/1062], TrLoss: 0.0178\n",
            "Epoch [40/40], Step [800/1062], TrLoss: 0.0126\n",
            "Epoch [40/40], Step [850/1062], TrLoss: 0.0306\n",
            "Epoch [40/40], Step [900/1062], TrLoss: 0.0013\n",
            "Epoch [40/40], Step [950/1062], TrLoss: 0.0029\n",
            "Epoch [40/40], Step [1000/1062], TrLoss: 0.0152\n",
            "Epoch [40/40], Step [1050/1062], TrLoss: 0.0051\n",
            "Training accuracy: 94.03601694915254 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoQkpa3cMbkl",
        "colab_type": "text"
      },
      "source": [
        "The test accuracy is shown as 90.4%, and we also printed the confusion matrix below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhILsKQRAxkG",
        "colab_type": "code",
        "outputId": "270f26f7-54cb-472e-df13-a353923132a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    PR = []\n",
        "    LB = []\n",
        "    for i, (images, segs, targets) in enumerate(test_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,16,16))\n",
        "        labels = targets.to(device)\n",
        "        LB.append(labels.cpu().numpy())\n",
        "        outputs=model(images.cuda())\n",
        "        OP.append(outputs.cpu().numpy())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        PR.append(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the 1000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 1000 test images: 90.4 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8172RGketM0",
        "colab_type": "code",
        "outputId": "de4ab302-9418-4297-83e3-7226779de786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = np.array(PR)\n",
        "pred = pred.reshape(1000)\n",
        "print(np.shape(pred))\n",
        "label = np.array(LB)\n",
        "label = label.reshape(1000)\n",
        "print(np.shape(label))\n",
        "cfm=confusion_matrix(pred, label)\n",
        "print(cfm)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "[[ 87   0   1   0   0   1   1   0   0   1]\n",
            " [  0 104   3   0   0   0   1   1   2   1]\n",
            " [  0   4  67   3   0   0   0   1   1   0]\n",
            " [  0   0   3 119   0   2   0   0   8   3]\n",
            " [  0   0   1   1  84   0   1   1   1   2]\n",
            " [  1   0   0   4   0  95   0   0   3   0]\n",
            " [  1   1   0   0   0   2  88   0   1   0]\n",
            " [  0   0   2   1   2   2   0  90   0   5]\n",
            " [  0   0   0   0   2   0   0   0  85   1]\n",
            " [  1   1   1   1   9   1   0   6   4  85]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RckaDwioJW1v",
        "colab_type": "text"
      },
      "source": [
        "Then we use the color dataset to test the model trained by the red dataset. First download the color dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwyFRL_qJft_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 40\n",
        "num_classes = 10\n",
        "batch_size = 8\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# ECE5470 dataset\n",
        "url = 'https://www.via.cornell.edu/ece5470/Lab9data1.zip'\n",
        "r=requests.get(url).content\n",
        "\n",
        "#save data in data dir\n",
        "z = zipfile.ZipFile(io.BytesIO(r))\n",
        "# os.mkdir('data1')\n",
        "z.extractall('./data1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwbbHUJyJz0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a65e418f-283f-412f-cf24-9fcc0db4e47b"
      },
      "source": [
        "mydata = SimpleDataset( \"./data1/\", \"labels.csv\")\n",
        "\n",
        "#splitting into images and labels \n",
        "X  = []\n",
        "y  = []\n",
        "Xs = []\n",
        "for i in range(len(mydata)):\n",
        "    X.append(mydata[i][0])\n",
        "    y.append((mydata[i][1]))\n",
        "    Xs.append(mydata[i][2])\n",
        "\n",
        "\n",
        "#converting into numpy arrays to enable easy reshaping and other array operations\n",
        "    \n",
        "X  = np.asarray(X)\n",
        "Xs = np.asarray(Xs)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape)\n",
        "y= np.asarray(y)\n",
        "\n",
        "X  = np.swapaxes(X,1,3)\n",
        "X  = np.swapaxes(X,2,3)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape,y.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the input image (10000, 16, 16, 3) (10000, 16, 16)\n",
            "Shape of the input image (10000, 3, 16, 16) (10000, 16, 16) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HZ5T4nuJ3xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5543edff-2c1f-4c84-ed69-22fcdbea0ec4"
      },
      "source": [
        "Xtr=X[:8500,:,:,:]/255\n",
        "Xstr=Xs[:8500,:,:]/255\n",
        "ytr=y[:8500]\n",
        "\n",
        "Xval=X[8500:9000,:,:,:]/255 #need to change validation size for 32x32 & 64x64 images\n",
        "Xsval=Xs[8500:9000,:,:]/255\n",
        "yval=y[8500:9000]\n",
        "\n",
        "Xte=X[-1000:,:,:,:]/255 #need to change test size for 32x32 & 64x64 images\n",
        "Xste=Xs[-1000:,:,:]/255\n",
        "yte=y[-1000:]\n",
        "\n",
        "\n",
        "print(Xtr.shape,Xstr.shape,ytr.shape)\n",
        "print(Xval.shape,Xsval.shape,yval.shape)\n",
        "print(Xte.shape,Xste.shape,yte.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8500, 3, 16, 16) (8500, 16, 16) (8500,)\n",
            "(500, 3, 16, 16) (500, 16, 16) (500,)\n",
            "(1000, 3, 16, 16) (1000, 16, 16) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBYK6LF7MiMW",
        "colab_type": "text"
      },
      "source": [
        "The color dataset is loaded to be the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3SjbPUrJ4za",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "81352143-ba6a-44b3-81c3-7d5841cf7f3f"
      },
      "source": [
        "targets=yte\n",
        "inputs = torch.from_numpy(Xte).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xste).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "testset = data_utils.TensorDataset(inputs, segs,targets)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size, \n",
        "                                          shuffle=False, drop_last=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([1000, 3, 16, 16])\n",
            "Size of ground truth: torch.Size([1000, 16, 16])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZbTNpYnKIhJ",
        "colab_type": "text"
      },
      "source": [
        "Test the color dataset on the model trained using the red dataset. The accuracy is only 22.9%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEpXj8OGKC-r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df33cf57-820f-4c71-e3fe-5cdc4a0712c2"
      },
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    OP = []\n",
        "    PR = []\n",
        "    LB = []\n",
        "    for i, (images, segs, targets) in enumerate(test_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,16,16))\n",
        "        labels = targets.to(device)\n",
        "        LB.append(labels.cpu().numpy())\n",
        "        outputs=model(images.cuda())\n",
        "        OP.append(outputs.cpu().numpy())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        PR.append(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the 1000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 1000 test images: 22.9 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxum2LS_KHC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "dfb4c283-b7dd-4821-8622-8fcaec8a3e81"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = np.array(PR)\n",
        "pred = pred.reshape(1000)\n",
        "print(np.shape(pred))\n",
        "label = np.array(LB)\n",
        "label = label.reshape(1000)\n",
        "print(np.shape(label))\n",
        "cfm=confusion_matrix(pred, label)\n",
        "print(cfm)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "[[ 2  0  0  0  0  0  1  0  0  0]\n",
            " [51 98 45 69 73 28 61 53 65 64]\n",
            " [ 8  6 19 12  4  5 11  3 14  6]\n",
            " [ 2  0  0 13  3  3  4  0  5  1]\n",
            " [ 0  0  0  0  2  0  1  1  1  1]\n",
            " [19  3  9 30 11 63  7 17 16 14]\n",
            " [ 0  0  0  1  0  1  5  0  0  0]\n",
            " [ 8  3  5  2  2  3  1 25  1 10]\n",
            " [ 0  0  0  2  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  2  0  0  0  3  2]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}