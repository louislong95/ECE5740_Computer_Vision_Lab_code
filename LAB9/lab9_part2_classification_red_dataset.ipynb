{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab9 part2 classification red dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ7lBdIP8_Xb",
        "colab_type": "text"
      },
      "source": [
        "part2 classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oOAwWvU9C0m",
        "colab_type": "text"
      },
      "source": [
        "red dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpL-P-sN8qXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torchvision.datasets as datasets\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import copy\n",
        "import torch.utils.data as data_utils\n",
        "import requests, zipfile, io\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 40\n",
        "num_classes = 10\n",
        "batch_size = 8\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# ECE5470 dataset\n",
        "url = 'https://www.via.cornell.edu/ece5470/Lab9data2r.zip'\n",
        "r=requests.get(url).content\n",
        "\n",
        "#save data in data dir\n",
        "z = zipfile.ZipFile(io.BytesIO(r))\n",
        "# os.mkdir('data1')\n",
        "z.extractall('./data1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRSYesZP9LOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Custom datatset loader\n",
        "    based on https://github.com/utkuozbulak/pytorch-custom-dataset-examples\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import imageio\n",
        "\n",
        "class SimpleDataset():\n",
        "    def __init__(self, data_path, csv_name, transform = None ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): path to the folder where images and csv files are located\n",
        "            csv_name (string): name of the csv lablel file\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        # Set path\n",
        "        self.data_path = data_path\n",
        "        \n",
        "        # Read the csv file\n",
        "        self.data_info = pd.read_csv(data_path + csv_name, header=0)\n",
        "       \n",
        "        # First column contains the image paths\n",
        "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
        "        \n",
        "        # Second column is the labels\n",
        "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
        "        # Calculate len\n",
        "        self.data_len = len(self.data_info.index)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # Get image name from the pandas df\n",
        "        single_image_name = self.image_arr[index]\n",
        "        # Open image\n",
        "        a=single_image_name[:-3] + \"png\"\n",
        "        single_image_name=a\n",
        "        img_as_img = imageio.imread(self.data_path + single_image_name)\n",
        "        # Open segmented mask\n",
        "        a = single_image_name[:2] + \"seg\" + single_image_name[2:]\n",
        "        imseg_name = a[:-3] + \"png\"\n",
        "        imgsg_as_img = imageio.imread(self.data_path + imseg_name)\n",
        "        \n",
        "        \n",
        "        # Get label(class) of the image based on the cropped pandas column\n",
        "        single_image_label = self.label_arr[index]\n",
        "        \n",
        "        return (img_as_img, single_image_label, imgsg_as_img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g74UsHmp9LQA",
        "colab_type": "code",
        "outputId": "b8fe5194-d8c2-439d-c835-6652de9b0780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mydata = SimpleDataset( \"./data1/\", \"labels.csv\")\n",
        "\n",
        "#splitting into images and labels \n",
        "X  = []\n",
        "y  = []\n",
        "Xs = []\n",
        "for i in range(len(mydata)):\n",
        "    X.append(mydata[i][0])\n",
        "    y.append((mydata[i][1]))\n",
        "    Xs.append(mydata[i][2])\n",
        "\n",
        "\n",
        "#converting into numpy arrays to enable easy reshaping and other array operations\n",
        "    \n",
        "X  = np.asarray(X)\n",
        "Xs = np.asarray(Xs)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape)\n",
        "y= np.asarray(y)\n",
        "\n",
        "X  = np.swapaxes(X,1,3)\n",
        "X  = np.swapaxes(X,2,3)\n",
        "print(\"Shape of the input image\", X.shape, Xs.shape,y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the input image (5000, 32, 32, 3) (5000, 32, 32)\n",
            "Shape of the input image (5000, 3, 32, 32) (5000, 32, 32) (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ox5xgux9Wx9",
        "colab_type": "code",
        "outputId": "32b906fb-db09-44ab-c375-fa2d0c5d5477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Xtr=X[:3500,:,:,:]/255\n",
        "Xstr=Xs[:3500,:,:]/255\n",
        "ytr=y[:3500]\n",
        "\n",
        "Xval=X[3500:4000,:,:,:]/255 #need to change validation size for 32x32 & 64x64 images\n",
        "Xsval=Xs[3500:4000,:,:]/255\n",
        "yval=y[3500:4000]\n",
        "\n",
        "Xte=X[4000:5000,:,:,:]/255 #need to change test size for 32x32 & 64x64 images\n",
        "Xste=Xs[4000:5000,:,:]/255\n",
        "yte=y[4000:5000]\n",
        "\n",
        "\n",
        "print(Xtr.shape,Xstr.shape,ytr.shape)\n",
        "print(Xval.shape,Xsval.shape,yval.shape)\n",
        "print(Xte.shape,Xste.shape,yte.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3500, 3, 32, 32) (3500, 32, 32) (3500,)\n",
            "(500, 3, 32, 32) (500, 32, 32) (500,)\n",
            "(1000, 3, 32, 32) (1000, 32, 32) (1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBEoG8Tv9Ym_",
        "colab_type": "code",
        "outputId": "ed29f5c1-27e4-4b6e-8b6c-3eca6993fec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 8\n",
        "'''\n",
        "inputs and segs are your data. \n",
        "'''\n",
        "targets=ytr\n",
        "\n",
        "inputs = torch.from_numpy(Xtr).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xstr).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "trainset = data_utils.TensorDataset(inputs, segs, targets)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size= batch_size, \n",
        "                                          shuffle=True,drop_last=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([3500, 3, 32, 32])\n",
            "Size of ground truth: torch.Size([3500, 32, 32])\n",
            "torch.Size([3500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKKalrII9a1F",
        "colab_type": "code",
        "outputId": "a82cc800-a553-4b7a-f3f7-fb18077aee19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "targets=yte\n",
        "inputs = torch.from_numpy(Xte).float()\n",
        "targets = torch.from_numpy(targets).float()\n",
        "segs    = torch.from_numpy(Xste).float()\n",
        "\n",
        "print('Size of inputs: {}'. format(inputs.shape))\n",
        "print('Size of ground truth: {}'. format(segs.shape))\n",
        "print(targets.shape)\n",
        "\n",
        "# Dataloader\n",
        "testset = data_utils.TensorDataset(inputs, segs,targets)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size= batch_size, \n",
        "                                          shuffle=False, drop_last=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of inputs: torch.Size([1000, 3, 32, 32])\n",
            "Size of ground truth: torch.Size([1000, 32, 32])\n",
            "torch.Size([1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7mrqwQa9cX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(2*32*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTJlZoZP9eG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdM4RNpf9fnF",
        "colab_type": "code",
        "outputId": "bb36a52d-8351-44c1-82a5-0131e3dbd2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "resultstr = []\n",
        "resultsval = []\n",
        "correct = 0\n",
        "total = 0\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, segs, targets) in enumerate(train_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,32,32))\n",
        "        labels = targets.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images.cuda())\n",
        "        loss = criterion(outputs, labels.to(torch.long))\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # O\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], TrLoss: {:.4f}' \n",
        "                   .format(epoch+1,num_epochs,i+1, total_step, loss.data))\n",
        "    \n",
        "    resultstr.append(loss.data.cpu().to(torch.float))\n",
        "acc = correct/total\n",
        "print('Training accuracy: {} %'.format(100*acc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/40], Step [50/437], TrLoss: 2.4010\n",
            "Epoch [1/40], Step [100/437], TrLoss: 2.4736\n",
            "Epoch [1/40], Step [150/437], TrLoss: 2.0550\n",
            "Epoch [1/40], Step [200/437], TrLoss: 2.1515\n",
            "Epoch [1/40], Step [250/437], TrLoss: 2.3487\n",
            "Epoch [1/40], Step [300/437], TrLoss: 2.2108\n",
            "Epoch [1/40], Step [350/437], TrLoss: 2.4453\n",
            "Epoch [1/40], Step [400/437], TrLoss: 2.1873\n",
            "Epoch [2/40], Step [50/437], TrLoss: 2.3154\n",
            "Epoch [2/40], Step [100/437], TrLoss: 2.3636\n",
            "Epoch [2/40], Step [150/437], TrLoss: 2.3027\n",
            "Epoch [2/40], Step [200/437], TrLoss: 2.5069\n",
            "Epoch [2/40], Step [250/437], TrLoss: 2.0324\n",
            "Epoch [2/40], Step [300/437], TrLoss: 2.3521\n",
            "Epoch [2/40], Step [350/437], TrLoss: 2.2464\n",
            "Epoch [2/40], Step [400/437], TrLoss: 2.2533\n",
            "Epoch [3/40], Step [50/437], TrLoss: 2.0478\n",
            "Epoch [3/40], Step [100/437], TrLoss: 2.2675\n",
            "Epoch [3/40], Step [150/437], TrLoss: 2.2281\n",
            "Epoch [3/40], Step [200/437], TrLoss: 2.2222\n",
            "Epoch [3/40], Step [250/437], TrLoss: 2.3322\n",
            "Epoch [3/40], Step [300/437], TrLoss: 2.2949\n",
            "Epoch [3/40], Step [350/437], TrLoss: 2.1184\n",
            "Epoch [3/40], Step [400/437], TrLoss: 2.3817\n",
            "Epoch [4/40], Step [50/437], TrLoss: 2.0482\n",
            "Epoch [4/40], Step [100/437], TrLoss: 2.0033\n",
            "Epoch [4/40], Step [150/437], TrLoss: 1.9521\n",
            "Epoch [4/40], Step [200/437], TrLoss: 2.0371\n",
            "Epoch [4/40], Step [250/437], TrLoss: 2.3921\n",
            "Epoch [4/40], Step [300/437], TrLoss: 2.4167\n",
            "Epoch [4/40], Step [350/437], TrLoss: 2.2490\n",
            "Epoch [4/40], Step [400/437], TrLoss: 2.3317\n",
            "Epoch [5/40], Step [50/437], TrLoss: 1.9636\n",
            "Epoch [5/40], Step [100/437], TrLoss: 2.1219\n",
            "Epoch [5/40], Step [150/437], TrLoss: 1.9225\n",
            "Epoch [5/40], Step [200/437], TrLoss: 2.0789\n",
            "Epoch [5/40], Step [250/437], TrLoss: 2.0814\n",
            "Epoch [5/40], Step [300/437], TrLoss: 2.3378\n",
            "Epoch [5/40], Step [350/437], TrLoss: 2.3127\n",
            "Epoch [5/40], Step [400/437], TrLoss: 2.0412\n",
            "Epoch [6/40], Step [50/437], TrLoss: 2.0303\n",
            "Epoch [6/40], Step [100/437], TrLoss: 1.6699\n",
            "Epoch [6/40], Step [150/437], TrLoss: 1.8880\n",
            "Epoch [6/40], Step [200/437], TrLoss: 1.6460\n",
            "Epoch [6/40], Step [250/437], TrLoss: 1.9185\n",
            "Epoch [6/40], Step [300/437], TrLoss: 2.1171\n",
            "Epoch [6/40], Step [350/437], TrLoss: 1.9881\n",
            "Epoch [6/40], Step [400/437], TrLoss: 2.1284\n",
            "Epoch [7/40], Step [50/437], TrLoss: 2.0198\n",
            "Epoch [7/40], Step [100/437], TrLoss: 2.0913\n",
            "Epoch [7/40], Step [150/437], TrLoss: 1.9626\n",
            "Epoch [7/40], Step [200/437], TrLoss: 2.0327\n",
            "Epoch [7/40], Step [250/437], TrLoss: 1.8101\n",
            "Epoch [7/40], Step [300/437], TrLoss: 1.6976\n",
            "Epoch [7/40], Step [350/437], TrLoss: 1.6102\n",
            "Epoch [7/40], Step [400/437], TrLoss: 1.5013\n",
            "Epoch [8/40], Step [50/437], TrLoss: 1.1799\n",
            "Epoch [8/40], Step [100/437], TrLoss: 1.7657\n",
            "Epoch [8/40], Step [150/437], TrLoss: 1.8651\n",
            "Epoch [8/40], Step [200/437], TrLoss: 1.5051\n",
            "Epoch [8/40], Step [250/437], TrLoss: 1.6212\n",
            "Epoch [8/40], Step [300/437], TrLoss: 1.2706\n",
            "Epoch [8/40], Step [350/437], TrLoss: 2.0744\n",
            "Epoch [8/40], Step [400/437], TrLoss: 1.1435\n",
            "Epoch [9/40], Step [50/437], TrLoss: 1.6550\n",
            "Epoch [9/40], Step [100/437], TrLoss: 2.0471\n",
            "Epoch [9/40], Step [150/437], TrLoss: 1.2865\n",
            "Epoch [9/40], Step [200/437], TrLoss: 1.1119\n",
            "Epoch [9/40], Step [250/437], TrLoss: 1.4149\n",
            "Epoch [9/40], Step [300/437], TrLoss: 1.7306\n",
            "Epoch [9/40], Step [350/437], TrLoss: 1.3053\n",
            "Epoch [9/40], Step [400/437], TrLoss: 1.4827\n",
            "Epoch [10/40], Step [50/437], TrLoss: 1.1709\n",
            "Epoch [10/40], Step [100/437], TrLoss: 1.5327\n",
            "Epoch [10/40], Step [150/437], TrLoss: 1.2441\n",
            "Epoch [10/40], Step [200/437], TrLoss: 1.2732\n",
            "Epoch [10/40], Step [250/437], TrLoss: 1.0974\n",
            "Epoch [10/40], Step [300/437], TrLoss: 1.9889\n",
            "Epoch [10/40], Step [350/437], TrLoss: 1.2692\n",
            "Epoch [10/40], Step [400/437], TrLoss: 1.4195\n",
            "Epoch [11/40], Step [50/437], TrLoss: 1.1496\n",
            "Epoch [11/40], Step [100/437], TrLoss: 1.4754\n",
            "Epoch [11/40], Step [150/437], TrLoss: 1.0604\n",
            "Epoch [11/40], Step [200/437], TrLoss: 1.1151\n",
            "Epoch [11/40], Step [250/437], TrLoss: 1.3846\n",
            "Epoch [11/40], Step [300/437], TrLoss: 1.5477\n",
            "Epoch [11/40], Step [350/437], TrLoss: 1.2673\n",
            "Epoch [11/40], Step [400/437], TrLoss: 2.0373\n",
            "Epoch [12/40], Step [50/437], TrLoss: 1.5484\n",
            "Epoch [12/40], Step [100/437], TrLoss: 1.1089\n",
            "Epoch [12/40], Step [150/437], TrLoss: 1.2255\n",
            "Epoch [12/40], Step [200/437], TrLoss: 1.3936\n",
            "Epoch [12/40], Step [250/437], TrLoss: 1.3214\n",
            "Epoch [12/40], Step [300/437], TrLoss: 1.1980\n",
            "Epoch [12/40], Step [350/437], TrLoss: 1.3376\n",
            "Epoch [12/40], Step [400/437], TrLoss: 1.1007\n",
            "Epoch [13/40], Step [50/437], TrLoss: 1.0285\n",
            "Epoch [13/40], Step [100/437], TrLoss: 1.5427\n",
            "Epoch [13/40], Step [150/437], TrLoss: 1.5529\n",
            "Epoch [13/40], Step [200/437], TrLoss: 0.9935\n",
            "Epoch [13/40], Step [250/437], TrLoss: 1.0388\n",
            "Epoch [13/40], Step [300/437], TrLoss: 0.8400\n",
            "Epoch [13/40], Step [350/437], TrLoss: 1.2177\n",
            "Epoch [13/40], Step [400/437], TrLoss: 0.9641\n",
            "Epoch [14/40], Step [50/437], TrLoss: 1.1506\n",
            "Epoch [14/40], Step [100/437], TrLoss: 0.9416\n",
            "Epoch [14/40], Step [150/437], TrLoss: 1.6465\n",
            "Epoch [14/40], Step [200/437], TrLoss: 0.9332\n",
            "Epoch [14/40], Step [250/437], TrLoss: 1.0508\n",
            "Epoch [14/40], Step [300/437], TrLoss: 0.8096\n",
            "Epoch [14/40], Step [350/437], TrLoss: 0.7997\n",
            "Epoch [14/40], Step [400/437], TrLoss: 0.5957\n",
            "Epoch [15/40], Step [50/437], TrLoss: 0.7846\n",
            "Epoch [15/40], Step [100/437], TrLoss: 0.8869\n",
            "Epoch [15/40], Step [150/437], TrLoss: 0.7261\n",
            "Epoch [15/40], Step [200/437], TrLoss: 1.2277\n",
            "Epoch [15/40], Step [250/437], TrLoss: 0.7184\n",
            "Epoch [15/40], Step [300/437], TrLoss: 0.8157\n",
            "Epoch [15/40], Step [350/437], TrLoss: 0.8194\n",
            "Epoch [15/40], Step [400/437], TrLoss: 0.8633\n",
            "Epoch [16/40], Step [50/437], TrLoss: 1.1851\n",
            "Epoch [16/40], Step [100/437], TrLoss: 0.8008\n",
            "Epoch [16/40], Step [150/437], TrLoss: 1.1553\n",
            "Epoch [16/40], Step [200/437], TrLoss: 0.7256\n",
            "Epoch [16/40], Step [250/437], TrLoss: 0.6638\n",
            "Epoch [16/40], Step [300/437], TrLoss: 0.6060\n",
            "Epoch [16/40], Step [350/437], TrLoss: 0.8761\n",
            "Epoch [16/40], Step [400/437], TrLoss: 0.9071\n",
            "Epoch [17/40], Step [50/437], TrLoss: 1.1531\n",
            "Epoch [17/40], Step [100/437], TrLoss: 0.8354\n",
            "Epoch [17/40], Step [150/437], TrLoss: 0.5832\n",
            "Epoch [17/40], Step [200/437], TrLoss: 0.9842\n",
            "Epoch [17/40], Step [250/437], TrLoss: 0.8842\n",
            "Epoch [17/40], Step [300/437], TrLoss: 0.8806\n",
            "Epoch [17/40], Step [350/437], TrLoss: 0.9916\n",
            "Epoch [17/40], Step [400/437], TrLoss: 1.2436\n",
            "Epoch [18/40], Step [50/437], TrLoss: 0.4886\n",
            "Epoch [18/40], Step [100/437], TrLoss: 0.7431\n",
            "Epoch [18/40], Step [150/437], TrLoss: 0.8176\n",
            "Epoch [18/40], Step [200/437], TrLoss: 0.5127\n",
            "Epoch [18/40], Step [250/437], TrLoss: 0.6425\n",
            "Epoch [18/40], Step [300/437], TrLoss: 0.7893\n",
            "Epoch [18/40], Step [350/437], TrLoss: 0.6536\n",
            "Epoch [18/40], Step [400/437], TrLoss: 0.7262\n",
            "Epoch [19/40], Step [50/437], TrLoss: 0.4743\n",
            "Epoch [19/40], Step [100/437], TrLoss: 0.4224\n",
            "Epoch [19/40], Step [150/437], TrLoss: 0.7393\n",
            "Epoch [19/40], Step [200/437], TrLoss: 0.4046\n",
            "Epoch [19/40], Step [250/437], TrLoss: 0.7491\n",
            "Epoch [19/40], Step [300/437], TrLoss: 0.8945\n",
            "Epoch [19/40], Step [350/437], TrLoss: 0.5828\n",
            "Epoch [19/40], Step [400/437], TrLoss: 0.7513\n",
            "Epoch [20/40], Step [50/437], TrLoss: 0.5655\n",
            "Epoch [20/40], Step [100/437], TrLoss: 0.5784\n",
            "Epoch [20/40], Step [150/437], TrLoss: 0.3942\n",
            "Epoch [20/40], Step [200/437], TrLoss: 0.6033\n",
            "Epoch [20/40], Step [250/437], TrLoss: 0.7834\n",
            "Epoch [20/40], Step [300/437], TrLoss: 0.4155\n",
            "Epoch [20/40], Step [350/437], TrLoss: 0.8316\n",
            "Epoch [20/40], Step [400/437], TrLoss: 0.9167\n",
            "Epoch [21/40], Step [50/437], TrLoss: 0.4914\n",
            "Epoch [21/40], Step [100/437], TrLoss: 0.9190\n",
            "Epoch [21/40], Step [150/437], TrLoss: 0.5582\n",
            "Epoch [21/40], Step [200/437], TrLoss: 0.7253\n",
            "Epoch [21/40], Step [250/437], TrLoss: 0.5511\n",
            "Epoch [21/40], Step [300/437], TrLoss: 0.6826\n",
            "Epoch [21/40], Step [350/437], TrLoss: 1.1656\n",
            "Epoch [21/40], Step [400/437], TrLoss: 0.3945\n",
            "Epoch [22/40], Step [50/437], TrLoss: 0.3633\n",
            "Epoch [22/40], Step [100/437], TrLoss: 0.5871\n",
            "Epoch [22/40], Step [150/437], TrLoss: 0.5367\n",
            "Epoch [22/40], Step [200/437], TrLoss: 0.4073\n",
            "Epoch [22/40], Step [250/437], TrLoss: 0.5079\n",
            "Epoch [22/40], Step [300/437], TrLoss: 0.5597\n",
            "Epoch [22/40], Step [350/437], TrLoss: 0.2405\n",
            "Epoch [22/40], Step [400/437], TrLoss: 0.5054\n",
            "Epoch [23/40], Step [50/437], TrLoss: 0.6696\n",
            "Epoch [23/40], Step [100/437], TrLoss: 0.3940\n",
            "Epoch [23/40], Step [150/437], TrLoss: 0.7792\n",
            "Epoch [23/40], Step [200/437], TrLoss: 0.4709\n",
            "Epoch [23/40], Step [250/437], TrLoss: 0.5917\n",
            "Epoch [23/40], Step [300/437], TrLoss: 0.3245\n",
            "Epoch [23/40], Step [350/437], TrLoss: 0.4429\n",
            "Epoch [23/40], Step [400/437], TrLoss: 0.4200\n",
            "Epoch [24/40], Step [50/437], TrLoss: 0.5117\n",
            "Epoch [24/40], Step [100/437], TrLoss: 0.6100\n",
            "Epoch [24/40], Step [150/437], TrLoss: 0.4868\n",
            "Epoch [24/40], Step [200/437], TrLoss: 0.4979\n",
            "Epoch [24/40], Step [250/437], TrLoss: 0.4585\n",
            "Epoch [24/40], Step [300/437], TrLoss: 0.6309\n",
            "Epoch [24/40], Step [350/437], TrLoss: 0.6560\n",
            "Epoch [24/40], Step [400/437], TrLoss: 0.4016\n",
            "Epoch [25/40], Step [50/437], TrLoss: 0.2376\n",
            "Epoch [25/40], Step [100/437], TrLoss: 0.9778\n",
            "Epoch [25/40], Step [150/437], TrLoss: 0.3856\n",
            "Epoch [25/40], Step [200/437], TrLoss: 0.4173\n",
            "Epoch [25/40], Step [250/437], TrLoss: 0.3179\n",
            "Epoch [25/40], Step [300/437], TrLoss: 0.2550\n",
            "Epoch [25/40], Step [350/437], TrLoss: 0.2396\n",
            "Epoch [25/40], Step [400/437], TrLoss: 0.4367\n",
            "Epoch [26/40], Step [50/437], TrLoss: 0.2534\n",
            "Epoch [26/40], Step [100/437], TrLoss: 0.3242\n",
            "Epoch [26/40], Step [150/437], TrLoss: 0.3605\n",
            "Epoch [26/40], Step [200/437], TrLoss: 0.2011\n",
            "Epoch [26/40], Step [250/437], TrLoss: 0.3254\n",
            "Epoch [26/40], Step [300/437], TrLoss: 0.2565\n",
            "Epoch [26/40], Step [350/437], TrLoss: 0.3173\n",
            "Epoch [26/40], Step [400/437], TrLoss: 0.2042\n",
            "Epoch [27/40], Step [50/437], TrLoss: 0.3763\n",
            "Epoch [27/40], Step [100/437], TrLoss: 0.2090\n",
            "Epoch [27/40], Step [150/437], TrLoss: 0.4215\n",
            "Epoch [27/40], Step [200/437], TrLoss: 0.3733\n",
            "Epoch [27/40], Step [250/437], TrLoss: 0.2870\n",
            "Epoch [27/40], Step [300/437], TrLoss: 0.3242\n",
            "Epoch [27/40], Step [350/437], TrLoss: 0.1879\n",
            "Epoch [27/40], Step [400/437], TrLoss: 0.2292\n",
            "Epoch [28/40], Step [50/437], TrLoss: 0.2754\n",
            "Epoch [28/40], Step [100/437], TrLoss: 0.3884\n",
            "Epoch [28/40], Step [150/437], TrLoss: 0.2874\n",
            "Epoch [28/40], Step [200/437], TrLoss: 0.2205\n",
            "Epoch [28/40], Step [250/437], TrLoss: 0.4678\n",
            "Epoch [28/40], Step [300/437], TrLoss: 0.5496\n",
            "Epoch [28/40], Step [350/437], TrLoss: 0.1204\n",
            "Epoch [28/40], Step [400/437], TrLoss: 0.5043\n",
            "Epoch [29/40], Step [50/437], TrLoss: 0.2913\n",
            "Epoch [29/40], Step [100/437], TrLoss: 0.4578\n",
            "Epoch [29/40], Step [150/437], TrLoss: 0.1367\n",
            "Epoch [29/40], Step [200/437], TrLoss: 0.2893\n",
            "Epoch [29/40], Step [250/437], TrLoss: 0.2937\n",
            "Epoch [29/40], Step [300/437], TrLoss: 0.1763\n",
            "Epoch [29/40], Step [350/437], TrLoss: 0.4738\n",
            "Epoch [29/40], Step [400/437], TrLoss: 0.5475\n",
            "Epoch [30/40], Step [50/437], TrLoss: 0.2437\n",
            "Epoch [30/40], Step [100/437], TrLoss: 0.2410\n",
            "Epoch [30/40], Step [150/437], TrLoss: 0.2520\n",
            "Epoch [30/40], Step [200/437], TrLoss: 0.3071\n",
            "Epoch [30/40], Step [250/437], TrLoss: 0.1878\n",
            "Epoch [30/40], Step [300/437], TrLoss: 0.3741\n",
            "Epoch [30/40], Step [350/437], TrLoss: 0.2979\n",
            "Epoch [30/40], Step [400/437], TrLoss: 0.2418\n",
            "Epoch [31/40], Step [50/437], TrLoss: 0.1653\n",
            "Epoch [31/40], Step [100/437], TrLoss: 0.1543\n",
            "Epoch [31/40], Step [150/437], TrLoss: 0.1849\n",
            "Epoch [31/40], Step [200/437], TrLoss: 0.3293\n",
            "Epoch [31/40], Step [250/437], TrLoss: 0.2653\n",
            "Epoch [31/40], Step [300/437], TrLoss: 0.3293\n",
            "Epoch [31/40], Step [350/437], TrLoss: 0.1054\n",
            "Epoch [31/40], Step [400/437], TrLoss: 0.3191\n",
            "Epoch [32/40], Step [50/437], TrLoss: 0.2385\n",
            "Epoch [32/40], Step [100/437], TrLoss: 0.0656\n",
            "Epoch [32/40], Step [150/437], TrLoss: 0.3908\n",
            "Epoch [32/40], Step [200/437], TrLoss: 0.2171\n",
            "Epoch [32/40], Step [250/437], TrLoss: 0.2294\n",
            "Epoch [32/40], Step [300/437], TrLoss: 0.1779\n",
            "Epoch [32/40], Step [350/437], TrLoss: 0.2063\n",
            "Epoch [32/40], Step [400/437], TrLoss: 0.2893\n",
            "Epoch [33/40], Step [50/437], TrLoss: 0.1075\n",
            "Epoch [33/40], Step [100/437], TrLoss: 0.2037\n",
            "Epoch [33/40], Step [150/437], TrLoss: 0.1822\n",
            "Epoch [33/40], Step [200/437], TrLoss: 0.1796\n",
            "Epoch [33/40], Step [250/437], TrLoss: 0.2669\n",
            "Epoch [33/40], Step [300/437], TrLoss: 0.1864\n",
            "Epoch [33/40], Step [350/437], TrLoss: 0.1869\n",
            "Epoch [33/40], Step [400/437], TrLoss: 0.0915\n",
            "Epoch [34/40], Step [50/437], TrLoss: 0.3450\n",
            "Epoch [34/40], Step [100/437], TrLoss: 0.1940\n",
            "Epoch [34/40], Step [150/437], TrLoss: 0.3627\n",
            "Epoch [34/40], Step [200/437], TrLoss: 0.1754\n",
            "Epoch [34/40], Step [250/437], TrLoss: 0.2433\n",
            "Epoch [34/40], Step [300/437], TrLoss: 0.1324\n",
            "Epoch [34/40], Step [350/437], TrLoss: 0.1706\n",
            "Epoch [34/40], Step [400/437], TrLoss: 0.0777\n",
            "Epoch [35/40], Step [50/437], TrLoss: 0.0976\n",
            "Epoch [35/40], Step [100/437], TrLoss: 0.0951\n",
            "Epoch [35/40], Step [150/437], TrLoss: 0.1063\n",
            "Epoch [35/40], Step [200/437], TrLoss: 0.1838\n",
            "Epoch [35/40], Step [250/437], TrLoss: 0.1859\n",
            "Epoch [35/40], Step [300/437], TrLoss: 0.1711\n",
            "Epoch [35/40], Step [350/437], TrLoss: 0.1242\n",
            "Epoch [35/40], Step [400/437], TrLoss: 0.2922\n",
            "Epoch [36/40], Step [50/437], TrLoss: 0.0948\n",
            "Epoch [36/40], Step [100/437], TrLoss: 0.0989\n",
            "Epoch [36/40], Step [150/437], TrLoss: 0.1498\n",
            "Epoch [36/40], Step [200/437], TrLoss: 0.2354\n",
            "Epoch [36/40], Step [250/437], TrLoss: 0.1020\n",
            "Epoch [36/40], Step [300/437], TrLoss: 0.1157\n",
            "Epoch [36/40], Step [350/437], TrLoss: 0.0564\n",
            "Epoch [36/40], Step [400/437], TrLoss: 0.2509\n",
            "Epoch [37/40], Step [50/437], TrLoss: 0.1594\n",
            "Epoch [37/40], Step [100/437], TrLoss: 0.1542\n",
            "Epoch [37/40], Step [150/437], TrLoss: 0.0678\n",
            "Epoch [37/40], Step [200/437], TrLoss: 0.2063\n",
            "Epoch [37/40], Step [250/437], TrLoss: 0.0647\n",
            "Epoch [37/40], Step [300/437], TrLoss: 0.1875\n",
            "Epoch [37/40], Step [350/437], TrLoss: 0.1361\n",
            "Epoch [37/40], Step [400/437], TrLoss: 0.1562\n",
            "Epoch [38/40], Step [50/437], TrLoss: 0.0852\n",
            "Epoch [38/40], Step [100/437], TrLoss: 0.1516\n",
            "Epoch [38/40], Step [150/437], TrLoss: 0.1265\n",
            "Epoch [38/40], Step [200/437], TrLoss: 0.0881\n",
            "Epoch [38/40], Step [250/437], TrLoss: 0.0591\n",
            "Epoch [38/40], Step [300/437], TrLoss: 0.0637\n",
            "Epoch [38/40], Step [350/437], TrLoss: 0.2090\n",
            "Epoch [38/40], Step [400/437], TrLoss: 0.1341\n",
            "Epoch [39/40], Step [50/437], TrLoss: 0.0547\n",
            "Epoch [39/40], Step [100/437], TrLoss: 0.0592\n",
            "Epoch [39/40], Step [150/437], TrLoss: 0.0944\n",
            "Epoch [39/40], Step [200/437], TrLoss: 0.1115\n",
            "Epoch [39/40], Step [250/437], TrLoss: 0.0402\n",
            "Epoch [39/40], Step [300/437], TrLoss: 0.2699\n",
            "Epoch [39/40], Step [350/437], TrLoss: 0.0668\n",
            "Epoch [39/40], Step [400/437], TrLoss: 0.0700\n",
            "Epoch [40/40], Step [50/437], TrLoss: 0.0445\n",
            "Epoch [40/40], Step [100/437], TrLoss: 0.1055\n",
            "Epoch [40/40], Step [150/437], TrLoss: 0.1786\n",
            "Epoch [40/40], Step [200/437], TrLoss: 0.1067\n",
            "Epoch [40/40], Step [250/437], TrLoss: 0.0632\n",
            "Epoch [40/40], Step [300/437], TrLoss: 0.0608\n",
            "Epoch [40/40], Step [350/437], TrLoss: 0.0507\n",
            "Epoch [40/40], Step [400/437], TrLoss: 0.0629\n",
            "Training accuracy: 75.69508009153319 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raZp724l9hSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc8e2051-873b-41e0-bcb8-e03e1a9ff9d3"
      },
      "source": [
        "# Test the model\n",
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    OP = []\n",
        "    PR = []\n",
        "    LB = []\n",
        "    for i, (images, segs, targets) in enumerate(test_loader):\n",
        "        segs = segs.to(device)\n",
        "        segs = torch.reshape(segs, (batch_size,1,32,32))\n",
        "        labels = targets.to(device)\n",
        "        LB.append(labels.cpu().numpy())\n",
        "        outputs=model(images.cuda())\n",
        "        OP.append(outputs.cpu().numpy())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        PR.append(predicted.cpu().numpy())\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.to(torch.int) == labels.to(torch.int)).sum().item()\n",
        "\n",
        "print('Test Accuracy of the model on the 1000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 1000 test images: 46.8 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3D3IkL9km1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aacb99b6-03ca-4092-ee70-95d6dddce1ca"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = np.array(PR)\n",
        "pred = pred.reshape(1000)\n",
        "print(np.shape(pred))\n",
        "label = np.array(LB)\n",
        "label = label.reshape(1000)\n",
        "print(np.shape(label))\n",
        "cfm=confusion_matrix(pred, label)\n",
        "print(cfm)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "(1000,)\n",
            "[[48  0  5  3  2  3  6  3  4  1]\n",
            " [ 2 90  2  6  6  0  2  6  4  2]\n",
            " [ 5  1 25 11  2  4  2  4  2  4]\n",
            " [ 1  0 19 53  4 23  1  6 12  6]\n",
            " [21 16 10  4 64  6 21 10  8 22]\n",
            " [ 0  2 11  7  1 22  4  0  4  2]\n",
            " [10  1  7  1  7  0 48  1  8  7]\n",
            " [ 6  6  6  2  2  1  2 46  2  9]\n",
            " [ 8  1 13  9  3  6  2  3 34 10]\n",
            " [ 6  8  8 10 14  6  6 16 12 38]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}